<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Introduction to deep learning: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/lab/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/lab/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/lab/favicon-16x16.png">
<link rel="manifest" href="favicons/lab/site.webmanifest">
<link rel="mask-icon" href="favicons/lab/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav lab"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="lab-logo" alt="Carpentries Lab" src="assets/images/lab-logo.svg"><abbr class="badge peer-reviewed" title="This lesson has passed peer review.">
          <a href="https://doi.org/10.5281/zenodo.8308391" class="external-link alert-link">
            <i aria-hidden="true" class="icon" data-feather="user-check" style="border-radius: 5px"></i>
            DOI: 10.5281/zenodo.8308391
          </a>
        </abbr>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav lab" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Lab" src="assets/images/lab-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Introduction to deep learning
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Introduction to deep learning
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to deep learning
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress lab">
    <div class="progress-bar lab" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="1-introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="2-keras.html">2. Classification by a neural network using Keras</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="3-monitor-the-model.html">3. Monitor the training process</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="4-advanced-layer-types.html">4. Advanced layer types</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="5-transfer-learning.html">5. Transfer learning</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="6-outlook.html">6. Outlook</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-1-introduction"><p>Content from <a href="1-introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2025-09-01 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/1-introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is deep learning?</li>
<li>What is a neural network?</li>
<li>Which operations are performed by a single neuron?</li>
<li>How do neural networks learn?</li>
<li>When does it make sense to use and not use deep learning?</li>
<li>What are tools involved in deep learning?</li>
<li>What is the workflow for deep learning?</li>
<li>Why did we choose to use Keras in this lesson?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Define deep learning</li>
<li>Describe how a neural network is build up</li>
<li>Explain the operations performed by a single neuron</li>
<li>Describe what a loss function is</li>
<li>Recall the sort of problems for which deep learning is a useful
tool</li>
<li>List some of the available tools for deep learning</li>
<li>Recall the steps of a deep learning workflow</li>
<li>Test that you have correctly installed the Keras, Seaborn and
scikit-learn libraries</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="what-is-deep-learning">What is Deep Learning?<a class="anchor" aria-label="anchor" href="#what-is-deep-learning"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="deep-learning-machine-learning-and-artificial-intelligence">Deep Learning, Machine Learning and Artificial Intelligence<a class="anchor" aria-label="anchor" href="#deep-learning-machine-learning-and-artificial-intelligence"></a>
</h3>
<p>Deep learning (DL) is just one of many techniques collectively known
as machine learning. Machine learning (ML) refers to techniques where a
computer can “learn” patterns in data, usually by being shown numerous
examples to train it. People often talk about machine learning being a
form of artificial intelligence (AI). Definitions of artificial
intelligence vary, but usually involve having computers mimic the
behaviour of intelligent biological systems. Since the 1950s many works
of science fiction have dealt with the idea of an artificial
intelligence which matches (or exceeds) human intelligence in all areas.
Although there have been great advances in AI and ML research recently
we can only come close to human like intelligence in a few specialist
areas and are still a long way from a general purpose AI. The image
below shows some differences between artificial intelligence, machine
learning and deep learning.</p>
<figure><img src="fig/01_AI_ML_DL_differences.png" style="width:60.0%" alt="An infographic showing the relation of artificial intelligence, machine learning, and deep learning. Deep learning is a specific subset of machine learning algorithms. Machine learning is one of the approaches to artificial intelligence." class="figure mx-auto d-block"></figure><div class="section level4">
<h4 id="neural-networks">Neural Networks<a class="anchor" aria-label="anchor" href="#neural-networks"></a>
</h4>
<p>A neural network is an artificial intelligence technique loosely
based on the way neurons in the brain work. A neural network consists of
connected computational units called <strong>neurons</strong>. Let’s
look at the operations of a single neuron.</p>
<div class="section level5">
<h5 id="a-single-neuron">A single neuron<a class="anchor" aria-label="anchor" href="#a-single-neuron"></a>
</h5>
<p>Each neuron …</p>
<ul>
<li>has one or more inputs (<span class="math inline">\(x_1, x_2,
...\)</span>), e.g. input data expressed as floating point numbers</li>
<li>most of the time, each neuron conducts 3 main operations:
<ul>
<li>take the weighted sum of the inputs where (<span class="math inline">\(w_1, w_2, ...\)</span>) indicate weights</li>
<li>add an extra constant weight (i.e. a bias term) to this weighted
sum</li>
<li>apply an <strong>activation function</strong> to the output so far,
we will explain activation functions</li>
</ul>
</li>
<li>return one output value, again a floating point number.</li>
<li>one example equation to calculate the output for a neuron is: <span class="math inline">\(output = Activation(\sum_{i} (x_i*w_i) +
bias)\)</span>
</li>
</ul>
<figure><img src="fig/01_neuron.png" alt="A diagram of a single artificial neuron combining inputs and weights using an activation function." width="600" class="figure mx-auto d-block"></figure>
</div>
<div class="section level5">
<h5 id="activation-functions">Activation functions<a class="anchor" aria-label="anchor" href="#activation-functions"></a>
</h5>
<p>The goal of the activation function is to convert the weighted sum of
the inputs to the output signal of the neuron. This output is then
passed on to the next layer of the network. There are many different
activation functions, 3 of them are introduced in the exercise
below.</p>
<div id="activation-functions-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="activation-functions-1" class="callout-inner">
<h3 class="callout-title">Activation functions</h3>
<div class="callout-content">
<p>Look at the following activation functions:</p>
<p><strong>A. Sigmoid activation function</strong> The sigmoid
activation function is given by: <span class="math display">\[ f(x) =
\frac{1}{1 + e^{-x}} \]</span></p>
<p><img src="fig/01_sigmoid.svg" style="width:70.0%" alt="Plot of the sigmoid function" align="left" class="figure"><br clear="all"></p>
<p><strong>B. ReLU activation function</strong> The Rectified Linear
Unit (ReLU) activation function is defined as: <span class="math display">\[ f(x) = \max(0, x) \]</span></p>
<p>This involves a simple comparison and maximum calculation, which are
basic operations that are computationally inexpensive. It is also simple
to compute the gradient: 1 for positive inputs and 0 for negative
inputs.</p>
<p><img src="fig/01_relu.svg" style="width:70.0%" alt="Plot of the ReLU function" align="left" class="figure"><br clear="all"></p>
<p><strong>C. Linear (or identity) activation function
(output=input)</strong> The linear activation function is simply the
identity function: <span class="math display">\[ f(x) = x \]</span></p>
<p><img src="fig/01_identity_function.svg" style="width:70.0%" alt="Plot of the Identity function" align="left" class="figure"><br clear="all"></p>
<p>Combine the following statements to the correct activation
function:</p>
<ol style="list-style-type: decimal">
<li>This function enforces the activation of a neuron to be between 0
and 1</li>
<li>This function is useful in regression tasks when applied to an
output neuron</li>
<li>This function is the most popular activation function in hidden
layers, since it introduces non-linearity in a computationally efficient
way.</li>
<li>This function is useful in classification tasks when applied to an
output neuron</li>
<li>(optional) For positive values this function results in the same
activations as the identity function.</li>
<li>(optional) This function is not differentiable at 0</li>
<li>(optional) This function is the default for Dense layers (search the
Keras documentation!)</li>
</ol>
<p><em>Activation function plots by Laughsinthestocks - Own work, CC
BY-SA 4.0, <a href="https://commons.wikimedia.org/w/index.php?curid=44920411" class="external-link uri">https://commons.wikimedia.org/w/index.php?curid=44920411</a>,
<a href="https://commons.wikimedia.org/w/index.php?curid=44920600" class="external-link uri">https://commons.wikimedia.org/w/index.php?curid=44920600</a>,
<a href="https://commons.wikimedia.org/w/index.php?curid=44920533" class="external-link uri">https://commons.wikimedia.org/w/index.php?curid=44920533</a></em></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>A</li>
<li>C</li>
<li>B</li>
<li>A</li>
<li>B</li>
<li>B</li>
<li>C</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="combining-multiple-neurons-into-a-network">Combining multiple neurons into a network<a class="anchor" aria-label="anchor" href="#combining-multiple-neurons-into-a-network"></a>
</h5>
<p>Multiple neurons can be joined together by connecting the output of
one to the input of another. These connections are associated with
weights that determine the ‘strength’ of the connection, the weights are
adjusted during training. In this way, the combination of neurons and
connections describe a computational graph, an example can be seen in
the image below.</p>
<p>In most neural networks, neurons are aggregated into layers. Signals
travel from the input layer to the output layer, possibly through one or
more intermediate layers called hidden layers. The image below shows an
example of a neural network with three layers, each circle is a neuron,
each line is an edge and the arrows indicate the direction data moves
in.</p>
<figure><img src="fig/01_neural_net.png" alt="A diagram of a three layer neural network with an input layer, one hidden layer, and an output layer." class="figure mx-auto d-block"><div class="figcaption">Image credit: Glosser.ca, CC BY-SA 3.0 <a href="https://creativecommons.org/licenses/by-sa/3.0" class="external-link uri">https://creativecommons.org/licenses/by-sa/3.0</a>, via
Wikimedia Commons, <a href="https://commons.wikimedia.org/wiki/File:Colored_neural_network.svg" class="external-link">original
source</a>
</div>
</figure><div id="neural-network-calculations" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="neural-network-calculations" class="callout-inner">
<h3 class="callout-title">Neural network calculations</h3>
<div class="callout-content">
<p>.</p>
<div class="section level4">
<h4 id="calculate-the-output-for-one-neuron">1. Calculate the output for one neuron<a class="anchor" aria-label="anchor" href="#calculate-the-output-for-one-neuron"></a>
</h4>
<p>Suppose we have:</p>
<ul>
<li>Input: X = (0, 0.5, 1)</li>
<li>Weights: W = (-1, -0.5, 0.5)</li>
<li>Bias: b = 1</li>
<li>Activation function <em>relu</em>:
<code>f(x) = max(x, 0)</code>
</li>
</ul>
<p>What is the output of the neuron?</p>
<p><em>Note: You can use whatever you like: brain only, pen&amp;paper,
Python, Excel…</em></p>
</div>
<div class="section level4">
<h4 id="optional-calculate-outputs-for-a-network">2. (optional) Calculate outputs for a network<a class="anchor" aria-label="anchor" href="#optional-calculate-outputs-for-a-network"></a>
</h4>
<p>Have a look at the following network where:</p>
<ul>
<li>
<span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> denote the two inputs of the
network.</li>
<li>
<span class="math inline">\(h_1\)</span> and <span class="math inline">\(h_2\)</span> denote the two neurons in the hidden
layer. They both have ReLU activation functions.</li>
<li>
<span class="math inline">\(h_1\)</span> and <span class="math inline">\(h_2\)</span> denotes the output neuron. It has a
ReLU activation function.</li>
<li>The value on the arrows represent the weight associated to that
input to the neuron.</li>
<li>
<span class="math inline">\(b_i\)</span> denotes the bias term of
that specific neuron <img src="fig/01_xor_exercise.png" alt="A diagram of a neural network with 2 inputs, 2 hidden layer neurons, and 1 output." width="400" class="figure">
</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Calculate the output of the network for the following combinations
of inputs:</li>
</ol>
<table class="table">
<thead><tr class="header">
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>..</td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td>..</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0</td>
<td>..</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>..</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>What logical problem does this network solve?</li>
</ol>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="section level4">
<h4 id="calculate-the-output-for-one-neuron-1">1: calculate the output for one neuron<a class="anchor" aria-label="anchor" href="#calculate-the-output-for-one-neuron-1"></a>
</h4>
<p>You can calculate the output as follows:</p>
<ul>
<li>Weighted sum of input:
<code>0 * (-1) + 0.5 * (-0.5) + 1 * 0.5 = 0.25</code>
</li>
<li>Add the bias: <code>0.25 + 1 = 1.25</code>
</li>
<li>Apply activation function: <code>max(1.25, 0) = 1.25</code>
</li>
</ul>
<p>So, the neuron’s output is <code>1.25</code></p>
</div>
<div class="section level4">
<h4 id="calculate-outputs-for-a-network">2: Calculate outputs for a network<a class="anchor" aria-label="anchor" href="#calculate-outputs-for-a-network"></a>
</h4>
<ol style="list-style-type: lower-alpha">
<li><table class="table">
<thead><tr class="header">
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0</td>
<td><strong>0</strong></td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td><strong>1</strong></td>
</tr>
<tr class="odd">
<td>1</td>
<td>1</td>
<td><strong>0</strong></td>
</tr>
<tr class="even">
<td>1</td>
<td>0</td>
<td><strong>1</strong></td>
</tr>
</tbody>
</table></li>
<li>This solves the XOR logical problem, the output is 1 if only one of
the two inputs is 1.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="what-makes-deep-learning-deep-learning">What makes deep learning deep learning?<a class="anchor" aria-label="anchor" href="#what-makes-deep-learning-deep-learning"></a>
</h5>
<p>Neural networks are not a new technique, they have been around since
the late 1940s. But until around 2010 neural networks tended to be quite
small, consisting of only 10s or perhaps 100s of neurons. This limited
them to only solving quite basic problems. Around 2010, improvements in
computing power and the algorithms for training the networks made much
larger and more powerful networks practical. These are known as deep
neural networks or deep learning.</p>
<p>Deep learning requires extensive training using example data which
shows the network what output it should produce for a given input. One
common application of deep learning is <a href="https://glosario.carpentries.org/en/#classification" class="external-link">classifying</a>
images. Here the network will be trained by being “shown” a series of
images and told what they contain. Once the network is trained it should
be able to take another image and correctly classify its contents.</p>
<p>But we are not restricted to just using images, any kind of data can
be learned by a deep learning neural network. This makes them able to
appear to learn a set of complex rules only by being shown what the
inputs and outputs of those rules are instead of being taught the actual
rules. Using these approaches, deep learning networks have been taught
to play video games and even drive cars.</p>
<p>The data on which networks are trained usually has to be quite
extensive, typically including thousands of examples. For this reason
they are not suited to all applications and should be considered just
one of many machine learning techniques which are available.</p>
<p>While traditional “shallow” networks might have had between three and
five layers, deep networks often have tens or even hundreds of layers.
This leads to them having millions of individual weights. The image
below shows a diagram of all the layers on a deep learning network
designed to detect pedestrians in images.</p>
<p>This image is from the paper <a href="https://doi.org/10.1155/2018/3518959" class="external-link">“An Efficient Pedestrian
Detection Method Based on YOLOv2” by Zhongmin Liu, Zhicai Chen, Zhanming
Li, and Wenjin Hu published in Mathematical Problems in Engineering,
Volume 2018</a></p>
<figure><img src="fig/01_deep_network.png" alt="An example of a deep neural network" class="figure mx-auto d-block"><div class="figcaption">
<strong>A visual representation of a deep neural
network used to detect pedestrians in images.</strong> There are too
many neurons to draw all of them, so each layer is represented by a
panel, with values indicating how many neurons are in each dimension of
the layer. Note that this model has 3-dimensional layers instead of the
1-dimensional layers that we introduced before. The input (left most)
layer of the network is an image of 448 x 448 pixels and 3 RGB channels.
The final (right most) layer of the network outputs a zero or one to
determine if the input data belongs to the class of data we are
interested in. The output of the previous layer is the input to the next
layer. Note that the color coding refers to different layer types that
will be introduced one by one as we proceed in this lesson.</div>
</figure>
</div>
</div>
</div>
<div class="section level3">
<h3 id="how-do-neural-networks-learn">How do neural networks learn?<a class="anchor" aria-label="anchor" href="#how-do-neural-networks-learn"></a>
</h3>
<p>What happens in a neural network during the training process? The
ultimate goal is of course to find a model that makes predictions that
are as close to the target value as possible. In other words, the goal
of training is to find the best set of parameters (weights and biases)
that bring the error between prediction and expected value to a minimum.
The total error between prediction and expected value is quantified in a
loss function (also called cost function). There are lots of loss
functions to pick from, and it is important that you pick one that
matches your problem definition well. We will look at an example of a
loss function in the next exercise.</p>

<div id="compute-the-mean-squared-error" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="compute-the-mean-squared-error" class="callout-inner">
<h3 class="callout-title">1. Compute the Mean Squared Error</h3>
<div class="callout-content">
<p>One of the simplest loss functions is the Mean Squared Error. MSE =
<span class="math inline">\(\frac{1}{n}
\Sigma_{i=1}^n({y}-\hat{y})^2\)</span> . It is the mean of all squared
errors, where the error is the difference between the predicted and
expected value. In the following table, fill in the missing values in
the ‘squared error’ column. What is the MSE loss for the predictions on
these 4 samples?</p>
<table class="table">
<thead><tr class="header">
<th><strong>Prediction</strong></th>
<th><strong>Expected value</strong></th>
<th><strong>Squared error</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>4</td>
</tr>
<tr class="even">
<td>2</td>
<td>-1</td>
<td>..</td>
</tr>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>..</td>
</tr>
<tr class="even">
<td>3</td>
<td>2</td>
<td>..</td>
</tr>
<tr class="odd">
<td></td>
<td><strong>MSE:</strong></td>
<td>..</td>
</tr>
</tbody>
</table>
<div class="section level4">
<h4 id="optional-huber-loss">2. (optional) Huber loss<a class="anchor" aria-label="anchor" href="#optional-huber-loss"></a>
</h4>
<p>A more complicated and less used loss function for regression is the
<a href="https://keras.io/api/losses/regression_losses/#huber-class" class="external-link">Huber
loss</a>.</p>
<p>Below you see the Huber loss (green, delta = 1) and Squared error
loss (blue) as a function of <code>y_true - y_pred</code>.</p>
<figure><img src="fig/01_huber_loss.png" alt="Line plot comparing squared error loss function with the Huber loss function where delta = 1, showing the cost of prediction error of both functions equal where y_true - y_pred is between -1 and 1, then rising linearly with the Huber loss function as y_true diverges further from y_pred, as opposed to expontentially for the squared error function." width="400" class="figure mx-auto d-block"></figure><p>Which loss function is more sensitive to outliers?</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<div class="section level4">
<h4 id="compute-the-mean-squared-error-1">1. ‘Compute the Mean Squared Error’<a class="anchor" aria-label="anchor" href="#compute-the-mean-squared-error-1"></a>
</h4>
<table class="table">
<thead><tr class="header">
<th><strong>Prediction</strong></th>
<th><strong>Expected value</strong></th>
<th><strong>Squared error</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>4</td>
</tr>
<tr class="even">
<td>2</td>
<td>-1</td>
<td>9</td>
</tr>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="odd">
<td></td>
<td><strong>MSE:</strong></td>
<td>3.5</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="huber-loss">2. ‘Huber loss’<a class="anchor" aria-label="anchor" href="#huber-loss"></a>
</h4>
<p>The squared error loss is more sensitive to outliers. Errors between
-1 and 1 result in the same loss value for both loss functions. But,
larger errors (in other words: outliers) result in quadratically larger
losses for the Mean Squared Error, while for the Huber loss they only
increase linearly.</p>
</div>
</div>
</div>
</div>
</div>
<p>So, a loss function quantifies the total error of the model. The
process of adjusting the weights in such a way as to minimize the loss
function is called ‘optimization’. We will dive further into how
optimization works in episode 3. For now, it is enough to understand
that during training the weights in the network are adjusted so that the
loss decreases through the process of optimization. This ultimately
results in a low loss, and this, generally, implies predictions that are
closer to the expected values.</p>

</div>
<div class="section level3">
<h3 id="what-sort-of-problems-can-deep-learning-solve">What sort of problems can deep learning solve?<a class="anchor" aria-label="anchor" href="#what-sort-of-problems-can-deep-learning-solve"></a>
</h3>
<ul>
<li>Pattern/object recognition</li>
<li>Segmenting images (or any data)</li>
<li>Translating between one set of data and another, for example natural
language translation.</li>
<li>Generating new data that looks similar to the training data, often
used to create synthetic datasets, art or even “deepfake” videos.
<ul>
<li>This can also be used to give the illusion of enhancing data, for
example making images look sharper, video look smoother or adding colour
to black and white images. But beware of this, it is not an accurate
recreation of the original data, but a recreation based on something
statistically similar, effectively a digital imagination of what that
data could look like.</li>
</ul>
</li>
</ul>
<div class="section level4">
<h4 id="examples-of-deep-learning-in-research">Examples of Deep Learning in Research<a class="anchor" aria-label="anchor" href="#examples-of-deep-learning-in-research"></a>
</h4>
<p>Here are just a few examples of how deep learning has been applied to
some research problems. Note: some of these articles might be behind
paywalls.</p>
<ul>
<li><a href="https://arxiv.org/abs/2003.09871" class="external-link">Detecting COVID-19 in
chest X-ray images</a></li>
<li><a href="https://arxiv.org/abs/1610.09460" class="external-link">Forecasting building
energy load</a></li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/29039790/" class="external-link">Protein function
prediction</a></li>
<li><a href="https://pubs.rsc.org/en/content/articlelanding/2018/sc/c7sc04934j" class="external-link">Simulating
Chemical Processes</a></li>
<li><a href="https://heritagesciencejournal.springeropen.com/articles/10.1186/s40494-020-0355-x" class="external-link">Help
to restore ancient murals</a></li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="what-sort-of-problems-can-deep-learning-not-solve">What sort of problems can deep learning not solve?<a class="anchor" aria-label="anchor" href="#what-sort-of-problems-can-deep-learning-not-solve"></a>
</h3>
<ul>
<li>Any case where only a small amount of training data is
available.</li>
<li>Tasks requiring an explanation of how the answer was arrived
at.</li>
<li>Classifying things which are nothing like their training data.</li>
</ul>
</div>
<div class="section level3">
<h3 id="what-sort-of-problems-can-deep-learning-solve-but-should-not-be-used-for">What sort of problems can deep learning solve, but should not be
used for?<a class="anchor" aria-label="anchor" href="#what-sort-of-problems-can-deep-learning-solve-but-should-not-be-used-for"></a>
</h3>
<p>Deep learning needs a lot of computational power, for this reason it
often relies on specialised hardware like <a href="https://glosario.carpentries.org/en/#gpu" class="external-link">graphical processing
units (GPUs)</a>. Many computational problems can be solved using less
intensive techniques, but could still technically be solved with deep
learning.</p>
<p>The following could technically be achieved using deep learning, but
it would probably be a very wasteful way to do it:</p>
<ul>
<li>Logic operations, such as computing totals, averages, ranges etc.
(see <a href="https://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow" class="external-link">this
example</a> applying deep learning to solve the <a href="https://en.wikipedia.org/wiki/Fizz_buzz" class="external-link">“FizzBuzz” problem</a>
often used for programming interviews)</li>
<li>Modelling well defined systems, where the equations governing them
are known and understood.</li>
<li>Basic computer vision tasks such as <a href="https://en.wikipedia.org/wiki/Edge_detection" class="external-link">edge detection</a>,
decreasing colour depth or blurring an image.</li>
</ul>
<div id="deep-learning-problems-exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="deep-learning-problems-exercise" class="callout-inner">
<h3 class="callout-title">Deep Learning Problems Exercise</h3>
<div class="callout-content">
<p>Which of the following would you apply deep learning to?</p>
<ol style="list-style-type: decimal">
<li>Recognising whether or not a picture contains a bird.</li>
<li>Calculating the median and interquartile range of a dataset.</li>
<li>Identifying MRI images of a rare disease when only one or two
example images available for training.</li>
<li>Identifying people in pictures after being trained only on cats and
dogs.</li>
<li>Translating English into French.</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>and 5 are the sort of tasks often solved with deep learning.</li>
<li>is technically possible but solving this with deep learning would be
extremely wasteful, you could do the same with much less computing power
using traditional techniques.</li>
<li>will probably fail because there is not enough training data.</li>
<li>will fail because the deep learning system only knows what cats and
dogs look like, it might accidentally classify the people as cats or
dogs.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="how-much-data-do-you-need-for-deep-learning">How much data do you need for deep learning?<a class="anchor" aria-label="anchor" href="#how-much-data-do-you-need-for-deep-learning"></a>
</h2>
<hr class="half-width">
<p>The rise of deep learning is partially due to the increased
availability of very large datasets. But how much data do you actually
need to train a deep learning model? Unfortunately, this question is not
easy to answer. It depends, among other things, on the complexity of the
task (which you often do not know beforehand), the quality of the
available dataset and the complexity of the network. For complex tasks
with large neural networks, we often see that adding more data continues
to improve performance. However, this is also not a generic truth: if
the data you add is too similar to the data you already have, it will
not give much new information to the neural network.</p>
<div id="what-if-i-do-not-have-enough-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="what-if-i-do-not-have-enough-data" class="callout-inner">
<h3 class="callout-title">What if I do not have enough data?</h3>
<div class="callout-content">
<p>In case you have too little data available to train a complex network
from scratch, it is sometimes possible to use a pretrained network that
was trained on a similar problem. Another trick is data augmentation,
where you expand the dataset with artificial data points that could be
real. An example of this is mirroring images when trying to classify
cats and dogs. An horizontally mirrored animal retains the label, but
exposes a different view.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="deep-learning-workflow">Deep learning workflow<a class="anchor" aria-label="anchor" href="#deep-learning-workflow"></a>
</h2>
<hr class="half-width">
<p>To apply deep learning to a problem there are several steps we need
to go through:</p>
<div class="section level3">
<h3 id="formulateoutline-the-problem">1. Formulate/Outline the problem<a class="anchor" aria-label="anchor" href="#formulateoutline-the-problem"></a>
</h3>
<p>Firstly we must decide what it is we want our deep learning system to
do. Is it going to classify some data into one of a few categories? For
example if we have an image of some hand written characters, the neural
network could classify which character it is being shown. Or is it going
to perform a prediction? For example trying to predict what the price of
something will be tomorrow given some historical data on pricing and
current trends.</p>
</div>
<div class="section level3">
<h3 id="identify-inputs-and-outputs">2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#identify-inputs-and-outputs"></a>
</h3>
<p>Next we need to identify what the inputs and outputs of the neural
network will be. This might require looking at our data and deciding
what features of the data we can use as inputs. If the data is images
then the inputs could be the individual pixels of the images.</p>
<p>For the outputs we will need to look at what we want to identify from
the data. If we are performing a classification problem then typically
we will have one output for each potential class.</p>
</div>
<div class="section level3">
<h3 id="prepare-data">3. Prepare data<a class="anchor" aria-label="anchor" href="#prepare-data"></a>
</h3>
<p>Many datasets are not ready for immediate use in a neural network and
will require some preparation. Neural networks can only really deal with
numerical data, so any non-numerical data (for example words) will have
to be somehow converted to numerical data.</p>
<p>Next we will need to divide the data into multiple sets. One of these
will be used by the training process and we will call it the training
set. Another will be used to evaluate the accuracy of the training and
we will call that one the test set. Sometimes we will also use a 3rd set
known as a validation set to refine the model.</p>
</div>
<div class="section level3">
<h3 id="choose-a-pre-trained-model-or-build-a-new-architecture-from-scratch">4. Choose a pre-trained model or build a new architecture from
scratch<a class="anchor" aria-label="anchor" href="#choose-a-pre-trained-model-or-build-a-new-architecture-from-scratch"></a>
</h3>
<p>Often we can use an existing neural network instead of designing one
from scratch. Training a network can take a lot of time and
computational resources. There are a number of well publicised networks
which have been shown to perform well at certain tasks, if you know of
one which already does a similar task well then it makes sense to use
one of these.</p>
<p>If instead we decide we do want to design our own network then we
need to think about how many input neurons it will have, how many hidden
layers and how many outputs, what types of layers we use (we will
explore the different types later on). This will probably need some
experimentation and we might have to try tweaking the network design a
few times before we see acceptable results.</p>
</div>
<div class="section level3">
<h3 id="choose-a-loss-function-and-optimizer">5. Choose a loss function and optimizer<a class="anchor" aria-label="anchor" href="#choose-a-loss-function-and-optimizer"></a>
</h3>
<p>The loss function tells the training algorithm how far away the
predicted value was from the true value. We will look at choosing a loss
function in more detail later on.</p>
<p>The optimizer is responsible for taking the output of the loss
function and then applying some changes to the weights within the
network. It is through this process that the “learning” (adjustment of
the weights) is achieved.</p>
</div>
<div class="section level3">
<h3 id="train-the-model">6. Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h3>
<p>We can now go ahead and start training our neural network. We will
probably keep doing this for a given number of iterations through our
training dataset (referred to as <em>epochs</em>) or until the loss
function gives a value under a certain threshold. The graph below show
the loss against the number of <em>epochs</em>, generally the loss will
go down with each <em>epoch</em>, but occasionally it will see a small
rise.</p>
<figure><img src="fig/training-0_to_1500.svg" alt="A graph showing an exponentially decreasing loss over the first 1500 epochs of training an example network." class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="perform-a-predictionclassification">7. Perform a Prediction/Classification<a class="anchor" aria-label="anchor" href="#perform-a-predictionclassification"></a>
</h3>
<p>After training the network we can use it to perform predictions. This
is the mode you would use the network in after you have fully trained it
to a satisfactory performance. Doing predictions on a special hold-out
set is used in the next step to measure the performance of the
network.</p>
</div>
<div class="section level3">
<h3 id="measure-performance">8. Measure Performance<a class="anchor" aria-label="anchor" href="#measure-performance"></a>
</h3>
<p>Once we trained the network we want to measure its performance. To do
this we use some additional data that was not part of the training, this
is known as a test set. There are many different methods available for
measuring performance and which one is best depends on the type of task
we are attempting. These metrics are often published as an indication of
how well our network performs.</p>
</div>
<div class="section level3">
<h3 id="refine-the-model">9. Refine the model<a class="anchor" aria-label="anchor" href="#refine-the-model"></a>
</h3>
<p>We refine the model further. We can for example slightly change the
architecture of the model, or change the number of nodes in a layer.
Hyperparameters are all the parameters set by the person configuring the
machine learning instead of those learned by the algorithm itself. The
hyperparameters include the number of epochs or the parameters for the
optimizer. It might be necessary to adjust these and re-run the training
many times before we are happy with the result, this is often done
automatically and that is referred to as hyperparameter tuning.</p>
</div>
<div class="section level3">
<h3 id="share-model">10. Share Model<a class="anchor" aria-label="anchor" href="#share-model"></a>
</h3>
<p>Now that we have a trained network that performs at a level we are
happy with we can go and use it on real data to perform a prediction. At
this point we might want to consider publishing a file with both the
architecture of our network and the weights which it has learned
(assuming we did not use a pre-trained network). This will allow others
to use it as as pre-trained network for their own purposes and for them
to (mostly) reproduce our result.</p>
<div id="deep-learning-workflow-exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="deep-learning-workflow-exercise" class="callout-inner">
<h3 class="callout-title">Deep learning workflow exercise</h3>
<div class="callout-content">
<p>Think about a problem you would like to use deep learning to
solve.</p>
<ol style="list-style-type: decimal">
<li>What do you want a deep learning system to be able to tell you?</li>
<li>What data inputs and outputs will you have?</li>
<li>Do you think you will need to train the network or will a
pre-trained network be suitable?</li>
<li>What data do you have to train with? What preparation will your data
need? Consider both the data you are going to predict/classify from and
the data you will use to train the network.</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>Discuss your answers with the group or the person next to you.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="deep-learning-libraries">Deep Learning Libraries<a class="anchor" aria-label="anchor" href="#deep-learning-libraries"></a>
</h2>
<hr class="half-width">
<p>There are many software libraries available for deep learning
including:</p>
<div class="section level3">
<h3 id="tensorflow">TensorFlow<a class="anchor" aria-label="anchor" href="#tensorflow"></a>
</h3>
<p><a href="https://www.tensorflow.org/" class="external-link">TensorFlow</a> was developed by
Google and is one of the older deep learning libraries, ported across
many languages since it was first released to the public in 2015. It is
very versatile and capable of much more than deep learning but as a
result it often takes a lot more lines of code to write deep learning
operations in TensorFlow than in other libraries. It offers (almost)
seamless integration with GPU accelerators and Google’s own TPU (Tensor
Processing Unit) chips that are built specially for machine
learning.</p>
</div>
<div class="section level3">
<h3 id="pytorch">PyTorch<a class="anchor" aria-label="anchor" href="#pytorch"></a>
</h3>
<p><a href="https://pytorch.org/" class="external-link">PyTorch</a> was developed by Facebook
in 2016 and is a popular choice for deep learning applications. It was
developed for Python from the start and feels a lot more “pythonic” than
TensorFlow. Like TensorFlow it was designed to do more than just deep
learning and offers some very low level interfaces. <a href="https://www.pytorchlightning.ai/" class="external-link">PyTorch Lightning</a> offers a
higher level interface to PyTorch to set up experiments. Like TensorFlow
it is also very easy to integrate PyTorch with a GPU. In many benchmarks
it outperforms the other libraries.</p>
</div>
<div class="section level3">
<h3 id="keras">Keras<a class="anchor" aria-label="anchor" href="#keras"></a>
</h3>
<p><a href="https://keras.io/" class="external-link">Keras</a> is designed to be easy to use
and usually requires fewer lines of code than other libraries. We have
chosen it for this lesson for that reason. Keras can actually work on
top of TensorFlow (and several other libraries), hiding away the
complexities of TensorFlow while still allowing you to make use of their
features.</p>
<p>The processing speed of Keras is sometimes not as high as with other
libraries and if you are going to move on to create very large networks
using very large datasets then you might want to consider one of the
other libraries. But for many applications, the difference will not be
enough to worry about and the time you will save with simpler code will
exceed what you will save by having the code run a little faster.</p>
<p>Keras also benefits from a very good set of <a href="https://keras.io/guides/" class="external-link">online documentation</a> and a large
user community. You will find that most of the concepts from Keras
translate very well across to the other libraries if you wish to learn
them at a later date.</p>
</div>
<div class="section level3">
<h3 id="installing-keras-and-other-dependencies">Installing Keras and other dependencies<a class="anchor" aria-label="anchor" href="#installing-keras-and-other-dependencies"></a>
</h3>
<p>Follow the <a href="index.html#packages">setup instructions</a> to
install Keras, Seaborn and scikit-learn.</p>
</div>
</section><section><h2 class="section-heading" id="testing-keras-installation">Testing Keras Installation<a class="anchor" aria-label="anchor" href="#testing-keras-installation"></a>
</h2>
<hr class="half-width">
<p>Keras is available as a module within TensorFlow, as described in the
<a href="index.html#packages">setup instructions</a>. Let’s therefore
check whether you have a suitable version of TensorFlow installed. Open
up a new Jupyter notebook or interactive python console and run the
following commands:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> tensorflow</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="bu">print</span>(tensorflow.__version__)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>2.17.0</code></pre>
</div>
<p>You should get a version number reported. At the time of writing
2.17.0 is the latest version.</p>
</section><section><h2 class="section-heading" id="testing-seaborn-installation">Testing Seaborn Installation<a class="anchor" aria-label="anchor" href="#testing-seaborn-installation"></a>
</h2>
<hr class="half-width">
<p>Lets check you have a suitable version of seaborn installed. In your
Jupyter notebook or interactive python console run the following
commands:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> seaborn</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="bu">print</span>(seaborn.__version__)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0.13.2</code></pre>
</div>
<p>You should get a version number reported. At the time of writing
0.13.2 is the latest version.</p>
</section><section><h2 class="section-heading" id="testing-scikit-learn-installation">Testing scikit-learn Installation<a class="anchor" aria-label="anchor" href="#testing-scikit-learn-installation"></a>
</h2>
<hr class="half-width">
<p>Lets check you have a suitable version of scikit-learn installed. In
your Jupyter notebook or interactive python console run the following
commands:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="bu">print</span>(sklearn.__version__)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1.5.1</code></pre>
</div>
<p>You should get a version number reported. At the time of writing
1.5.1 is the latest version.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Machine learning is the process where computers learn to recognise
patterns of data.</li>
<li>Artificial neural networks are a machine learning technique based on
a model inspired by groups of neurons in the brain.</li>
<li>Artificial neural networks can be trained on example data.</li>
<li>Deep learning is a machine learning technique based on using many
artificial neurons arranged in layers.</li>
<li>Neural networks learn by minimizing a loss function.</li>
<li>Deep learning is well suited to classification and prediction
problems such as image recognition.</li>
<li>To use deep learning effectively we need to go through a workflow
of: defining the problem, identifying inputs and outputs, preparing
data, choosing the type of network, choosing a loss function, training
the model, refine the model, measuring performance before we can
classify data.</li>
<li>Keras is a deep learning library that is easier to use than many of
the alternatives such as TensorFlow and PyTorch.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-2-keras"><p>Content from <a href="2-keras.html">Classification by a neural network using Keras</a></p>
<hr>
<p>Last updated on 2025-09-03 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/2-keras.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I compose a neural network using Keras?</li>
<li>How do I train this network on a dataset?</li>
<li>How do I get insight into learning process?</li>
<li>How do I measure the performance of the network?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use the deep learning workflow to structure the notebook</li>
<li>Explore the dataset using pandas and seaborn</li>
<li>Identify the inputs and outputs of a deep neural network.</li>
<li>Use one-hot encoding to prepare data for classification in
Keras</li>
<li>Describe a fully connected layer</li>
<li>Implement a fully connected layer with Keras</li>
<li>Use Keras to train a small fully connected network on prepared
data</li>
<li>Interpret the loss curve of the training process</li>
<li>Use a confusion matrix to measure the trained networks’ performance
on a test set</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>In this episode we will learn how to create and train a neural
network using Keras to solve a simple classification task.</p>
<p>The goal of this episode is to quickly get your hands dirty in
actually defining and training a neural network, without going into
depth of how neural networks work on a technical or mathematical level.
We want you to go through the full deep learning workflow once before
going into more details.</p>
<p>In fact, this is also what we would recommend you to do when working
on real-world problems: First quickly build a working pipeline, while
taking shortcuts. Then, slowly make the pipeline more advanced while you
keep on evaluating the approach.</p>
<p>In <a href="3-monitor-the-model.html">episode 3</a> we will expand on
the concepts that are lightly introduced in this episode. Some of these
concepts include: how to monitor the training progress and how
optimization works.</p>

<p>As a reminder below are the steps of the deep learning workflow:</p>
<ol style="list-style-type: decimal">
<li>Formulate / Outline the problem</li>
<li>Identify inputs and outputs</li>
<li>Prepare data</li>
<li>Choose a pretrained model or start building architecture from
scratch</li>
<li>Choose a loss function and optimizer</li>
<li>Train the model</li>
<li>Perform a Prediction/Classification</li>
<li>Measure performance</li>
<li>Refine the model</li>
<li>Save model</li>
</ol>
<p>In this episode we will focus on a minimal example for each of these
steps, later episodes will build on this knowledge to go into greater
depth for some or all of these steps.</p>
<div id="gpu-usage" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="gpu-usage" class="callout-inner">
<h3 class="callout-title">GPU usage</h3>
<div class="callout-content">
<p>For this lesson having a <a href="https://glosario.carpentries.org/en/#gpu" class="external-link">GPU (graphics processing
unit)</a> available is not needed. We specifically use very small toy
problems so that you do not need one. However, Keras will use your GPU
automatically when it is available. Using a GPU becomes necessary when
tackling larger datasets or complex problems which require a more
complex neural network.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="formulateoutline-the-problem-penguin-classification">1. Formulate/outline the problem: penguin classification<a class="anchor" aria-label="anchor" href="#formulateoutline-the-problem-penguin-classification"></a>
</h2>
<hr class="half-width">
<p>In this episode we will be using the <a href="https://zenodo.org/record/3960218" class="external-link">penguin dataset</a>. This is a
dataset that was published in 2020 by Allison Horst and contains data on
three different species of the penguins.</p>
<p>We will use the penguin dataset to train a neural network which can
classify which species a penguin belongs to, based on their physical
characteristics.</p>
<div id="goal" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="goal" class="callout-inner">
<h3 class="callout-title">Goal</h3>
<div class="callout-content">
<p>The goal is to predict a penguins’ species using the attributes
available in this dataset.</p>
</div>
</div>
</div>
<p>The <code>palmerpenguins</code> data contains size measurements for
three penguin species observed on three islands in the Palmer
Archipelago, Antarctica. The physical attributes measured are flipper
length, beak length, beak width, body mass, and sex.</p>
<figure><img src="fig/palmer_penguins.png" title="Palmer Penguins" alt="Illustration of the three species of penguins found in the Palmer Archipelago, Antarctica: Chinstrap, Gentoo and Adele" class="figure mx-auto d-block"><div class="figcaption"><em>Artwork by <span class="citation">@allison_horst</span></em></div>
</figure><figure><img src="fig/culmen_depth.png" title="Culmen Depth" alt='Illustration of how the beak dimensions were measured. In the raw data, bill dimensions are recorded as "culmen length" and "culmen depth". The culmen is the dorsal ridge atop the bill.' class="figure mx-auto d-block"><div class="figcaption"><em>Artwork by <span class="citation">@allison_horst</span></em></div>
</figure><p>These data were collected from 2007 - 2009 by Dr. Kristen Gorman with
the <a href="https://lternet.edu/site/palmer-antarctica-lter/" class="external-link">Palmer
Station Long Term Ecological Research Program</a>, part of the <a href="https://lternet.edu/" class="external-link">US Long Term Ecological Research
Network</a>. The data were imported directly from the <a href="https://edirepository.org/" class="external-link">Environmental Data Initiative</a>
(EDI) Data Portal, and are available for use by CC0 license (“No Rights
Reserved”) in accordance with the <a href="https://lternet.edu/data-access-policy/" class="external-link">Palmer Station Data
Policy</a>.</p>
</section><section><h2 class="section-heading" id="identify-inputs-and-outputs">2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#identify-inputs-and-outputs"></a>
</h2>
<hr class="half-width">
<p>To identify the inputs and outputs that we will use to design the
neural network we need to familiarize ourselves with the dataset. This
step is sometimes also called data exploration.</p>
<p>We will start by importing the <a href="https://seaborn.pydata.org/" class="external-link">Seaborn</a> library that will help us
get the dataset and visualize it. Seaborn is a powerful library with
many visualizations. Keep in mind it requires the data to be in a pandas
dataframe, luckily the datasets available in seaborn are already in a
pandas dataframe.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code></pre>
</div>
<p>We can load the penguin dataset using</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>)</span></code></pre>
</div>
<p>This will give you a pandas dataframe which contains the penguin
data.</p>
<div class="section level3">
<h3 id="inspecting-the-data">Inspecting the data<a class="anchor" aria-label="anchor" href="#inspecting-the-data"></a>
</h3>
<p>Using the pandas <code>head</code> function gives us a quick look at
the data:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>penguins.head()</span></code></pre>
</div>
<table style="width:100%;" class="table">
<colgroup>
<col width="6%">
<col width="14%">
<col width="13%">
<col width="17%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="11%">
</colgroup>
<thead><tr class="header">
<th align="right"></th>
<th align="right">species</th>
<th align="right">island</th>
<th align="right">bill_length_mm</th>
<th align="right">bill_depth_mm</th>
<th align="right">flipper_length_mm</th>
<th align="right">body_mass_g</th>
<th align="right">sex</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">Adelie</td>
<td align="right">Torgersen</td>
<td align="right">39.1</td>
<td align="right">18.7</td>
<td align="right">181.0</td>
<td align="right">3750.0</td>
<td align="right">Male</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">Adelie</td>
<td align="right">Torgersen</td>
<td align="right">39.5</td>
<td align="right">17.4</td>
<td align="right">186.0</td>
<td align="right">3800.0</td>
<td align="right">Female</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">Adelie</td>
<td align="right">Torgersen</td>
<td align="right">40.3</td>
<td align="right">18.0</td>
<td align="right">195.0</td>
<td align="right">3250.0</td>
<td align="right">Female</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">Adelie</td>
<td align="right">Torgersen</td>
<td align="right">NaN</td>
<td align="right">NaN</td>
<td align="right">NaN</td>
<td align="right">NaN</td>
<td align="right">NaN</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">Adelie</td>
<td align="right">Torgersen</td>
<td align="right">36.7</td>
<td align="right">19.3</td>
<td align="right">193.0</td>
<td align="right">3450.0</td>
<td align="right">Female</td>
</tr>
</tbody>
</table>
<p>We can use all columns as features to predict the species of the
penguin, except for the <code>species</code> column itself.</p>
<p>Let’s look at the shape of the dataset:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>penguins.shape</span></code></pre>
</div>
<p>There are 344 samples and 7 columns (plus the index column), so 6
features.</p>
</div>
<div class="section level3">
<h3 id="visualization">Visualization<a class="anchor" aria-label="anchor" href="#visualization"></a>
</h3>
<p>Looking at numbers like this usually does not give a very good
intuition about the data we are working with, so let us create a
visualization.</p>
<div class="section level4">
<h4 id="pair-plot">Pair Plot<a class="anchor" aria-label="anchor" href="#pair-plot"></a>
</h4>
<p>One nice visualization for datasets with relatively few attributes is
the Pair Plot. This can be created using <code>sns.pairplot(...)</code>.
It shows a scatterplot of each attribute plotted against each of the
other attributes. By using the <code>hue='species'</code> setting for
the pairplot the graphs on the diagonal are layered kernel density
estimate plots for the different values of the <code>species</code>
column.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>sns.pairplot(penguins, hue<span class="op">=</span><span class="st">"species"</span>)</span></code></pre>
</div>
<figure><img src="fig/pairplot.png" title="Pair Plot" alt="Grid of scatter plots and histograms comparing observed values of the four physicial attributes (features) measured in the penguins sampled. Scatter plots illustrate the distribution of values observed for each pair of features. On the diagonal, where one feature would be compared with itself, histograms are displayed that show the distribution of values observed for that feature, coloured according to the species of the individual sampled. The pair plot shows distinct but overlapping clusters of data points representing the different species, with no pair of features providing a clean separation of clusters on its own." class="figure mx-auto d-block"></figure><div id="pairplot" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="pairplot" class="callout-inner">
<h3 class="callout-title">Pairplot</h3>
<div class="callout-content">
<p>Take a look at the pairplot we created. Consider the following
questions:</p>
<ul>
<li>Is there any class that is easily distinguishable from the
others?</li>
<li>Which combination of attributes shows the best separation for all 3
class labels at once?</li>
<li>(optional) Create a similar pairplot, but with
<code>hue="sex"</code>. Explain the patterns you see. Which combination
of features distinguishes the two sexes best?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ul>
<li>The plots show that the green class, Gentoo is somewhat more easily
distinguishable from the other two.</li>
<li>The other two seem to be separable by a combination of bill length
and bill depth (other combinations are also possible such as bill length
and flipper length).</li>
</ul>
<p>Answer to optional question:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>sns.pairplot(penguins, hue<span class="op">=</span><span class="st">'sex'</span>)</span></code></pre>
</div>
<figure><img src="fig/02_sex_pairplot.png" title="Pair plot grouped by sex" alt="Grid of scatter plots and histograms comparing observed values of the four physicial attributes (features) measured in the penguins sampled, with data points coloured according to the sex of the individual sampled. The pair plot shows similarly-shaped distribution of values observed for each feature in male and female penguins, with the distribution of measurements for females skewed towards smaller values." class="figure mx-auto d-block"></figure><p>You see that for each species females have smaller bills and
flippers, as well as a smaller body mass. You would need a combination
of the species and the numerical features to successfully distinguish
males from females. The combination of <code>bill_depth_mm</code> and
<code>body_mass_g</code> gives the best separation.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="input-and-output-selection">Input and Output Selection<a class="anchor" aria-label="anchor" href="#input-and-output-selection"></a>
</h3>
<p>Now that we have familiarized ourselves with the dataset we can
select the data attributes to use as input for the neural network and
the target that we want to predict.</p>
<p>In the rest of this episode we will use the
<code>bill_length_mm</code>, <code>bill_depth_mm</code>,
<code>flipper_length_mm</code>, <code>body_mass_g</code> attributes. The
target for the classification task will be the <code>species</code>.</p>
<div id="data-exploration" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="data-exploration" class="callout-inner">
<h3 class="callout-title">Data Exploration</h3>
<div class="callout-content">
<p>Exploring the data is an important step to familiarize yourself with
the problem and to help you determine the relevant inputs and
outputs.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="prepare-data">3. Prepare data<a class="anchor" aria-label="anchor" href="#prepare-data"></a>
</h2>
<hr class="half-width">
<p>The input data and target data are not yet in a format that is
suitable to use for training a neural network.</p>
<p>For now we will only use the numerical features
<code>bill_length_mm</code>, <code>bill_depth_mm</code>,
<code>flipper_length_mm</code>, <code>body_mass_g</code> only, so let’s
drop the categorical columns:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Drop categorical columns</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>penguins_filtered <span class="op">=</span> penguins.drop(columns<span class="op">=</span>[<span class="st">'island'</span>, <span class="st">'sex'</span>])</span></code></pre>
</div>
<div class="section level3">
<h3 id="clean-missing-values">Clean missing values<a class="anchor" aria-label="anchor" href="#clean-missing-values"></a>
</h3>
<p>During the exploration phase you may have noticed that some rows in
the dataset have missing (NaN) values, leaving such values in the input
data will ruin the training, so we need to deal with them. There are
many ways to deal with missing values, but for now we will just remove
the offending rows by adding a call to <code>dropna()</code>:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Drop the rows that have NaN values in them</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>penguins_filtered <span class="op">=</span> penguins_filtered.dropna()</span></code></pre>
</div>
<p>Finally, we select only the features</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Extract columns corresponding to features</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>features <span class="op">=</span> penguins_filtered.drop(columns<span class="op">=</span>[<span class="st">'species'</span>])</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="prepare-target-data-for-training">Prepare target data for training<a class="anchor" aria-label="anchor" href="#prepare-target-data-for-training"></a>
</h3>
<p>Second, the target data is also in a format that cannot be used in
training. A neural network can only take numerical inputs and outputs,
and learns by calculating how “far away” the species predicted by the
neural network is from the true species.</p>
<p>When the target is a string category column as we have here, we need
to transform this column into a numerical format first. Again, there are
many ways to do this. We will be using the one-hot encoding. This
encoding creates multiple columns, as many as there are unique values,
and puts a 1 in the column with the corresponding correct class, and 0’s
in the other columns. For instance, for a penguin of the Adelie species
the one-hot encoding would be 1 0 0.</p>
<p>Fortunately, Pandas is able to generate this encoding for us.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>target <span class="op">=</span> pd.get_dummies(penguins_filtered[<span class="st">'species'</span>])</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>target.head() <span class="co"># print out the top 5 to see what it looks like.</span></span></code></pre>
</div>
<div id="one-hot-encoding" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="one-hot-encoding" class="callout-inner">
<h3 class="callout-title">One-hot encoding</h3>
<div class="callout-content">
<p>How many output neurons will our network have now that we one-hot
encoded the target class?</p>
<ul>
<li>A: 1</li>
<li>B: 2</li>
<li>C: 3</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>C: 3, one for each output variable class</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="split-data-into-training-and-test-set">Split data into training and test set<a class="anchor" aria-label="anchor" href="#split-data-into-training-and-test-set"></a>
</h3>
<p>Finally, we will split the dataset into a training set and a test
set. As the names imply we will use the training set to train the neural
network, while the test set is kept separate. We will use the test set
to assess the performance of the trained neural network on unseen
samples. In many cases a validation set is also kept separate from the
training and test sets (i.e. the dataset is split into 3 parts). This
validation set is then used to select the values of the parameters of
the neural network and the training methods. For this episode we will
keep it at just a training and test set however.</p>
<p>To split the cleaned dataset into a training and test set we will use
a very convenient function from sklearn called
<code>train_test_split</code>.</p>
<p>This function takes a number of parameters which are extensively
explained in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" class="external-link">the
scikit-learn documentation</a> :</p>
<ul>
<li>The first two parameters are the dataset (in our case
<code>features</code>) and the corresponding targets (i.e. defined as
target).</li>
<li>Next is the named parameter <code>test_size</code> this is the
fraction of the dataset that is used for testing, in this case
<code>0.2</code> means 20% of the data will be used for testing.</li>
<li>
<code>random_state</code> controls the shuffling of the dataset,
setting this value will reproduce the same results (assuming you give
the same integer) every time it is called.</li>
<li>
<code>shuffle</code> which can be either <code>True</code> or
<code>False</code>, it controls whether the order of the rows of the
dataset is shuffled before splitting. It defaults to
<code>True</code>.</li>
<li>
<code>stratify</code> is a more advanced parameter that controls how
the split is done. By setting it to <code>target</code> the train and
test sets the function will return will have roughly the same
proportions (with regards to the number of penguins of a certain
species) as the dataset.</li>
</ul>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(features, target, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>, shuffle<span class="op">=</span><span class="va">True</span>, stratify<span class="op">=</span>target)</span></code></pre>
</div>
<div id="importance-of-using-the-same-train-test-split" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="importance-of-using-the-same-train-test-split" class="callout-inner">
<h3 class="callout-title">Importance of using the same train-test
split</h3>
<div class="callout-content">
<p>By setting <code>random_state=0</code> we ensure that everyone has
the same train-test split. When doing machine learning and deep learning
it is crucial that you use the same train and test dataset for different
experiments. Comparing evaluation metrics between experiments run on
different data splits is meaningless, because the accuracy of a model
depends on the data used to train and test it.</p>
</div>
</div>
</div>

</div>
</section><section><h2 class="section-heading" id="build-an-architecture-from-scratch">4. Build an architecture from scratch<a class="anchor" aria-label="anchor" href="#build-an-architecture-from-scratch"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="keras-for-neural-networks">Keras for neural networks<a class="anchor" aria-label="anchor" href="#keras-for-neural-networks"></a>
</h3>
<p>Keras is a machine learning framework with ease of use as one of its
main features. It is part of the tensorflow python package and can be
imported using <code>from tensorflow import keras</code>.</p>
<p>Keras includes functions, classes and definitions to define deep
learning models, cost functions and optimizers (optimizers are used to
train a model).</p>
<p>Before we move on to the next section of the workflow we need to make
sure we have Keras imported. We do this as follows:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span></code></pre>
</div>
<p>For this episode it is useful if everyone gets the same results from
their training. Keras uses a random number generator at certain points
during its execution. Therefore we will need to set two random seeds,
one for numpy and one for tensorflow:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>keras.utils.set_random_seed(<span class="dv">2</span>)</span></code></pre>
</div>
<div id="when-to-use-random-seeds" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="when-to-use-random-seeds" class="callout-inner">
<h3 class="callout-title">When to use random seeds?</h3>
<div class="callout-content">
<p>We use a random seed here to ensure that we get the same results
every time we run this code. This makes our results reproducible and
allows us to better compare results between different experiments.</p>
<p>Please note that even though you have selected a random seed, this
seed is used to generate a <strong>different</strong> random number
every time you execute a Jupyter cell. So, to get truly replicable deep
learning pipelines you need to run the notebook from start to end in one
go.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="build-a-neural-network-from-scratch">Build a neural network from scratch<a class="anchor" aria-label="anchor" href="#build-a-neural-network-from-scratch"></a>
</h3>
<p>We will now build a simple neural network from scratch using
Keras.</p>
<p>With Keras you compose a neural network by creating layers and
linking them together. For now we will only use one type of layer called
a fully connected or Dense layer. In Keras this is defined by the
<code>keras.layers.Dense</code> class.</p>
<p>A dense layer has a number of neurons, which is a parameter you can
choose when you create the layer. When connecting the layer to its input
and output layers every neuron in the dense layer gets an edge
(i.e. connection) to <strong><em>all</em></strong> of the input neurons
and <strong><em>all</em></strong> of the output neurons. The hidden
layer in the image in the introduction of this episode is a Dense
layer.</p>
<p>The input in Keras also gets special treatment, Keras automatically
calculates the number of inputs and outputs a layer needs and therefore
how many edges need to be created. This means we need to inform Keras
how big our input is going to be. We do this by instantiating a
<code>keras.Input</code> class and tell it how big our input is, thus
the number of columns it contains.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>],))</span></code></pre>
</div>
<p>We store a reference to this input class in a variable so we can pass
it to the creation of our hidden layer. Creating the hidden layer can
then be done as follows:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>hidden_layer <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(inputs)</span></code></pre>
</div>
<p>The instantiation here has 2 parameters and a seemingly strange
combination of parentheses, so let us take a closer look. The first
parameter <code>10</code> is the number of neurons we want in this
layer, this is one of the hyperparameters of our system and needs to be
chosen carefully. We will get back to this in the section on refining
the model.</p>
<p>The second parameter is the activation function to use. We choose
<code>relu</code> which returns 0 for inputs that are 0 and below and
the identity function (returning the same value) for inputs above 0.
This is a commonly used activation function in deep neural networks that
is proven to work well.</p>
<p>Next we see an extra set of parenthenses with inputs in them. This
means that after creating an instance of the Dense layer we call it as
if it was a function. This tells the Dense layer to connect the layer
passed as a parameter, in this case the inputs.</p>
<p>Finally we store a reference in the <code>hidden_layer</code>
variable so we can pass it to the output layer in a minute.</p>
<p>Now we create another layer that will be our output layer. Again we
use a Dense layer and so the call is very similar to the previous
one.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>output_layer <span class="op">=</span> keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)(hidden_layer)</span></code></pre>
</div>
<p>Because we chose the one-hot encoding, we use three neurons for the
output layer.</p>
<p>The <code>softmax</code> activation ensures that the three output
neurons produce values in the range (0, 1) and they sum to 1. We can
interpret this as a kind of ‘probability’ that the sample belongs to a
certain species.</p>
<p>Now that we have defined the layers of our neural network we can
combine them into a Keras model which facilitates training the
network.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>output_layer)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<p>The model summary here can show you some information about the neural
network we have defined.</p>
<div id="trainable-and-non-trainable-parameters" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="trainable-and-non-trainable-parameters" class="callout-inner">
<h3 class="callout-title">Trainable and non-trainable parameters</h3>
<div class="callout-content">
<p>Keras distinguishes between two types of weights, namely:</p>
<ul>
<li><p>trainable parameters: these are weights of the neurons that are
modified when we train the model in order to minimize our loss function
(we will learn about loss functions shortly!).</p></li>
<li><p>non-trainable parameters: these are weights of the neurons that
are not changed when we train the model. These could be for many reasons
- using a pre-trained model, choice of a particular filter for a
convolutional neural network, and statistical weights for batch
normalization are some examples.</p></li>
</ul>
<p>If these reasons are not clear right away, don’t worry! In later
episodes of this course, we will touch upon a couple of these
concepts.</p>
</div>
</div>
</div>

<div id="create-the-neural-network" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="create-the-neural-network" class="callout-inner">
<h3 class="callout-title">Create the neural network</h3>
<div class="callout-content">
<p>With the code snippets above, we defined a Keras model with 1 hidden
layer with 10 neurons and an output layer with 3 neurons.</p>
<ol style="list-style-type: decimal">
<li>How many parameters does the resulting model have?</li>
<li>What happens to the number of parameters if we increase or decrease
the number of neurons in the hidden layer?</li>
</ol>
<div class="section level4">
<h4 id="optional-visualizing-the-model">(optional) Visualizing the model<a class="anchor" aria-label="anchor" href="#optional-visualizing-the-model"></a>
</h4>
<p>Optionally, you can also visualize the same information as
<code>model.summary()</code> in graph form. This step requires the
command-line tool <code>dot</code> from Graphviz installed, you
installed it by following the setup instructions. You can check that the
installation was successful by executing <code>dot -V</code> in the
command line. You should get something as follows:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="ex">$</span> dot <span class="at">-V</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="ex">dot</span> <span class="at">-</span> graphviz version 2.43.0 <span class="er">(</span><span class="ex">0</span><span class="kw">)</span></span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>(optional) Provided you have <code>dot</code> installed, execute the
<code>plot_model</code> function as shown below.</li>
</ol>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>keras.utils.plot_model(</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>    model,</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>    show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>    show_layer_names<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    show_layer_activations<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>    show_trainable<span class="op">=</span><span class="va">True</span></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="optional-keras-sequential-vs-functional-api">(optional) Keras Sequential vs Functional API<a class="anchor" aria-label="anchor" href="#optional-keras-sequential-vs-functional-api"></a>
</h4>
<p>So far we have used the <a href="https://keras.io/guides/functional_api/" class="external-link">Functional API</a> of
Keras. You can also implement neural networks using <a href="https://keras.io/guides/sequential_model/" class="external-link">the Sequential
model</a>. As you can read in the documentation, the Sequential model is
appropriate for <strong>a plain stack of layers</strong> where each
layer has <strong>exactly one input tensor and one output
tensor</strong>.</p>
<ol start="4" style="list-style-type: decimal">
<li>(optional) Use the Sequential model to implement the same
network</li>
</ol>
</div>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Have a look at the output of <code>model.summary()</code>:</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓
┃ Layer (type)               ┃ Output Shape   ┃    Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩
│ input_layer (InputLayer)   │ (None, 4)      │          0 │
├────────────────────────────┼────────────────┼────────────┤
│ dense (Dense)              │ (None, 10)     │         50 │
├────────────────────────────┼────────────────┼────────────┤
│ dense_1 (Dense)            │ (None, 3)      │         33 │
└────────────────────────────┴────────────────┴────────────┘

 Total params: 83 (332.00 B)

 Trainable params: 83 (332.00 B)

 Non-trainable params: 0 (0.00 B)
</code></pre>
</div>
<p>The model has 83 trainable parameters. Each of the 10 neurons in the
in the <code>dense</code> hidden layer is connected to each of the 4
inputs in the input layer resulting in 40 weights that can be trained.
The 10 neurons in the hidden layer are also connected to each of the 3
outputs in the <code>dense_1</code> output layer, resulting in a further
30 weights that can be trained. By default <code>Dense</code> layers in
Keras also contain 1 bias term for each neuron, resulting in a further
10 bias values for the hidden layer and 3 bias terms for the output
layer. <code>40+30+10+3=83</code> trainable parameters.</p>
<p>Note that the output shape always contains <code>None</code> as the
first entry of the tuple. This is a <em>flexible</em> dimension which is
used by the model when processing several samples at the same time, what
is usually called a <code>batch</code>. You will learn more about
batching in lesson 3.</p>
<p>The value <code>(332.00 B)</code> next to it describes the memory
footprint for model weights and this depends on their data type. Take a
look at what <code>model.dtype</code> is.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="bu">print</span>(model.dtype)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="va">float32</span></span></code></pre>
</div>
<p>The model weights are represented using <code>float32</code> data
type, which consumes 32 bits or 4 bytes for each weight. We have 83
parameters, and therefore in total, the model requires
<code>83*4=332</code> bytes of memory to load into the computer’s
memory.</p>
<p>If you increase the number of neurons in the hidden layer the number
of trainable parameters in both the hidden and output layer increases or
decreases in accordance with the number of neurons added. Each extra
neuron has 4 weights connected to the input layer, 1 bias term, and 3
weights connected to the output layer. So in total 8 extra
parameters.</p>
<p><em>The name in quotes within the string
<code>Model: "functional"</code> may be different in your view; this
detail is not important.</em></p>
<div class="section level4">
<h4 id="optional-visualizing-the-model-1">(optional) Visualizing the model<a class="anchor" aria-label="anchor" href="#optional-visualizing-the-model-1"></a>
</h4>
<ol start="3" style="list-style-type: decimal">
<li>Upon executing the <code>plot_model</code> function, you should see
the following image.</li>
</ol>
<figure><img src="fig/02_plot_model.png" title="Output of keras.utils.plot_model() function" alt="A directed graph showing the three layers of the neural network connected by arrows. First layer is of type InputLayer. Second layer is of type Dense with a relu activation. The third layer is also of type Dense, with a softmax activation. The input and output shapes of every layer are also mentioned. Only the second and third layers contain trainable parameters." class="figure mx-auto d-block"><div class="figcaption">Output of <em>keras.utils.plot_model()</em>
function</div>
</figure>
</div>
<div class="section level4">
<h4 id="optional-keras-sequential-vs-functional-api-1">(optional) Keras Sequential vs Functional API<a class="anchor" aria-label="anchor" href="#optional-keras-sequential-vs-functional-api-1"></a>
</h4>
<ol start="4" style="list-style-type: decimal">
<li>This implements the same model using the Sequential API:</li>
</ol>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>model <span class="op">=</span> keras.Sequential(</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>    [</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>        keras.Input(shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>],)),</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>        keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>        keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">"softmax"</span>),</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>    ]</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>)</span></code></pre>
</div>
<p>We will use the Functional API for the remainder of this course,
since it is more flexible and more explicit.</p>
</div>
</div>
</div>
</div>
</div>
<div id="how-to-choose-an-architecture" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="how-to-choose-an-architecture" class="callout-inner">
<h3 class="callout-title">How to choose an architecture?</h3>
<div class="callout-content">
<p>Even for this small neural network, we had to make a choice on the
number of hidden neurons. Other choices to be made are the number of
layers and type of layers (as we will see later). You might wonder how
you should make these architectural choices. Unfortunately, there are no
clear rules to follow here, and it often boils down to a lot of trial
and error. However, it is recommended to look what others have done with
similar datasets and problems. Another best practice is to start with a
relatively simple architecture. Once running start to add layers and
tweak the network to see if performance increases.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="choose-a-pretrained-model">Choose a pretrained model<a class="anchor" aria-label="anchor" href="#choose-a-pretrained-model"></a>
</h3>
<p>If your data and problem is very similar to what others have done,
you can often use a <em>pretrained network</em>. Even if your problem is
different, but the data type is common (for example images), you can use
a pretrained network and finetune it for your problem. A large number of
openly available pretrained networks can be found on <a href="https://huggingface.co/models" class="external-link">Hugging Face</a> (especially LLMs),
<a href="https://monai.io/" class="external-link">MONAI</a> (medical imaging), the <a href="https://modelzoo.co/" class="external-link">Model Zoo</a>, <a href="https://pytorch.org/hub/" class="external-link">pytorch hub</a> or <a href="https://www.tensorflow.org/hub/" class="external-link">tensorflow hub</a>.</p>
<p>We will cover the concept of Transfer Learning in <a href="./5-transfer-learning.html">episode 5</a></p>
</div>
</section><section><h2 class="section-heading" id="choose-a-loss-function-and-optimizer">5. Choose a loss function and optimizer<a class="anchor" aria-label="anchor" href="#choose-a-loss-function-and-optimizer"></a>
</h2>
<hr class="half-width">
<p>We have now designed a neural network that in theory we should be
able to train to classify Penguins. However, we first need to select an
appropriate loss function that we will use during training. This loss
function tells the training algorithm how wrong, or how ‘far away’ from
the true value the predicted value is.</p>
<p>For the one-hot encoding that we selected earlier a suitable loss
function is the Categorical Crossentropy loss. In Keras this is
implemented in the <code>keras.losses.CategoricalCrossentropy</code>
class. This loss function works well in combination with the
<code>softmax</code> activation function we chose earlier. The
Categorical Crossentropy works by comparing the probabilities that the
neural network predicts with ‘true’ probabilities that we generated
using the one-hot encoding. This is a measure for how close the
distribution of the three neural network outputs corresponds to the
distribution of the three values in the one-hot encoding. It is lower if
the distributions are more similar.</p>
<p>For more information on the available loss functions in Keras you can
check the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses" class="external-link">documentation</a>.</p>
<p>Next we need to choose which optimizer to use and, if this optimizer
has parameters, what values to use for those. Furthermore, we need to
specify how many times to show the training samples to the
optimizer.</p>
<p>Once more, Keras gives us plenty of choices all of which have their
own pros and cons, but for now let us go with the widely used <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" class="external-link">Adam
optimizer</a>. Adam has a number of parameters, but the default values
work well for most problems. So we will use it with its default
parameters.</p>
<p>Combining this with the loss function we decided on earlier we can
now compile the model using <code>model.compile</code>. Compiling the
model prepares it to start the training.</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span>keras.losses.CategoricalCrossentropy())</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="train-model">6. Train model<a class="anchor" aria-label="anchor" href="#train-model"></a>
</h2>
<hr class="half-width">
<p>We are now ready to train the model.</p>
<p>Training the model is done using the <code>fit</code> method, it
takes the input data and target data as inputs and it has several other
parameters for certain options of the training. Here we only set a
different number of <code>epochs</code>. One training epoch means that
every sample in the training data has been shown to the neural network
and used to update its parameters.</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">100</span>)</span></code></pre>
</div>
<p>The fit method returns a history object that has a history attribute
with the training loss and potentially other metrics per training epoch.
It can be very insightful to plot the training loss to see how the
training progresses. Using seaborn we can do this as follows:</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span>history.epoch, y<span class="op">=</span>history.history[<span class="st">'loss'</span>])</span></code></pre>
</div>
<figure><img src="fig/02_training_curve.png" title="Training Curve" alt="Plot of the Cross Entropy loss, showing a sharp decrease in the first around 10 epochs, and converging at a low value afterwards." class="figure mx-auto d-block"></figure><div id="i-get-a-different-plot" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="i-get-a-different-plot" class="callout-inner">
<h3 class="callout-title">I get a different plot</h3>
<div class="callout-content">
<p>It could be that you get a different plot than the one shown here.
This could be because of a different random initialization of the model
or a different split of the data. This difference can be avoided by
setting <code>random_state</code> and random seed in the same way like
we discussed in <a href="#when-to-use-random-seeds">When to use random
seeds?</a>.</p>
</div>
</div>
</div>
<p>This plot can be used to identify whether the training is well
configured or whether there are problems that need to be addressed.</p>
<div id="the-training-curve" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="the-training-curve" class="callout-inner">
<h3 class="callout-title">The Training Curve</h3>
<div class="callout-content">
<p>Looking at the training curve we have just made.</p>
<ol style="list-style-type: decimal">
<li>How does the training progress?
<ul>
<li>Does the training loss increase or decrease?</li>
<li>Does it change quickly or slowly?</li>
<li>Does the graph look very jittery?</li>
</ul>
</li>
<li>Do you think the resulting trained network will work well on the
test set?</li>
</ol>
<p>When the training process does not go well:</p>
<ol start="3" style="list-style-type: decimal">
<li>(optional) Something went wrong here during training. What could be
the problem, and how do you see that in the training curve? Also compare
the range on the y-axis with the previous training curve. <img src="fig/02_bad_training_history_1.png" title="Training Curve Gone Wrong" alt="Very jittery training curve with the loss value jumping back and forth between 2 and 4. The range of the y-axis is from 2 to 4, whereas in the previous training curve it was from 0 to 2. The loss seems to decrease a litle bit, but not as much as compared to the previous plot where it dropped to almost 0. The minimum loss in the end is somewhere around 2." class="figure">
</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>The training loss decreases quickly. It drops in a smooth line with
little jitter. This is ideal for a training curve.</li>
<li>The results of the training give very little information on its
performance on a test set. You should be careful not to use the training
loss as an indication of a well trained network. The test set, since it
contains unseen samples, is more representative of the model performance
in a real-world scenario.</li>
<li>(optional) The loss does not go down at all, or only very slightly.
This means that the model is not learning anything. It could be that
something went wrong in the data preparation (for example the labels are
not attached to the right features). In addition, the graph is very
jittery. This means that for every update step, the weights in the
network are updated in such a way that the loss sometimes increases a
lot and sometimes decreases a lot. This could indicate that the weights
are updated too much at every learning step and you need a smaller
learning rate (we will go into more details on this in the next
episode). Or there is a high variation in the data, leading the
optimizer to change the weights in different directions at every
learning step. This could be addressed by presenting more data at every
learning step (or in other words increasing the batch size). In this
case the graph was created by training on nonsense data, so this a
training curve for a problem where nothing can be learned really.</li>
</ol>
<p>We will take a closer look at training curves in the next episode.
Some of the concepts touched upon here will also be further explained
there.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="perform-a-predictionclassification">7. Perform a prediction/classification<a class="anchor" aria-label="anchor" href="#perform-a-predictionclassification"></a>
</h2>
<hr class="half-width">
<p>Now that we have a trained neural network, we can use it to predict
new samples of penguin using the <code>predict</code> function.</p>
<p>We will use the neural network to predict the species of the test set
using the <code>predict</code> function. We will be using this
prediction in the next step to measure the performance of our trained
network. This will return a <code>numpy</code> matrix, which we convert
to a pandas dataframe to easily see the labels.</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a>prediction <span class="op">=</span> pd.DataFrame(y_pred, columns<span class="op">=</span>target.columns)</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a>prediction</span></code></pre>
</div>
<table class="table"><tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.304484</td>
<td align="right">0.192893</td>
<td align="right">0.502623</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0.527107</td>
<td align="right">0.095888</td>
<td align="right">0.377005</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">0.373989</td>
<td align="right">0.195604</td>
<td align="right">0.430406</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.493643</td>
<td align="right">0.154104</td>
<td align="right">0.352253</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">0.309051</td>
<td align="right">0.308646</td>
<td align="right">0.382303</td>
</tr>
<tr class="even">
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
<tr class="odd">
<td align="right">64</td>
<td align="right">0.406074</td>
<td align="right">0.191430</td>
<td align="right">0.402496</td>
</tr>
<tr class="even">
<td align="right">65</td>
<td align="right">0.645621</td>
<td align="right">0.077174</td>
<td align="right">0.277204</td>
</tr>
<tr class="odd">
<td align="right">66</td>
<td align="right">0.356284</td>
<td align="right">0.185958</td>
<td align="right">0.457758</td>
</tr>
<tr class="even">
<td align="right">67</td>
<td align="right">0.393868</td>
<td align="right">0.159575</td>
<td align="right">0.446557</td>
</tr>
<tr class="odd">
<td align="right">68</td>
<td align="right">0.509837</td>
<td align="right">0.144219</td>
<td align="right">0.345943</td>
</tr>
</tbody></table>
<p>Remember that the output of the network uses the <code>softmax</code>
activation function and has three outputs, one for each species. This
dataframe shows this nicely.</p>
<p>We now need to transform this output to one penguin species per
sample. We can do this by looking for the index of highest valued output
and converting that to the corresponding species. Pandas dataframes have
the <code>idxmax</code> function, which will do exactly that.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>predicted_species <span class="op">=</span> prediction.idxmax(axis<span class="op">=</span><span class="st">"columns"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>predicted_species</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0     Gentoo
1     Adelie
2     Gentoo
3     Adelie
4     Gentoo
      ...
64    Adelie
65    Adelie
66    Gentoo
67    Gentoo
68    Adelie
Length: 69, dtype: object</code></pre>
</div>

</section><section><h2 class="section-heading" id="measuring-performance">8. Measuring performance<a class="anchor" aria-label="anchor" href="#measuring-performance"></a>
</h2>
<hr class="half-width">
<p>Now that we have a trained neural network it is important to assess
how well it performs. We want to know how well it will perform in a
realistic prediction scenario, measuring performance will also come back
when refining the model.</p>
<p>We have created a test set (i.e. y_test) during the data preparation
stage which we will use now to create a confusion matrix.</p>
<div class="section level3">
<h3 id="confusion-matrix">Confusion matrix<a class="anchor" aria-label="anchor" href="#confusion-matrix"></a>
</h3>
<p>With the predicted species we can now create a confusion matrix and
display it using seaborn.</p>
<p>A confusion matrix is an <code>N x N</code> matrix used for
evaluating the performance of a classification model, where
<code>N</code> is the number of target classes. The matrix compares the
actual target values with those predicted from the classification model,
which gives a holistic view of how well the classification model is
performing.</p>
<p>To create a confusion matrix we will use another convenience function
from sklearn called <code>confusion_matrix</code>. This function takes
as a first parameter the true labels of the test set. We can get these
by using the <code>idxmax</code> method on the y_test dataframe. The
second parameter is the predicted labels which we did above.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>true_species <span class="op">=</span> y_test.idxmax(axis<span class="op">=</span><span class="st">"columns"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a>matrix <span class="op">=</span> confusion_matrix(true_species, predicted_species)</span>
<span id="cb31-6"><a href="#cb31-6" tabindex="-1"></a><span class="bu">print</span>(matrix)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[22  0  8]
 [ 5  0  9]
 [ 6  0 19]]</code></pre>
</div>
<p>Unfortunately, this matrix is not immediately understandable. Its not
clear which column and which row corresponds to which species. So let’s
convert it to a Pandas Dataframe with its index and columns set to the
species as follows:</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="co"># Convert to a pandas dataframe</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>confusion_df <span class="op">=</span> pd.DataFrame(matrix, index<span class="op">=</span>y_test.columns.values, columns<span class="op">=</span>y_test.columns.values)</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a><span class="co"># Set the names of the x and y axis, this helps with the readability of the heatmap.</span></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>confusion_df.index.name <span class="op">=</span> <span class="st">'True Label'</span></span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a>confusion_df.columns.name <span class="op">=</span> <span class="st">'Predicted Label'</span></span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a>confusion_df.head()</span></code></pre>
</div>
<p>We can then use the <code>heatmap</code> function from seaborn to
create a nice visualization of the confusion matrix. The
<code>annot=True</code> parameter here will put the numbers from the
confusion matrix in the heatmap.</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>sns.heatmap(confusion_df, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span></code></pre>
</div>
<figure><img src="fig/confusion_matrix.png" title="Confusion Matrix" alt="Confusion matrix of the test set with high accuracy for Adelie and Gentoo classification and no correctly predicted Chinstrap" class="figure mx-auto d-block"></figure><p>Here are more explanations of this confusion matrix and the
classification model.</p>
<ul>
<li>The first row: There are 30 Adelie penguins in the test data, with
22 identified as Adelie (valid), 8 being identified as Gentoo (invalid),
and no Adelie is identified as Chinstrap.</li>
<li>The second row: There are 14 Chinstrap pengunis in the test data,
with 5 identified as Adelie (invalid), none are correctly recognized as
Chinstrap, and 9 Chinstraps are identified as Gentoo (invalid).</li>
<li>The third row: There are 25 Gentoo penguins in the test data, with 6
identified as Adelie (invalid), none being recognized as Chinstrap
(invalid), and 19 Gentoos are identified as Gentoo (valid).</li>
</ul>
<div id="confusion-matrix-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="confusion-matrix-1" class="callout-inner">
<h3 class="callout-title">Confusion Matrix</h3>
<div class="callout-content">
<p>Measure the performance of the neural network you trained and
visualize a confusion matrix.</p>
<ul>
<li>Did the neural network perform well on the test set?</li>
<li>Did you expect this from the training loss you saw?</li>
<li>What could we do to improve the performance?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>The confusion matrix shows that the predictions for Adelie and Gentoo
are decent, but could be improved. However, Chinstrap is not predicted
ever.</p>
<p>If we go back to the <a href="#pair-plot"><strong>Pair
Plot</strong></a> in the Visualization section above, we can figure out
that the biggest challenge is distinguishing the Chinstrap penguins from
the marginal distributions of the four features (bill length, bill
depth, flipper length, and body mass). That means that there is no
single variable that separates Chinstrap penguins from all other
species. Only the combination of bill length and bill depth gives a good
separation of Chinstrap from Adelie and Gentoo penguins.</p>
<p>The training loss was very low, so the low accuracy on the test set
may be surprising. But this illustrates very well why a test set is
important to give a realistic evaluation when training neural networks
(or other machine learning classifiers).</p>
<p>We can try many things to improve the performance from here. One of
the first things we can try is to balance the dataset better.</p>
<p>Furthermore, the constructed neural network has a limited number of
parameters. A practical workaround is to increase the number of dense
layers and also the number of neurons in each dense layers.</p>
<p>In addition, adjusting the learning rate can also help achieving a
high score for the prediction. You will get more info in the <a href="./4-advanced-layer-types.html"><strong>Advanced layer
types</strong></a> episode.</p>
<p>Note that the outcome you have might be slightly different from what
is shown in this tutorial.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="refine-the-model">9. Refine the model<a class="anchor" aria-label="anchor" href="#refine-the-model"></a>
</h2>
<hr class="half-width">
<p>As we discussed before the design and training of a neural network
comes with many hyperparameter and model architecture choices. We will
go into more depth of these choices in later episodes. For now it is
important to realize that the parameters we chose were somewhat
arbitrary and more careful consideration needs to be taken to pick
hyperparameter values.</p>
</section><section><h2 class="section-heading" id="share-model">10. Share model<a class="anchor" aria-label="anchor" href="#share-model"></a>
</h2>
<hr class="half-width">
<p>It is very useful to be able to use the trained neural network at a
later stage without having to retrain it. This can be done by using the
<code>save</code> method of the model. It takes a string as a parameter
which is the path of a directory where the model is stored.</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>model.save(<span class="st">'my_first_model.keras'</span>)</span></code></pre>
</div>
<p>This saved model can be loaded again by using the
<code>load_model</code> method as follows:</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>pretrained_model <span class="op">=</span> keras.models.load_model(<span class="st">'my_first_model.keras'</span>)</span></code></pre>
</div>
<p>This loaded model can be used as before to predict.</p>
<div class="codewrapper sourceCode" id="cb37">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="co"># use the pretrained model here</span></span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>y_pretrained_pred <span class="op">=</span> pretrained_model.predict(X_test)</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>pretrained_prediction <span class="op">=</span> pd.DataFrame(y_pretrained_pred, columns<span class="op">=</span>target.columns.values)</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a><span class="co"># idxmax will select the column for each row with the highest value</span></span>
<span id="cb37-6"><a href="#cb37-6" tabindex="-1"></a>pretrained_predicted_species <span class="op">=</span> pretrained_prediction.idxmax(axis<span class="op">=</span><span class="st">"columns"</span>)</span>
<span id="cb37-7"><a href="#cb37-7" tabindex="-1"></a><span class="bu">print</span>(pretrained_predicted_species)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0     Adelie
1     Gentoo
2     Adelie
3     Gentoo
4     Gentoo
      ...
64    Gentoo
65    Gentoo
66    Adelie
67    Adelie
68    Gentoo
Length: 69, dtype: object</code></pre>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>The deep learning workflow is a useful tool to structure your
approach, it helps to make sure you do not forget any important
steps.</li>
<li>Exploring the data is an important step to familiarize yourself with
the problem and to help you determine the relavent inputs and
outputs.</li>
<li>One-hot encoding is a preprocessing step to prepare labels for
classification in Keras.</li>
<li>A fully connected layer is a layer which has connections to all
neurons in the previous and subsequent layers.</li>
<li>keras.layers.Dense is an implementation of a fully connected layer,
you can set the number of neurons in the layer and the activation
function used.</li>
<li>To train a neural network with Keras we need to first define the
network using layers and the Model class. Then we can train it using the
model.fit function.</li>
<li>Plotting the loss curve can be used to identify and troubleshoot the
training process.</li>
<li>The loss curve on the training set does not provide any information
on how well a network performs in a real setting.</li>
<li>Creating a confusion matrix with results from a test set gives
better insight into the network’s performance.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-3-monitor-the-model"><p>Content from <a href="3-monitor-the-model.html">Monitor the training process</a></p>
<hr>
<p>Last updated on 2025-09-02 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/3-monitor-the-model.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I create a neural network for a regression task?</li>
<li>How does optimization work?</li>
<li>How do I monitor the training process?</li>
<li>How do I detect (and avoid) overfitting?</li>
<li>What are common options to improve the model performance?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain the importance of keeping your test set clean, by validating
on the validation set instead of the test set</li>
<li>Use the data splits to plot the training process</li>
<li>Explain how optimization works</li>
<li>Design a neural network for a regression task</li>
<li>Measure the performance of your deep neural network</li>
<li>Interpret the training plots to recognize overfitting</li>
<li>Use normalization as preparation step for deep learning</li>
<li>Implement basic strategies to prevent overfitting</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In this episode we will explore how to monitor the training progress,
evaluate our the model predictions and finetune the model to avoid
over-fitting. For that we will use a more complicated weather
data-set.</p>
<section><h2 class="section-heading" id="formulate-outline-the-problem-weather-prediction">1. Formulate / Outline the problem: weather prediction<a class="anchor" aria-label="anchor" href="#formulate-outline-the-problem-weather-prediction"></a>
</h2>
<hr class="half-width">
<p>Here we want to work with the <em>weather prediction dataset</em>
(the light version) which can be <a href="https://doi.org/10.5281/zenodo.5071376" class="external-link">downloaded from
Zenodo</a>. It contains daily weather observations from 11 different
European cities or places through the years 2000 to 2010. For all
locations the data contains the variables ‘mean temperature’, ‘max
temperature’, and ‘min temperature’. In addition, for multiple
locations, the following variables are provided: ‘cloud_cover’,
‘wind_speed’, ‘wind_gust’, ‘humidity’, ‘pressure’, ‘global_radiation’,
‘precipitation’, ‘sunshine’, but not all of them are provided for every
location. A more extensive description of the dataset including the
different physical units is given in accompanying metadata file. The
full dataset comprises of 10 years (3654 days) of collected weather data
across Europe.</p>
<figure><img src="fig/03_weather_prediction_dataset_map.png" alt="18 European locations in the weather prediction dataset distributed across Austria, France, Germany, Hungary, Italy, the Netherlands, Norway, Slovenia, Sweden, Switzerland, and the United Kingdom." class="figure mx-auto d-block"><div class="figcaption">European locations in the weather prediction
dataset</div>
</figure><p>A very common task with weather data is to make a prediction about
the weather sometime in the future, say the next day. In this episode,
we will try to predict tomorrow’s sunshine hours, a
challenging-to-predict feature, using a neural network with the
available weather data for one location: BASEL.</p>
</section><section><h2 class="section-heading" id="identify-inputs-and-outputs">2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#identify-inputs-and-outputs"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="import-dataset">Import Dataset<a class="anchor" aria-label="anchor" href="#import-dataset"></a>
</h3>
<p>We will now import and explore the weather data-set:</p>
<div id="load-the-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="load-the-data" class="callout-inner">
<h3 class="callout-title">Load the data</h3>
<div class="callout-content">
<p>If you have not downloaded the data yet, you can also load it
directly from Zenodo:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"https://zenodo.org/record/5071376/files/weather_prediction_dataset_light.csv?download=1"</span>)</span></code></pre>
</div>
<div class="section level4">
<h4 id="ssl-certificate-error">SSL certificate error<a class="anchor" aria-label="anchor" href="#ssl-certificate-error"></a>
</h4>
<!-- Using H4 here because H3 renders to big compared to the title of the callout -->
<p>If you get the following error message:
<code>certificate verify failed: unable to get local issuer certificate</code>,
you can download <a href="https://zenodo.org/record/5071376/files/weather_prediction_dataset_light.csv?download=1" class="external-link">the
data from here manually</a> into a local folder and load the data using
the code below.</p>
</div>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>filename_data <span class="op">=</span> <span class="st">"weather_prediction_dataset_light.csv"</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(filename_data)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>data.head()</span></code></pre>
</div>
<table class="table">
<colgroup>
<col width="7%">
<col width="7%">
<col width="17%">
<col width="16%">
<col width="21%">
<col width="14%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th align="right"></th>
<th align="right">DATE</th>
<th align="right">MONTH</th>
<th align="right">BASEL_cloud_cover</th>
<th align="right">BASEL_humidity</th>
<th align="right">BASEL_pressure</th>
<th align="right">…</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">20000101</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">0.89</td>
<td align="right">1.0286</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">20000102</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">0.87</td>
<td align="right">1.0318</td>
<td align="right">…</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">20000103</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">0.81</td>
<td align="right">1.0314</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">20000104</td>
<td align="right">1</td>
<td align="right">7</td>
<td align="right">0.79</td>
<td align="right">1.0262</td>
<td align="right">…</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">20000105</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">0.90</td>
<td align="right">1.0246</td>
<td align="right">…</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="brief-exploration-of-the-data">Brief exploration of the data<a class="anchor" aria-label="anchor" href="#brief-exploration-of-the-data"></a>
</h3>
<p>Let us start with a quick look at the type of features that we find
in the data.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>data.columns</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Index(['DATE', 'MONTH', 'BASEL_cloud_cover', 'BASEL_humidity',
       'BASEL_pressure', 'BASEL_global_radiation', 'BASEL_precipitation',
       'BASEL_sunshine', 'BASEL_temp_mean', 'BASEL_temp_min', 'BASEL_temp_max',
        ...
       'SONNBLICK_temp_min', 'SONNBLICK_temp_max', 'TOURS_humidity',
       'TOURS_pressure', 'TOURS_global_radiation', 'TOURS_precipitation',
       'TOURS_temp_mean', 'TOURS_temp_min', 'TOURS_temp_max'],
      dtype='object')</code></pre>
</div>
<p>There is a total of 9 different measured variables (global_radiation,
humidity, etcetera)</p>
<p>Let’s have a look at the shape of the dataset:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>data.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(3654, 91)</code></pre>
</div>
<p>This will give both the number of samples (3654) and the number of
features (89 + month + date).</p>
<p>For any row <code>i</code>, we will use the values of all fields
except <code>MONTH</code> and <code>DATE</code> as the input features
<code>X</code>. We want to use them to forecast the number of sunshine
hours of the next day, hence we use the value of the field
<code>BASEL_sunshine</code> in the <em>subsequent</em> row
(<code>i+1</code>) as the label that we want to predict
(<code>y</code>).</p>
</div>
</section><section><h2 class="section-heading" id="prepare-data">3. Prepare data<a class="anchor" aria-label="anchor" href="#prepare-data"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="select-a-subset-and-split-into-data-x-and-labels-y">Select a subset and split into data (X) and labels (y)<a class="anchor" aria-label="anchor" href="#select-a-subset-and-split-into-data-x-and-labels-y"></a>
</h3>
<p>The full dataset comprises of 10 years (3654 days) from which we will
select only the first 3 years. The present dataset is sorted by “DATE”,
so for each row <code>i</code> in the table we can pick a corresponding
feature and location from row <code>i+1</code> that we later want to
predict with our model. As outlined in step 1, we would like to predict
the sunshine hours for the location: BASEL.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>nr_rows <span class="op">=</span> <span class="dv">365</span><span class="op">*</span><span class="dv">3</span> <span class="co"># 3 years</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>X_data <span class="op">=</span> data.loc[:nr_rows] <span class="co"># Select first 3 years</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>X_data <span class="op">=</span> X_data.drop(columns<span class="op">=</span>[<span class="st">'DATE'</span>, <span class="st">'MONTH'</span>]) <span class="co"># Drop date and month column</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co"># labels (sunshine hours the next day)</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>y_data <span class="op">=</span> data.loc[<span class="dv">1</span>:(nr_rows <span class="op">+</span> <span class="dv">1</span>)][<span class="st">"BASEL_sunshine"</span>]</span></code></pre>
</div>
<p>In general, it is important to check if the data contains any
unexpected values such as <code>9999</code> or <code>NaN</code> or
<code>NoneType</code>. You can use the pandas
<code>data.describe()</code> or <code>data.isnull()</code> function for
this. If so, such values must be removed or replaced. In the present
case the data is luckily well prepared and shouldn’t contain such
values, so that this step can be omitted.</p>
</div>
<div class="section level3">
<h3 id="split-data-and-labels-into-training-validation-and-test-set">Split data and labels into training, validation, and test set<a class="anchor" aria-label="anchor" href="#split-data-and-labels-into-training-validation-and-test-set"></a>
</h3>
<p>As with classical machine learning techniques, it is required in deep
learning to split off a hold-out <em>test set</em> which remains
untouched during model training and tuning. It is later used to evaluate
the model performance. On top, we will also split off an additional
<em>validation set</em>, the reason of which will hopefully become
clearer later in this lesson.</p>
<p>To make our lives a bit easier, we employ a trick to create these 3
datasets, <code>training set</code>, <code>test set</code> and
<code>validation set</code>, by calling the
<code>train_test_split</code> method of <code>scikit-learn</code>
twice.</p>
<p>First we create the training set and leave the remainder of 30 % of
the data to the two hold-out sets.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>X_train, X_holdout, y_train, y_holdout <span class="op">=</span> train_test_split(X_data, y_data, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre>
</div>
<p>Now we split the 30 % of the data in two equal sized parts.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>X_val, X_test, y_val, y_test <span class="op">=</span> train_test_split(X_holdout, y_holdout, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre>
</div>
<p>Setting the <code>random_state</code> to <code>0</code> is a
short-hand at this point. Note however, that changing this seed of the
pseudo-random number generator will also change the composition of your
data sets. For the sake of reproducibility, this is one example of a
parameters that should not change at all.</p>

</div>
</section><section><h2 class="section-heading" id="choose-a-pretrained-model-or-start-building-architecture-from-scratch">4. Choose a pretrained model or start building architecture from
scratch<a class="anchor" aria-label="anchor" href="#choose-a-pretrained-model-or-start-building-architecture-from-scratch"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="regression-and-classification">Regression and classification<a class="anchor" aria-label="anchor" href="#regression-and-classification"></a>
</h3>
<p>In episode 2 we trained a dense neural network on a
<em>classification task</em>. For this one hot encoding was used
together with a <code>Categorical Crossentropy</code> loss function.
This measured how close the distribution of the neural network outputs
corresponds to the distribution of the three values in the one hot
encoding. Now we want to work on a <em>regression task</em>, thus not
predicting a class label (or integer number) for a datapoint. In
regression, we predict one (and sometimes many) values of a feature.
This is typically a floating point number.</p>
<div id="exercise-architecture-of-the-network" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-architecture-of-the-network" class="callout-inner">
<h3 class="callout-title">Exercise: Architecture of the network</h3>
<div class="callout-content">
<p>As we want to design a neural network architecture for a regression
task, see if you can first come up with the answers to the following
questions:</p>
<ol style="list-style-type: decimal">
<li>What must be the dimension of our input layer?</li>
<li>We want to output the prediction of a single number. The output
layer of the NN hence cannot be the same as for the classification task
earlier. This is because the <code>softmax</code> activation being used
had a concrete meaning with respect to the class labels which is not
needed here. What output layer design would you choose for regression?
Hint: A layer with <code>relu</code> activation, with
<code>sigmoid</code> activation or no activation at all?</li>
<li>(Optional) How would we change the model if we would like to output
a prediction of the precipitation in Basel in <em>addition</em> to the
sunshine hours?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>The shape of the input layer has to correspond to the number of
features in our data: 89</li>
<li>The output is a single value per prediction, so the output layer can
consist of a dense layer with only one node. The <em>softmax</em>
activiation function works well for a classification task, but here we
do not want to restrict the possible outcomes to the range of zero and
one. In fact, we can omit the activation in the output layer.</li>
<li>The output layer should have 2 neurons, one for each number that we
try to predict. Our y_train (and val and test) then becomes a
(n_samples, 2) matrix.</li>
</ol>
</div>
</div>
</div>
</div>
<p>In our example we want to predict the sunshine hours in Basel (or any
other place in the dataset) for tomorrow based on the weather data of
all 18 locations today. <code>BASEL_sunshine</code> is a floating point
value (i.e. <code>float64</code>). The network should hence output a
single float value which is why the last layer of our network will only
consist of a single node.</p>
<p>We compose a network of two hidden layers to start off with
something. We go by a scheme with 100 neurons in the first hidden layer
and 50 neurons in the second layer. As activation function we settle on
the <code>relu</code> function as a it is very robust and widely used.
To make our live easier later, we wrap the definition of the network in
a function called <code>create_nn()</code>.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>keras.utils.set_random_seed(<span class="dv">2</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="kw">def</span> create_nn(input_shape):</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    <span class="co"># Input layer</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>input_shape, name<span class="op">=</span><span class="st">'input'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    <span class="co"># Dense layers</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    layers_dense <span class="op">=</span> keras.layers.Dense(<span class="dv">100</span>, <span class="st">'relu'</span>)(inputs)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    layers_dense <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, <span class="st">'relu'</span>)(layers_dense)</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">1</span>)(layers_dense)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"weather_prediction_model"</span>)</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],))</span></code></pre>
</div>
<p>The shape of the input layer has to correspond to the number of
features in our data: <code>89</code>. We use
<code>X_data.shape[1]</code> to obtain this value dynamically</p>
<p>The output layer here is a dense layer with only 1 node. And we here
have chosen to use <em>no activation function</em>. While we might use
<em>softmax</em> for a classification task, here we do not want to
restrict the possible outcomes for a start.</p>
<p>In addition, we have here chosen to write the network creation as a
function so that we can use it later again to initiate new models.</p>
<p>Let us check how our model looks like by calling the
<code>summary</code> method.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "weather_prediction_model"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                ┃ Output Shape        ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input (InputLayer)          │ (None, 89)          │             0 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense (Dense)               │ (None, 100)         │         9,000 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_1 (Dense)             │ (None, 50)          │         5,050 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_2 (Dense)             │ (None, 1)           │            51 │
└─────────────────────────────┴─────────────────────┴───────────────┘

 Total params: 14,101 (55.08 KB)

 Trainable params: 14,101 (55.08 KB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
<p>When compiling the model we can define a few very important aspects.
We will discuss them now in more detail.</p>
</div>
</section><section><h2 class="section-heading" id="intermezzo-how-do-neural-networks-learn">Intermezzo: How do neural networks learn?<a class="anchor" aria-label="anchor" href="#intermezzo-how-do-neural-networks-learn"></a>
</h2>
<hr class="half-width">
<p>In the introduction we learned about the loss function: it quantifies
the total error of the predictions made by the model. During model
training we aim to find the model parameters that minimize the loss.
This is called optimization, but how does optimization actually
work?</p>
<div class="section level3">
<h3 id="gradient-descent">Gradient descent<a class="anchor" aria-label="anchor" href="#gradient-descent"></a>
</h3>
<p>Gradient descent is a widely used optimization algorithm, most other
optimization algorithms are based on it. It works as follows: Imagine a
neural network with only one neuron. Take a look at the figure below.
The plot shows the loss as a function of the weight of the neuron.</p>
<figure><img src="fig/03_gradient_descent.png" alt="Plot of the loss as a function of the weights. Through gradient descent the global loss minimum is found" class="figure mx-auto d-block"></figure><p>As you can see there is a global loss minimum, we would like to find
the weight at this point in the parabola. To do this, we initialize the
model weight with some random value. Then we compute the gradient of the
loss function with respect to the weight. This tells us how much the
loss function will change if we change the weight by a small amount.
Then, we update the weight by taking a small step in the direction of
the negative gradient, so down the slope. This will slightly decrease
the loss. This process is repeated until the loss function reaches a
minimum. The size of the step that is taken in each iteration is called
the ‘learning rate’.</p>
</div>
<div class="section level3">
<h3 id="batch-gradient-descent">Batch gradient descent<a class="anchor" aria-label="anchor" href="#batch-gradient-descent"></a>
</h3>
<p>You could use the entire training dataset to perform one learning
step in gradient descent, which would mean that one epoch equals one
learning step. In practice, in each learning step we only use a subset
of the training data to compute the loss and the gradients. This subset
is called a ‘batch’, the number of samples in one batch is called the
‘batch size’.</p>
<div id="exercise-gradient-descent" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-gradient-descent" class="callout-inner">
<h3 class="callout-title">Exercise: Gradient descent</h3>
<div class="callout-content">
<p>Answer the following questions:</p>
<div class="section level3">
<h3 id="what-is-the-goal-of-optimization">1. What is the goal of optimization?<a class="anchor" aria-label="anchor" href="#what-is-the-goal-of-optimization"></a>
</h3>
<ul>
<li>A. To find the weights that maximize the loss function</li>
<li>B. To find the weights that minimize the loss function</li>
</ul>
</div>
<div class="section level3">
<h3 id="what-happens-in-one-gradient-descent-step">2. What happens in one gradient descent step?<a class="anchor" aria-label="anchor" href="#what-happens-in-one-gradient-descent-step"></a>
</h3>
<ul>
<li>A. The weights are adjusted so that we move in the direction of the
gradient, so up the slope of the loss function</li>
<li>B. The weights are adjusted so that we move in the direction of the
gradient, so down the slope of the loss function</li>
<li>C. The weights are adjusted so that we move in the direction of the
negative gradient, so up the slope of the loss function</li>
<li>D. The weights are adjusted so that we move in the direction of the
negative gradient, so down the slope of the loss function</li>
</ul>
</div>
<div class="section level3">
<h3 id="when-the-batch-size-is-increased">3. When the batch size is increased:<a class="anchor" aria-label="anchor" href="#when-the-batch-size-is-increased"></a>
</h3>
<p>(multiple answers might apply)</p>
<ul>
<li>A. The number of samples in an epoch also increases</li>
<li>B. The number of batches in an epoch goes down</li>
<li>C. The training progress is more jumpy, because more samples are
consulted in each update step (one batch).</li>
<li>D. The memory load (memory as in computer hardware) of the training
process is increased</li>
</ul>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li><p>Correct answer: B. To find the weights that minimize the loss
function. The loss function quantifies the total error of the network,
we want to have the smallest error as possible, hence we minimize the
loss.</p></li>
<li><p>Correct answer: D The weights are adjusted so that we move in the
direction of the negative gradient, so down the slope of the loss
function. We want to move towards the global minimum, so in the opposite
direction of the gradient.</p></li>
<li>
<p>Correct answer: B &amp; D</p>
<ul>
<li>A. The number of samples in an epoch also increases
(<strong>incorrect</strong>, an epoch is always defined as passing
through the training data for one cycle)</li>
<li>B. The number of batches in an epoch goes down
(<strong>correct</strong>, the number of batches is the samples in an
epoch divided by the batch size)</li>
<li>C. The training progress is more jumpy, because more samples are
consulted in each update step (one batch). (<strong>incorrect</strong>,
more samples are consulted in each update step, but this makes the
progress less jumpy since you get a more accurate estimate of the loss
in the entire dataset)</li>
<li>D. The memory load (memory as in computer hardware) of the training
process is increased (<strong>correct</strong>, the data is begin loaded
one batch at a time, so more samples means more memory usage)</li>
</ul>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="choose-a-loss-function-and-optimizer">5. Choose a loss function and optimizer<a class="anchor" aria-label="anchor" href="#choose-a-loss-function-and-optimizer"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="loss-function">Loss function<a class="anchor" aria-label="anchor" href="#loss-function"></a>
</h3>
<p>The loss is what the neural network will be optimized on during
training, so choosing a suitable loss function is crucial for training
neural networks. In the given case we want to stimulate that the
predicted values are as close as possible to the true values. This is
commonly done by using the <em>mean squared error</em> (mse) or the
<em>mean absolute error</em> (mae), both of which should work OK in this
case. Often, mse is preferred over mae because it “punishes” large
prediction errors more severely. In Keras this is implemented in the
<code>keras.losses.MeanSquaredError</code> class (see Keras
documentation: <a href="https://keras.io/api/losses/" class="external-link uri">https://keras.io/api/losses/</a>). This can be provided into
the <code>model.compile</code> method with the <code>loss</code>
parameter and setting it to <code>mse</code>, e.g.</p>
<!--cce:skip-->
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="optimizer">Optimizer<a class="anchor" aria-label="anchor" href="#optimizer"></a>
</h3>
<p>Somewhat coupled to the loss function is the <em>optimizer</em> that
we want to use. The <em>optimizer</em> here refers to the algorithm with
which the model learns to optimize on the provided loss function. A
basic example for such an optimizer would be <em>stochastic gradient
descent</em>. For now, we can largely skip this step and pick one of the
most common optimizers that works well for most tasks: the <em>Adam
optimizer</em>. Similar to activation functions, the choice of optimizer
depends on the problem you are trying to solve, your model architecture
and your data. <em>Adam</em> is a good starting point though, which is
why we chose it.</p>
<!--cce:skip-->
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">'mse'</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="metrics">Metrics<a class="anchor" aria-label="anchor" href="#metrics"></a>
</h3>
<p>In our first example (episode 2) we plotted the progression of the
loss during training. That is indeed a good first indicator if things
are working alright, i.e. if the loss is indeed decreasing as it should
with the number of epochs. However, when models become more complicated
then also the loss functions often become less intuitive. That is why it
is good practice to monitor the training process with additional, more
intuitive metrics. They are not used to optimize the model, but are
simply recorded during training.</p>
<p>With Keras, such additional metrics can be added via
<code>metrics=[...]</code> parameter and can contain one or multiple
metrics of interest. Here we could for instance chose <code>mae</code>
(<a href="https://glosario.carpentries.org/en/#mean_absolute_error" class="external-link">mean
absolute error</a>), or the the <a href="https://glosario.carpentries.org/en/#root_mean_squared_error" class="external-link"><em>root
mean squared error</em> (RMSE)</a> which unlike the <em>mse</em> has the
same units as the predicted values. For the sake of units, we choose the
latter.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">'mse'</span>,</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>              metrics<span class="op">=</span>[keras.metrics.RootMeanSquaredError()])</span></code></pre>
</div>
<p>Let’s create a <code>compile_model</code> function to easily compile
the model throughout this lesson:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="kw">def</span> compile_model(model):</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>                  loss<span class="op">=</span><span class="st">'mse'</span>,</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>                  metrics<span class="op">=</span>[keras.metrics.RootMeanSquaredError()])</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>compile_model(model)</span></code></pre>
</div>
<p>With this, we complete the compilation of our network and are ready
to start training.</p>
</div>
</section><section><h2 class="section-heading" id="train-the-model">6. Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<hr class="half-width">
<p>Now that we created and compiled our dense neural network, we can
start training it. We add the <code>batch_size</code> parameter that
defines – as discussed above – how many samples from the training data
will be used to estimate the error gradient before the model weights are
updated. Larger batches will produce better, more accurate gradient
estimates but also less frequent updates of the weights. Here we are
going to use a batch size of 32 which is a common starting point.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>                    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>                    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>                    verbose<span class="op">=</span><span class="dv">2</span>)</span></code></pre>
</div>
<p>We can plot the training process using the <code>history</code>
object returned from the model training. We will create a function for
it, because we will make use of this more often in this lesson!</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="kw">def</span> plot_history(history, metrics):</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="co">    Plot the training history</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a><span class="co">        history (keras History object that is returned by model.fit())</span></span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a><span class="co">        metrics (str, list): Metric or a list of metrics to plot</span></span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>    plt.style.use(<span class="st">'ggplot'</span>)  <span class="co"># optional, that's only to define a visual style</span></span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>    history_df <span class="op">=</span> pd.DataFrame.from_dict(history.history)</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>    sns.lineplot(data<span class="op">=</span>history_df[metrics])</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>    plt.xlabel(<span class="st">"epochs"</span>)</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a>plot_history(history, <span class="st">'root_mean_squared_error'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_training_history_1_rmse.png" alt="Plot of the RMSE over epochs for the trained model that shows a decreasing error metric." class="figure mx-auto d-block"></figure><p>This looks very promising! Our metric “root_mean_squared_error”
(RMSE) is dropping nicely and while it maybe keeps fluctuating a bit it
does end up at fairly low values. But this metric is just the root
<em>mean</em> squared error, so we might want to look a bit more in
detail how well our just trained model does in predicting the sunshine
hours.</p>
</section><section><h2 class="section-heading" id="perform-a-predictionclassification">7. Perform a Prediction/Classification<a class="anchor" aria-label="anchor" href="#perform-a-predictionclassification"></a>
</h2>
<hr class="half-width">
<p>Now that we have our model trained, we can make a prediction with the
model before measuring the performance of our neural network.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>y_train_predicted <span class="op">=</span> model.predict(X_train)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>y_test_predicted <span class="op">=</span> model.predict(X_test)</span></code></pre>
</div>

</section><section><h2 class="section-heading" id="measure-performance">8. Measure performance<a class="anchor" aria-label="anchor" href="#measure-performance"></a>
</h2>
<hr class="half-width">
<p>There is not a single way to evaluate how a model performs. But there
are at least two very common approaches. For a <em>classification
task</em> that is to compute a <em>confusion matrix</em> for the test
set which shows how often particular classes were predicted correctly or
incorrectly.</p>
<p>For the present <em>regression task</em>, it makes more sense to
compare true and predicted values in a scatter plot.</p>
<p>So, let’s look at how the predicted sunshine hour have developed with
reference to their ground truth values.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># We define a function that we will reuse in this lesson</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="kw">def</span> plot_predictions(y_pred, y_true, title):</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>    plt.style.use(<span class="st">'ggplot'</span>)  <span class="co"># optional, that's only to define a visual style</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>    plt.scatter(y_pred, y_true, s<span class="op">=</span><span class="dv">10</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>    plt.axline((<span class="dv">0</span>,<span class="dv">0</span>),slope <span class="op">=</span> <span class="dv">1</span>, color <span class="op">=</span> <span class="st">"black"</span>) <span class="co"># plot diagonal reference line</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>    plt.xlabel(<span class="st">"predicted sunshine hours"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a>    plt.ylabel(<span class="st">"true sunshine hours"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a>plot_predictions(y_train_predicted, y_train, title<span class="op">=</span><span class="st">'Predictions on the training set'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_regression_predictions_trainset.png" alt="Scatter plot between predictions and true sunshine hours in Basel on the training set showing a concise spread" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>plot_predictions(y_test_predicted, y_test, title<span class="op">=</span><span class="st">'Predictions on the test set'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_regression_predictions_testset.png" alt="Scatter plot between predictions and true sunshine hours in Basel on the test set showing a wide spread" class="figure mx-auto d-block"></figure><div id="exercise-reflecting-on-our-results" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-reflecting-on-our-results" class="callout-inner">
<h3 class="callout-title">Exercise: Reflecting on our results</h3>
<div class="callout-content">
<ul>
<li>Is the performance of the model as you expected (or
better/worse)?</li>
<li>Is there a noteable difference between training set and test set?
And if so, any idea why?</li>
<li>(Optional) When developing a model, you will often vary different
aspects of your model like which features you use, model parameters and
architecture. It is important to settle on a single-number evaluation
metric to compare your models.
<ul>
<li>What single-number evaluation metric would you choose here and
why?</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>While the performance on the train set seems reasonable, the
performance on the test set is much worse. This is a common problem
called <strong>overfitting</strong>, which we will discuss in more
detail later.</p>
<div class="section level4">
<h4 id="optional-exercise">Optional exercise:<a class="anchor" aria-label="anchor" href="#optional-exercise"></a>
</h4>
<p>The metric that we are using: RMSE would be a good one. You could
also consider Mean Squared Error, that punishes large errors more
(because large errors create even larger squared errors). It is
important that if the model improves in performance on the basis of this
metric then that should also lead you a step closer to reaching your
goal: to predict tomorrow’s sunshine hours. If you feel that improving
the metric does not lead you closer to your goal, then it would be
better to choose a different metric</p>
</div>
</div>
</div>
</div>
</div>
<p>The accuracy on the training set seems fairly good. In fact,
considering that the task of predicting the daily sunshine hours is
really not easy it might even be surprising how well the model predicts
that (at least on the training set). Maybe a little too good? We also
see the noticeable difference between train and test set when
calculating the exact value of the RMSE:</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>train_metrics <span class="op">=</span> model.evaluate(X_train, y_train, return_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>test_metrics <span class="op">=</span> model.evaluate(X_test, y_test, return_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Train RMSE: </span><span class="sc">{:.2f}</span><span class="st">, Test RMSE: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(train_metrics[<span class="st">'root_mean_squared_error'</span>], test_metrics[<span class="st">'root_mean_squared_error'</span>]))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>24/24 [==============================] - 0s 442us/step - loss: 0.7092 - root_mean_squared_error: 0.8421
6/6 [==============================] - 0s 647us/step - loss: 16.4413 - root_mean_squared_error: 4.0548
Train RMSE: 0.84, Test RMSE: 4.05</code></pre>
</div>
<p>For those experienced with (classical) machine learning this might
look familiar. The plots above expose the signs of
<strong>overfitting</strong> which means that the model has to some
extent memorized aspects of the training data. As a result, it makes
much more accurate predictions on the training data than on unseen test
data.</p>
<p>Overfitting also happens in classical machine learning, but there it
is usually interpreted as the model having more parameters than the
training data would justify (say, a decision tree with too many branches
for the number of training instances). As a consequence one would reduce
the number of parameters to avoid overfitting. In deep learning the
situation is slightly different. It can - as for classical machine
learning - also be a sign of having a <em>too big</em> model, meaning a
model with too many parameters (layers and/or nodes). However, in deep
learning higher number of model parameters are often still considered
acceptable and models often perform best (in terms of prediction
accuracy) when they are at the verge of overfitting. So, in a way,
training deep learning models is always a bit like playing with
fire…</p>
<div class="section level3">
<h3 id="set-expectations-how-difficult-is-the-defined-problem">Set expectations: How difficult is the defined problem?<a class="anchor" aria-label="anchor" href="#set-expectations-how-difficult-is-the-defined-problem"></a>
</h3>
<p>Before we dive deeper into handling overfitting and (trying to)
improving the model performance, let us ask the question: How well must
a model perform before we consider it a good model?</p>
<p>Now that we defined a problem (predict tomorrow’s sunshine hours), it
makes sense to develop an intuition for how difficult the posed problem
is. Frequently, models will be evaluated against a so called
<strong>baseline</strong>. A baseline can be the current standard in the
field or if such a thing does not exist it could also be an intuitive
first guess or toy model. The latter is exactly what we would use for
our case.</p>
<p>Maybe the simplest sunshine hour prediction we can easily do is:
Tomorrow we will have the same number of sunshine hours as today.
(sounds very naive, but for many observables such as temperature this is
already a fairly good predictor)</p>
<p>We can take the <code>BASEL_sunshine</code> column of our data,
because this contains the sunshine hours from one day before what we
have as a label.</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>y_baseline_prediction <span class="op">=</span> X_test[<span class="st">'BASEL_sunshine'</span>]</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>plot_predictions(y_baseline_prediction, y_test, title<span class="op">=</span><span class="st">'Baseline predictions on the test set'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_regression_test_5_naive_baseline.png" alt="Scatter plot of predicted vs true sunshine hours in Basel for the test set where today's sunshine hours is considered as the true sunshine hours for tomorrow" class="figure mx-auto d-block"></figure><p>It is difficult to interpret from this plot whether our model is
doing better than the baseline. We can also have a look at the RMSE:</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> root_mean_squared_error</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>rmse_baseline <span class="op">=</span> root_mean_squared_error(y_test, y_baseline_prediction)</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Baseline:'</span>, rmse_baseline)</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Neural network: '</span>, test_metrics[<span class="st">'root_mean_squared_error'</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Baseline: 3.877323350410224
Neural network:  4.077792167663574</code></pre>
</div>
<p>Judging from the numbers alone, our neural network prediction would
be performing worse than the baseline.</p>
<div id="exercise-baseline" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-baseline" class="callout-inner">
<h3 class="callout-title">Exercise: Baseline</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>Looking at this baseline: Would you consider this a simple or a hard
problem to solve?</li>
<li>(Optional) Can you think of other baselines?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>This really depends on your definition of hard! The baseline gives a
more accurate prediction than just randomly predicting a number, so the
problem is not impossible to solve with machine learning. However, given
the structure of the data and our expectations with respect to quality
of prediction, it may remain hard to find a good algorithm which exceeds
our baseline by orders of magnitude.</li>
<li>There are a lot of possible answers. A slighly more complicated
baseline would be to take the average over the last couple of days.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="refine-the-model">9. Refine the model<a class="anchor" aria-label="anchor" href="#refine-the-model"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="watch-your-model-training-closely">Watch your model training closely<a class="anchor" aria-label="anchor" href="#watch-your-model-training-closely"></a>
</h3>
<p>As we saw when comparing the predictions for the training and the
test set, deep learning models are prone to overfitting. Instead of
iterating through countless cycles of model trainings and subsequent
evaluations with a reserved test set, it is common practice to work with
a second split off dataset to monitor the model during training. This is
the <em>validation set</em> which can be regarded as a second test set.
As with the test set, the datapoints of the <em>validation set</em> are
not used for the actual model training itself. Instead, we evaluate the
model with the <em>validation set</em> after every epoch during
training, for instance to stop if we see signs of clear overfitting.</p>
<p>Since we are adapting our model (tuning our hyperparameters) based on
this validation set, it is <em>very</em> important that it is kept
separate from the test set. If we used the same set, we would not know
whether our model truly generalizes or is only overfitting.</p>
<div id="test-vs.-validation-set" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="test-vs.-validation-set" class="callout-inner">
<h3 class="callout-title">Test vs. validation set</h3>
<div class="callout-content">
<p>Not everybody agrees on the terminology of test set versus validation
set. You might find examples in literature where these terms are used
the other way around. We are sticking to the definition that is
consistent with the Keras API. In there, the validation set can be used
during training, and the test set is reserved for afterwards.</p>
</div>
</div>
</div>
<p>Let’s give this a try!</p>
<p>We need to initiate a new model – otherwise Keras will simply assume
that we want to continue training the model we already trained
above.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],))</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>compile_model(model)</span></code></pre>
</div>
<p>But now we train it with the small addition of also passing it our
validation set:</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a>                    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a>                    epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a>                    validation_data<span class="op">=</span>(X_val, y_val))</span></code></pre>
</div>
<p>With this we can plot both the performance on the training data and
on the validation data!</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>plot_history(history, [<span class="st">'root_mean_squared_error'</span>, <span class="st">'val_root_mean_squared_error'</span>])</span></code></pre>
</div>
<figure><img src="fig/03_training_history_2_rmse.png" alt="Plot of RMSE vs epochs for the training set and the validation set which depicts a divergence between the two around 10 epochs." class="figure mx-auto d-block"></figure><div id="exercise-plot-the-training-progress." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-plot-the-training-progress." class="callout-inner">
<h3 class="callout-title">Exercise: plot the training progress.</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>Is there a difference between the training curves of training versus
validation data? And if so, what would this imply?</li>
<li>(Optional) Take a pen and paper, draw the perfect training and
validation curves. (This may seem trivial, but it will trigger you to
think about what you actually would like to see)</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>The difference in the two curves shows that something is not
completely right here. The error for the model predictions on the
validation set quickly seem to reach a plateau while the error on the
training set keeps decreasing. That is a common signature of
<em>overfitting</em>.</p>
<p>Optional:</p>
<p>Ideally you would like the training and validation curves to be
identical and slope down steeply to 0. After that the curves will just
consistently stay at 0.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="counteract-model-overfitting">Counteract model overfitting<a class="anchor" aria-label="anchor" href="#counteract-model-overfitting"></a>
</h3>
<p>Overfitting is a very common issue and there are many strategies to
handle it. Most similar to classical machine learning might to
<strong>reduce the number of parameters</strong>.</p>
<div id="exercise-try-to-reduce-the-degree-of-overfitting-by-lowering-the-number-of-parameters" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-try-to-reduce-the-degree-of-overfitting-by-lowering-the-number-of-parameters" class="callout-inner">
<h3 class="callout-title">Exercise: Try to reduce the degree of
overfitting by lowering the number of parameters</h3>
<div class="callout-content">
<p>We can keep the network architecture unchanged (2 dense layers + a
one-node output layer) and only play with the number of nodes per layer.
Try to lower the number of nodes in one or both of the two dense layers
and observe the changes to the training and validation losses. If time
is short: Suggestion is to run one network with only 10 and 5 nodes in
the first and second layer.</p>
<ol style="list-style-type: decimal">
<li>Is it possible to get rid of overfitting this way?</li>
<li>Does the overall performance suffer or does it mostly stay the
same?</li>
<li>(optional) How low can you go with the number of parameters without
notable effect on the performance on the validation set?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Show me the solution </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" aria-labelledby="headingSolution6" data-bs-parent="#accordionSolution6">
<div class="accordion-body">
<p>Let’s first adapt our <code>create_nn()</code> function so that we
can tweak the number of nodes in the 2 layers by passing arguments to
the function:</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="kw">def</span> create_nn(input_shape, nodes1<span class="op">=</span><span class="dv">100</span>, nodes2<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>   <span class="co"># Input layer</span></span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a>   inputs <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>input_shape, name<span class="op">=</span><span class="st">'input'</span>)</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a>   <span class="co"># Dense layers</span></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a>   layers_dense <span class="op">=</span> keras.layers.Dense(nodes1, <span class="st">'relu'</span>)(inputs)</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a>   layers_dense <span class="op">=</span> keras.layers.Dense(nodes2, <span class="st">'relu'</span>)(layers_dense)</span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a>   <span class="co"># Output layer</span></span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a>   outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">1</span>)(layers_dense)</span>
<span id="cb30-9"><a href="#cb30-9" tabindex="-1"></a>   <span class="cf">return</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"model_small"</span>)</span></code></pre>
</div>
<p>Let’s see if it works by creating a much smaller network with 10
nodes in the first layer, and 5 nodes in the second layer:</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],), nodes1<span class="op">=</span><span class="dv">10</span>, nodes2<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<pre><code>Model: "model_small"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                ┃ Output Shape        ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input (InputLayer)          │ (None, 89)          │             0 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_9 (Dense)             │ (None, 10)          │           900 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_10 (Dense)            │ (None, 5)           │            55 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_11 (Dense)            │ (None, 1)           │             6 │
└─────────────────────────────┴─────────────────────┴───────────────┘

 Total params: 961 (3.75 KB)

 Trainable params: 961 (3.75 KB)

 Non-trainable params: 0 (0.00 B)

</code></pre>
<p>Let’s compile and train this network:</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>compile_model(model)</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>                   batch_size <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a>                   epochs <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>                   validation_data<span class="op">=</span>(X_val, y_val))</span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a>plot_history(history, [<span class="st">'root_mean_squared_error'</span>, <span class="st">'val_root_mean_squared_error'</span>])</span></code></pre>
</div>
<figure><img src="fig/03_training_history_3_rmse_smaller_model.png" alt="Plot of RMSE vs epochs for the training set and the validation set with similar performance across the two sets. RMSE for the validation set diverges from RMSE for the training set after around 10 epochs but the difference in RMSE values for the two sets is much smaller than in the previous example." class="figure mx-auto d-block"></figure><ol style="list-style-type: decimal">
<li>With this smaller model we have reduced overfitting a bit, since the
training and validation loss are now closer to each other, and the
validation loss does now reach a plateau and does not further increase.
We have not completely avoided overfitting though.</li>
<li>In the case of this small example model, the validation RMSE seems
to end up around 3.2, which is much better than the 4.08 we had before.
Note that you can double check the actual score by calling
<code>model.evaluate()</code> on the test set.</li>
<li>In general, it quickly becomes a complicated search for the right
“sweet spot”, i.e. the settings for which overfitting will be (nearly)
avoided but the model still performs equally well. A model with 3
neurons in both layers seems to be around this spot, reaching an RMSE of
3.1 on the validation set. Reducing the number of nodes further
increases the validation RMSE again.</li>
</ol>
</div>
</div>
</div>
</div>
<p>We saw that reducing the number of parameters can be a strategy to
avoid overfitting. In practice, however, this is usually not the (main)
way to go when it comes to deep learning. One reason is, that finding
the sweet spot can be really hard and time consuming. And it has to be
repeated every time the model is adapted, e.g. when more training data
becomes available.</p>
</div>
<div class="section level3">
<h3 id="early-stopping-stop-when-things-are-looking-best">Early stopping: stop when things are looking best<a class="anchor" aria-label="anchor" href="#early-stopping-stop-when-things-are-looking-best"></a>
</h3>
<p>Arguable <strong>the</strong> most common technique to avoid (severe)
overfitting in deep learning is called <strong>early stopping</strong>.
As the name suggests, this technique just means that you stop the model
training if things do not seem to improve anymore. More specifically,
this usually means that the training is stopped if the validation loss
does not (notably) improve anymore. Early stopping is both intuitive and
effective to use, so it has become a standard addition for model
training.</p>
<p>To better study the effect, we can now safely go back to models with
many (too many?) parameters:</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],))</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>compile_model(model)</span></code></pre>
</div>
<p>To apply early stopping during training it is easiest to use Keras
<code>EarlyStopping</code> class. This allows to define the condition of
when to stop training. In our case we will say when the validation loss
is lowest. However, since we have seen some fluctuation of the losses
during training above we will also set <code>patience=10</code> which
means that the model will stop training if the validation loss has not
gone down for 10 epochs.</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb35-2"><a href="#cb35-2" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" tabindex="-1"></a>earlystopper <span class="op">=</span> EarlyStopping(</span>
<span id="cb35-4"><a href="#cb35-4" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb35-5"><a href="#cb35-5" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">10</span></span>
<span id="cb35-6"><a href="#cb35-6" tabindex="-1"></a>    )</span>
<span id="cb35-7"><a href="#cb35-7" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb35-9"><a href="#cb35-9" tabindex="-1"></a>                    batch_size <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb35-10"><a href="#cb35-10" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb35-11"><a href="#cb35-11" tabindex="-1"></a>                    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb35-12"><a href="#cb35-12" tabindex="-1"></a>                    callbacks<span class="op">=</span>[earlystopper])</span></code></pre>
</div>
<p>As before, we can plot the losses during training:</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>plot_history(history, [<span class="st">'root_mean_squared_error'</span>, <span class="st">'val_root_mean_squared_error'</span>])</span></code></pre>
</div>
<figure><img src="fig/03_training_history_3_rmse_early_stopping.png" alt="Plot of RMSE vs epochs for the training set and the validation set displaying similar performance across the two sets. RMSE for the validation set diverges slowly from RMSE for the training set after approximately 8 epochs, with RMSE for the validation set dropping more slowly." class="figure mx-auto d-block"></figure><p>This still seems to reveal the onset of overfitting, but the training
stops before the discrepancy between training and validation loss can
grow further. In addition to avoiding severe cases of overfitting, early
stopping has the advantage that the number of training epochs will be
regulated automatically.</p>
<p>What might be a bit unintuitive is that the training runs might now
end very rapidly. This raises the question: have we really reached an
optimum yet? And often the answer to this is “no”, which is why early
stopping frequently is combined with other approaches to avoid
overfitting. Overfitting means that a model (seemingly) performs better
on seen data compared to unseen data. One then often also says that it
does not “generalize” well. Techniques to avoid overfitting, or to
improve model generalization, are termed <strong>regularization
techniques</strong> and we will come back to this in <strong>episode
4</strong>.</p>
</div>
<div class="section level3">
<h3 id="batchnorm-the-standard-scaler-for-deep-learning">BatchNorm: the “standard scaler” for deep learning<a class="anchor" aria-label="anchor" href="#batchnorm-the-standard-scaler-for-deep-learning"></a>
</h3>
<p>A very common step in classical machine learning pipelines is to
scale the features, for instance by using sckit-learn’s
<code>StandardScaler</code>. This can in principle also be done for deep
learning. An alternative, more common approach, is to add
<strong>BatchNormalization</strong> layers (<a href="https://keras.io/api/layers/normalization_layers/batch_normalization/" class="external-link">documentation
of the batch normalization layer</a>) which will learn how to scale the
input values. Similar to dropout, batch normalization is available as a
network layer in Keras and can be added to the network in a similar way.
It does not require any additional parameter setting.</p>
<p>The <code>BatchNormalization</code> can be inserted as yet another
layer into the architecture.</p>
<div class="codewrapper sourceCode" id="cb37">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="kw">def</span> create_nn(input_shape):</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>    <span class="co"># Input layer</span></span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>    inputs <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>input_shape, name<span class="op">=</span><span class="st">'input'</span>)</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a>    <span class="co"># Dense layers</span></span>
<span id="cb37-6"><a href="#cb37-6" tabindex="-1"></a>    layers_dense <span class="op">=</span> keras.layers.BatchNormalization()(inputs) <span class="co"># This is new!</span></span>
<span id="cb37-7"><a href="#cb37-7" tabindex="-1"></a>    layers_dense <span class="op">=</span> keras.layers.Dense(<span class="dv">100</span>, <span class="st">'relu'</span>)(layers_dense)</span>
<span id="cb37-8"><a href="#cb37-8" tabindex="-1"></a>    layers_dense <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, <span class="st">'relu'</span>)(layers_dense)</span>
<span id="cb37-9"><a href="#cb37-9" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb37-11"><a href="#cb37-11" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">1</span>)(layers_dense)</span>
<span id="cb37-12"><a href="#cb37-12" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" tabindex="-1"></a>    <span class="co"># Defining the model and compiling it</span></span>
<span id="cb37-14"><a href="#cb37-14" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"model_batchnorm"</span>)</span>
<span id="cb37-15"><a href="#cb37-15" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],))</span>
<span id="cb37-17"><a href="#cb37-17" tabindex="-1"></a>compile_model(model)</span>
<span id="cb37-18"><a href="#cb37-18" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<p>This new layer appears in the model summary as well.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "model_batchnorm"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                ┃ Output Shape        ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input (InputLayer)          │ (None, 89)          │             0 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ batch_normalization_1       │ (None, 89)          │           356 │
│ (BatchNormalization)        │                     │               │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_6 (Dense)             │ (None, 100)         │         9,000 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_7 (Dense)             │ (None, 50)          │         5,050 │
├─────────────────────────────┼─────────────────────┼───────────────┤
│ dense_8 (Dense)             │ (None, 1)           │            51 │
└─────────────────────────────┴─────────────────────┴───────────────┘

 Total params: 14,457 (56.47 KB)

 Trainable params: 14,279 (55.78 KB)

 Non-trainable params: 178 (712.00 B)</code></pre>
</div>
<p>We can train the model again as follows:</p>
<div class="codewrapper sourceCode" id="cb39">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>                    batch_size <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a>                    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a>                    callbacks<span class="op">=</span>[earlystopper])</span>
<span id="cb39-6"><a href="#cb39-6" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" tabindex="-1"></a>plot_history(history, [<span class="st">'root_mean_squared_error'</span>, <span class="st">'val_root_mean_squared_error'</span>])</span></code></pre>
</div>
<figure><img src="fig/03_training_history_5_rmse_batchnorm.png" alt="Plot of error vs epochs for the training set and the validation set displaying similar performance across the two sets. RMSE for the validation set drops more than for the training set at first, tracks the training error until approximately 50 epochs, then begins to gradually increase while error for the training set continues to gradually decrease." class="figure mx-auto d-block"></figure><div id="batchnorm-parameters" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="batchnorm-parameters" class="callout-inner">
<h3 class="callout-title">Batchnorm parameters</h3>
<div class="callout-content">
<p>You may have noticed that the number of parameters of the Batchnorm
layers corresponds to 4 parameters per input node. These are the moving
mean, moving standard deviation, additional scaling factor (gamma) and
offset factor (beta). There is a difference in behavior for Batchnorm
between training and prediction time. During training time, the data is
scaled with the mean and standard deviation of the batch. During
prediction time, the moving mean and moving standard deviation of the
training set is used instead. The additional parameters gamma and beta
are introduced to allow for more flexibility in output values, and are
used in both training and prediction.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="run-on-test-set-and-compare-to-naive-baseline">Run on test set and compare to naive baseline<a class="anchor" aria-label="anchor" href="#run-on-test-set-and-compare-to-naive-baseline"></a>
</h3>
<p>It seems that no matter what we add, the overall loss does not
decrease much further (we at least avoided overfitting though!). Let us
again plot the results on the test set:</p>
<div class="codewrapper sourceCode" id="cb40">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a>y_test_predicted <span class="op">=</span> model.predict(X_test)</span>
<span id="cb40-2"><a href="#cb40-2" tabindex="-1"></a>plot_predictions(y_test_predicted, y_test, title<span class="op">=</span><span class="st">'Predictions on the test set'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_regression_test_5_dropout_batchnorm.png" alt="Scatter plot between predictions and true sunshine hours for Basel on the test set, showing a loose positive correlation." class="figure mx-auto d-block"></figure><p>Well, the above is certainly not perfect. But how good or bad is
this? Maybe not good enough to plan your picnic for tomorrow. But let’s
better compare it to the naive baseline we created in the beginning.
What would you say, did we improve on that?</p>
<div id="exercise-simplify-the-model-and-add-data" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-simplify-the-model-and-add-data" class="callout-inner">
<h3 class="callout-title">Exercise: Simplify the model and add data</h3>
<div class="callout-content">
<p>You may have been wondering why we are including weather observations
from multiple cities to predict sunshine hours only in Basel. The
weather is a complex phenomenon with correlations over large distances
and time scales, but what happens if we limit ourselves to only one
city?</p>
<ol style="list-style-type: decimal">
<li>Since we will be reducing the number of features quite
significantly, we could afford to include more data. Instead of using
only 3 years, use 8 or 9 years!</li>
<li>Only use the features in the dataset that are for Basel, remove the
data for other cities. You can use something like:</li>
</ol>
<div class="codewrapper sourceCode" id="cb41">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> X_data.columns <span class="cf">if</span> c[:<span class="dv">5</span>] <span class="op">==</span> <span class="st">'BASEL'</span>]</span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a>X_data <span class="op">=</span> X_data[cols]</span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Now rerun the last model we defined which included the BatchNorm
layer. Recreate the scatter plot comparing your predictions with the
true values, and evaluate the model by computing the RMSE on the test
score. Note that even though we will use many more observations than
previously, the network should still train quickly because we reduce the
number of features (columns). Is the prediction better compared to what
we had before?</li>
<li>(Optional) Try to train a model on all years that are available, and
all features from all cities. How does it perform?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution7" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution7" aria-expanded="false" aria-controls="collapseSolution7">
  <h4 class="accordion-header" id="headingSolution7"> Show me the solution </h4>
</button>
<div id="collapseSolution7" class="accordion-collapse collapse" aria-labelledby="headingSolution7" data-bs-parent="#accordionSolution7">
<div class="accordion-body">
<div class="section level3">
<h3 id="use-9-years-out-of-the-dataset">1. Use 9 years out of the dataset<a class="anchor" aria-label="anchor" href="#use-9-years-out-of-the-dataset"></a>
</h3>
<div class="codewrapper sourceCode" id="cb42">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a>nr_rows <span class="op">=</span> <span class="dv">365</span><span class="op">*</span><span class="dv">9</span></span>
<span id="cb42-2"><a href="#cb42-2" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb42-3"><a href="#cb42-3" tabindex="-1"></a>X_data <span class="op">=</span> data.loc[:nr_rows].drop(columns<span class="op">=</span>[<span class="st">'DATE'</span>, <span class="st">'MONTH'</span>])</span>
<span id="cb42-4"><a href="#cb42-4" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" tabindex="-1"></a><span class="co"># labels (sunshine hours the next day)</span></span>
<span id="cb42-6"><a href="#cb42-6" tabindex="-1"></a>y_data <span class="op">=</span> data.loc[<span class="dv">1</span>:(nr_rows <span class="op">+</span> <span class="dv">1</span>)][<span class="st">"BASEL_sunshine"</span>]</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="only-use-features-for-basel">2. Only use features for Basel<a class="anchor" aria-label="anchor" href="#only-use-features-for-basel"></a>
</h3>
<div class="codewrapper sourceCode" id="cb43">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="co"># only use columns with 'BASEL'</span></span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> X_data.columns <span class="cf">if</span> c[:<span class="dv">5</span>] <span class="op">==</span> <span class="st">'BASEL'</span>]</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>X_data <span class="op">=</span> X_data[cols]</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="rerun-the-model-and-evaluate-it">3. Rerun the model and evaluate it<a class="anchor" aria-label="anchor" href="#rerun-the-model-and-evaluate-it"></a>
</h3>
<p>Do the train-test-validation split:</p>
<div class="codewrapper sourceCode" id="cb44">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a>X_train, X_holdout, y_train, y_holdout <span class="op">=</span> train_test_split(X_data, y_data, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a>X_val, X_test, y_val, y_test <span class="op">=</span> train_test_split(X_holdout, y_holdout, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre>
</div>
<p>Create the network. We can re-use the <code>create_nn()</code>
function that we already have. Because we have reduced the number of
input features the number of parameters in the network goes down from
14457 to 6137.</p>
<div class="codewrapper sourceCode" id="cb45">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="co"># create the network and view its summary</span></span>
<span id="cb45-2"><a href="#cb45-2" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>(X_data.shape[<span class="dv">1</span>],))</span>
<span id="cb45-3"><a href="#cb45-3" tabindex="-1"></a>compile_model(model)</span>
<span id="cb45-4"><a href="#cb45-4" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<p>Fit with early stopping and output showing performance on validation
set:</p>
<div class="codewrapper sourceCode" id="cb46">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb46-2"><a href="#cb46-2" tabindex="-1"></a>                   batch_size <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb46-3"><a href="#cb46-3" tabindex="-1"></a>                   epochs <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb46-4"><a href="#cb46-4" tabindex="-1"></a>                   validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb46-5"><a href="#cb46-5" tabindex="-1"></a>                   callbacks<span class="op">=</span>[earlystopper],</span>
<span id="cb46-6"><a href="#cb46-6" tabindex="-1"></a>                   verbose <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb46-7"><a href="#cb46-7" tabindex="-1"></a>plot_history(history, [<span class="st">'root_mean_squared_error'</span>, <span class="st">'val_root_mean_squared_error'</span>])</span></code></pre>
</div>
<p>Create a scatter plot to compare with true observations:</p>
<div class="codewrapper sourceCode" id="cb47">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a>y_test_predicted <span class="op">=</span> model.predict(X_test)</span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a>plot_predictions(y_test_predicted, y_test, title<span class="op">=</span><span class="st">'Predictions on the test set'</span>)</span></code></pre>
</div>
<figure><img src="fig/03_scatter_plot_basel_model.png" alt="Scatterplot of predictions and true number of sunshine hours for all cities, showing many data points distributed in a very loose positive correlation." class="figure mx-auto d-block"></figure><p>Compute the RMSE on the test set:</p>
<div class="codewrapper sourceCode" id="cb48">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a>test_metrics <span class="op">=</span> model.evaluate(X_test, y_test, return_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE: </span><span class="sc">{</span>test_metrics[<span class="st">"root_mean_squared_error"</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Test RMSE: 3.3761725425720215</code></pre>
</div>
<p>This RMSE is already a lot better compared to what we had before and
certainly better than the baseline. Additionally, it could be further
improved with hyperparameter tuning.</p>
<p>Note that because we ran <code>train_test_split()</code> again, we
are evaluating on a different test set than before. In the real world it
is important to always compare results on the exact same test set.</p>
</div>
<div class="section level3">
<h3 id="optional-train-a-model-on-all-years-and-all-features-available-">4. (optional) Train a model on all years and all features
available.<a class="anchor" aria-label="anchor" href="#optional-train-a-model-on-all-years-and-all-features-available-"></a>
</h3>
<p>You can tweak the above code to use all years and all features:</p>
<div class="codewrapper sourceCode" id="cb50">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="co"># We cannot take all rows, because we need to be able to take the sunshine hours of the next day</span></span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>nr_rows <span class="op">=</span> <span class="bu">len</span>(data) <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb50-3"><a href="#cb50-3" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb50-5"><a href="#cb50-5" tabindex="-1"></a>X_data <span class="op">=</span> data.loc[:nr_rows].drop(columns<span class="op">=</span>[<span class="st">'DATE'</span>, <span class="st">'MONTH'</span>])</span>
<span id="cb50-6"><a href="#cb50-6" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" tabindex="-1"></a><span class="co"># labels (sunshine hours the next day)</span></span>
<span id="cb50-8"><a href="#cb50-8" tabindex="-1"></a>y_data <span class="op">=</span> data.loc[<span class="dv">1</span>:(nr_rows <span class="op">+</span> <span class="dv">1</span>)][<span class="st">"BASEL_sunshine"</span>]</span></code></pre>
</div>
<p>For the rest you can use the same code as above to train and evaluate
the model</p>
<p>This results in an RMSE on the test set of 3.23 (your result can be
different, but should be in the same range). From this we can conclude
that adding more training data results in even better performance!</p>
</div>
</div>
</div>
</div>
</div>
<div id="tensorboard" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="tensorboard" class="callout-inner">
<h3 class="callout-title">Tensorboard</h3>
<div class="callout-content">
<p>If we run many different experiments with different architectures, it
can be difficult to keep track of these different models or compare the
achieved performance. We can use <em>tensorboard</em>, a framework that
keeps track of our experiments and shows graphs like we plotted above.
Tensorboard is included in our tensorflow installation by default. To
use it, we first need to add a <em>callback</em> to our (compiled) model
that saves the progress of training performance in a logs rectory:</p>
<div class="codewrapper sourceCode" id="cb51">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> TensorBoard</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a>log_dir <span class="op">=</span> <span class="st">"logs/fit/"</span> <span class="op">+</span> datetime.datetime.now().strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>) <span class="co"># You can adjust this to add a more meaningful model name</span></span>
<span id="cb51-4"><a href="#cb51-4" tabindex="-1"></a>tensorboard_callback <span class="op">=</span> TensorBoard(log_dir<span class="op">=</span>log_dir, histogram_freq<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb51-5"><a href="#cb51-5" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb51-6"><a href="#cb51-6" tabindex="-1"></a>                   batch_size <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb51-7"><a href="#cb51-7" tabindex="-1"></a>                   epochs <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb51-8"><a href="#cb51-8" tabindex="-1"></a>                   validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb51-9"><a href="#cb51-9" tabindex="-1"></a>                   callbacks<span class="op">=</span>[tensorboard_callback],</span>
<span id="cb51-10"><a href="#cb51-10" tabindex="-1"></a>                   verbose <span class="op">=</span> <span class="dv">2</span>)</span></code></pre>
</div>
<p>You can launch the tensorboard interface from a Jupyter notebook,
showing all trained models: <!--cce:skip--></p>
<pre><code>%load_ext tensorboard
%tensorboard --logdir logs/fit</code></pre>
<p>Which will show an interface that looks something like this: <img src="fig/03_tensorboard.png" alt="Tensorboard graphical user interface." class="figure"></p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="save-model">10. Save model<a class="anchor" aria-label="anchor" href="#save-model"></a>
</h2>
<hr class="half-width">
<p>Now that we have a somewhat acceptable model, let us not forget to
save it for future users to benefit from our explorative efforts!</p>
<div class="codewrapper sourceCode" id="cb53">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a>model.save(<span class="st">'my_tuned_weather_model.keras'</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="outlook">Outlook<a class="anchor" aria-label="anchor" href="#outlook"></a>
</h2>
<hr class="half-width">
<p>Correctly predicting tomorrow’s sunshine hours is apparently not that
simple. Our models get the general trends right, but still predictions
vary quite a bit and can even be far off.</p>
<div id="open-question-what-could-be-next-steps-to-further-improve-the-model" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="open-question-what-could-be-next-steps-to-further-improve-the-model" class="callout-inner">
<h3 class="callout-title">Open question: What could be next steps to
further improve the model?</h3>
<div class="callout-content">
<p>With unlimited options to modify the model architecture or to play
with the training parameters, deep learning can trigger very extensive
hunting for better and better results. Usually models are “well
behaving” in the sense that small changes to the architectures also only
result in small changes of the performance (if any). It is often
tempting to hunt for some magical settings that will lead to much better
results. But do those settings exist? Applying common sense is often a
good first step to make a guess of how much better results
<em>could</em> be. In the present case we might certainly not expect to
be able to reliably predict sunshine hours for the next day with 5-10
minute precision. But how much better our model could be exactly, often
remains difficult to answer.</p>
<ul>
<li>What changes to the model architecture might make sense to
explore?</li>
<li>Ignoring changes to the model architecture, what might notably
improve the prediction quality?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution8" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution8" aria-expanded="false" aria-controls="collapseSolution8">
  <h4 class="accordion-header" id="headingSolution8"> Show me the solution </h4>
</button>
<div id="collapseSolution8" class="accordion-collapse collapse" aria-labelledby="headingSolution8" data-bs-parent="#accordionSolution8">
<div class="accordion-body">
<p>This is an open question. And we don’t actually know how far one
could push this sunshine hour prediction (try it out yourself if you
like! We’re curious!). But there are a few things that might be worth
exploring. Regarding the model architecture:</p>
<ul>
<li>In the present case we do not see a magical silver bullet to
suddenly boost the performance. But it might be worth testing if
<em>deeper</em> networks do better (more layers).</li>
</ul>
<p>Other changes that might impact the quality notably:</p>
<ul>
<li>The most obvious answer here would be: more data! Even this will not
always work (e.g. if data is very noisy and uncorrelated, more data
might not add much).</li>
<li>Related to more data: use data augmentation. By creating realistic
variations of the available data, the model might improve as well.</li>
<li>More data can mean more data points (you can test it yourself by
taking more than the 3 years we used here!)</li>
<li>More data can also mean more features! What about adding the
month?</li>
<li>The labels we used here (sunshine hours) are highly biased, many
days with no or nearly no sunshine but a few with &gt;10 hours.
Techniques such as oversampling or undersampling might handle such
biased labels better.</li>
</ul>
<p>Another alternative would be to not only look at data from one day,
but use the data of a longer period such as a full week. This will turn
the data into time series data which in turn might also make it worth to
apply different model architectures…</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Separate training, validation, and test sets allows monitoring and
evaluating your model.</li>
<li>Batchnormalization scales the data as part of the model.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-4-advanced-layer-types"><p>Content from <a href="4-advanced-layer-types.html">Advanced layer types</a></p>
<hr>
<p>Last updated on 2025-09-03 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/4-advanced-layer-types.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Why do we need different types of layers?</li>
<li>What are good network designs for image data?</li>
<li>What is a convolutional layer?</li>
<li>How can we use different types of layers to prevent
overfitting?</li>
<li>What is hyperparameter tuning?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand why convolutional and pooling layers are useful for image
data</li>
<li>Implement a convolutional neural network on an image dataset</li>
<li>Use a dropout layer to prevent overfitting</li>
<li>Be able to tune the hyperparameters of a Keras model</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="different-types-of-layers">Different types of layers<a class="anchor" aria-label="anchor" href="#different-types-of-layers"></a>
</h2>
<hr class="half-width">
<p>Networks are like onions: a typical neural network consists of many
layers. In fact, the word <em>deep</em> in <em>deep learning</em> refers
to the many layers that make the network deep.</p>
<p>So far, we have seen one type of layer, namely the <strong>fully
connected</strong>, or <strong>dense</strong> layer. This layer is
called fully connected, because all input neurons are taken into account
by each output neuron. The number of parameters that need to be learned
by the network, is thus in the order of magnitude of the number of input
neurons times the number of hidden neurons.</p>
<p>However, there are many different types of layers that perform
different calculations and take different inputs. In this episode we
will take a look at <strong>convolutional layers</strong> and
<strong>dropout layers</strong>, which are useful in the context of
image data, but also in many other types of (structured) data.</p>
</section><section><h2 class="section-heading" id="formulate-outline-the-problem-image-classification">1. Formulate / Outline the problem: Image classification<a class="anchor" aria-label="anchor" href="#formulate-outline-the-problem-image-classification"></a>
</h2>
<hr class="half-width">
<p>The <a href="https://www.kaggle.com/datasets/mlcommons/the-dollar-street-dataset" class="external-link">MLCommons
Dollar Street Dataset</a> is a collection of images of everyday
household items from homes around the world that visually captures
socioeconomic diversity of traditionally underrepresented populations.
We use <a href="https://zenodo.org/records/10970014" class="external-link">a subset of the
original dataset</a> that can be used for multiclass classification with
10 categories. Let’s load the data:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> pathlib</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>DATA_FOLDER <span class="op">=</span> pathlib.Path(<span class="st">'data/dataset_dollarstreet/'</span>) <span class="co"># change to location where you stored the data</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>train_images <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'train_images.npy'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>val_images <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'test_images.npy'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>train_labels <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'train_labels.npy'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>val_labels <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'test_labels.npy'</span>)</span></code></pre>
</div>
<div id="a-note-about-data-provenance" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="a-note-about-data-provenance" class="callout-inner">
<h3 class="callout-title">A note about data provenance</h3>
<div class="callout-content">
<p>In an earlier version, this part of the lesson used a different
example dataset. During <a href="https://github.com/carpentries-lab/reviews/issues/25#issuecomment-1953271802" class="external-link">peer
review</a>, the decision was made to replace that dataset due to the way
it had been compiled using images “scraped” from the internet without
permission from or credit to the original creators of those images.
Unfortunately, uncredited use of images is a common problem among
datasets used to benchmark models for image classification.</p>
<p>The Dollar Street dataset was chosen for use in the lesson as it
contains only images <a href="https://www.gapminder.org/dollar-street/about?" class="external-link">created by the
Gapminder project</a> for the purposes of using them in the dataset. The
original Dollar Street dataset is very large – more than 100 GB – with
the potential to grow even bigger, so we created a subset for use in
this lesson.</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="dollar-street-10-dataset">Dollar Street 10 dataset<a class="anchor" aria-label="anchor" href="#dollar-street-10-dataset"></a>
</h3>
<p>The Dollar Street 10 dataset consists of images of 10 different
classes, this is the mapping of the categories:</p>
<table class="table">
<thead><tr class="header">
<th>Category</th>
<th>label</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>day bed</td>
<td>0</td>
</tr>
<tr class="even">
<td>dishrag</td>
<td>1</td>
</tr>
<tr class="odd">
<td>plate</td>
<td>2</td>
</tr>
<tr class="even">
<td>running shoe</td>
<td>3</td>
</tr>
<tr class="odd">
<td>soap dispenser</td>
<td>4</td>
</tr>
<tr class="even">
<td>street sign</td>
<td>5</td>
</tr>
<tr class="odd">
<td>table lamp</td>
<td>6</td>
</tr>
<tr class="even">
<td>tile roof</td>
<td>7</td>
</tr>
<tr class="odd">
<td>toilet seat</td>
<td>8</td>
</tr>
<tr class="even">
<td>washing machine</td>
<td>9</td>
</tr>
</tbody>
</table>
<figure><img src="fig/04_dollar_street_10.png" alt="A 5 by 5 grid of 25 sample images from the dollar street 10 data-set. Each image is labelled with a category, for example: 'street sign' or 'soap dispenser'." class="figure mx-auto d-block"><div class="figcaption">Sample images from the Dollar Street 10 dataset.
Each image is labelled with a category, for example: ‘street sign’ or
‘soap dispenser’</div>
</figure>
</div>
</section><section><h2 class="section-heading" id="identify-inputs-and-outputs">2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#identify-inputs-and-outputs"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="explore-the-data">Explore the data<a class="anchor" aria-label="anchor" href="#explore-the-data"></a>
</h3>
<p>Let’s do a quick exploration of the dimensions of the data:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>train_images.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(878, 64, 64, 3)</code></pre>
</div>
<p>The first value, <code>878</code>, is the number of training images
in the dataset. The remainder of the shape, namely
<code>(64, 64, 3)</code>, denotes the dimension of one image. The last
value 3 is typical for color images, and stands for the three color
channels <strong>R</strong>ed, <strong>G</strong>reen,
<strong>B</strong>lue.</p>
<div id="number-of-features-in-dollar-street-10" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="number-of-features-in-dollar-street-10" class="callout-inner">
<h3 class="callout-title">Number of features in Dollar Street 10</h3>
<div class="callout-content">
<p>How many features does one image in the Dollar Street 10 dataset
have?</p>
<ul>
<li>A. 64</li>
<li>B. 4096</li>
<li>C. 12288</li>
<li>D. 878</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>The correct solution is C: 12288</p>
<p>There are 4096 pixels in one image (64 * 64), each pixel has 3
channels (RGB). So 4096 * 3 = 12288.</p>
</div>
</div>
</div>
</div>
<p>We can find out the range of values of our input data as follows:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>train_images.<span class="bu">min</span>(), train_images.<span class="bu">max</span>()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(0, 255)</code></pre>
</div>
<p>So the values of the three channels range between <code>0</code> and
<code>255</code>. Lastly, we inspect the dimension of the labels:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>train_labels.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(878,)</code></pre>
</div>
<p>So we have, for each image, a single value denoting the label. To
find out what the possible values of these labels are:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>train_labels.<span class="bu">min</span>(), train_labels.<span class="bu">max</span>()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(0, 9)</code></pre>
</div>
<p>The values of the labels range between <code>0</code> and
<code>9</code>, denoting 10 different classes.</p>
</div>
</section><section><h2 class="section-heading" id="prepare-data">3. Prepare data<a class="anchor" aria-label="anchor" href="#prepare-data"></a>
</h2>
<hr class="half-width">
<p>The training set consists of 878 images of <code>64x64</code> pixels
and 3 channels (RGB values). The RGB values are between <code>0</code>
and <code>255</code>. For input of neural networks, it is better to have
small input values. So we normalize our data between <code>0</code> and
<code>1</code>:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>train_images <span class="op">=</span> train_images <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>val_images <span class="op">=</span> val_images <span class="op">/</span> <span class="fl">255.0</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="choose-a-pretrained-model-or-start-building-architecture-from-scratch">4. Choose a pretrained model or start building architecture from
scratch<a class="anchor" aria-label="anchor" href="#choose-a-pretrained-model-or-start-building-architecture-from-scratch"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="convolutional-layers">Convolutional layers<a class="anchor" aria-label="anchor" href="#convolutional-layers"></a>
</h3>
<p>In the previous episodes, we used ‘fully connected layers’ , that
connected all input values of a layer to all outputs of a layer. This
results in many connections, and thus many weights to be learned, in the
network. Note that our input dimension is now quite high (even with
small pictures of <code>64x64</code> pixels): we have 12288
features.</p>
<div id="parameters-exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="parameters-exercise-1" class="callout-inner">
<h3 class="callout-title">Number of parameters</h3>
<div class="callout-content">
<p>Suppose we create a single Dense (fully connected) layer with 100
hidden units that connect to the input pixels, how many parameters does
this layer have?</p>
<ul>
<li>A. 1228800</li>
<li>B. 1228900</li>
<li>C. 100</li>
<li>D. 12288</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>The correct answer is B: Each entry of the input dimensions, i.e. the
<code>shape</code> of one single data point, is connected with 100
neurons of our hidden layer, and each of these neurons has a bias term
associated to it. So we have <code>1228900</code> parameters to
learn.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>width, height <span class="op">=</span> (<span class="dv">64</span>, <span class="dv">64</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>n_hidden_neurons <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>n_bias <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>n_input_items <span class="op">=</span> width <span class="op">*</span> height <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>n_parameters <span class="op">=</span> (n_input_items <span class="op">*</span> n_hidden_neurons) <span class="op">+</span> n_bias</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>n_parameters</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">1228900</span></span></code></pre>
</div>
<p>We can also check this by building the layer in Keras:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(n_input_items,))</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">100</span>)(inputs)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>model <span class="op">=</span> keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer (InputLayer)     │ (None, 12288)        │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense (Dense)                │ (None, 100)          │   1,228,900 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 1,228,900 (4.69 MB)

 Trainable params: 1,228,900 (4.69 MB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>We can decrease the number of units in our hidden layer, but this
also decreases the number of patterns our network can remember.
Moreover, if we increase the image size, the number of weights will
‘explode’, even though the task of recognizing large images is not
necessarily more difficult than the task of recognizing small
images.</p>
<p>The solution is that we make the network learn in a ‘smart’ way. The
features that we learn should be similar both for small and large
images, and similar features (e.g. edges, corners) can appear anywhere
in the image (in mathematical terms: <em>translation invariant</em>). We
do this by making use of a concept from image processing that predates
deep learning.</p>
<p>A <strong>convolution matrix</strong>, or <strong>kernel</strong>, is
a matrix transformation that we ‘slide’ over the image to calculate
features at each position of the image. For each pixel, we calculate the
matrix product between the kernel and the pixel with its surroundings. A
kernel is typically small, between 3x3 and 7x7 pixels. We can for
example think of the 3x3 kernel:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[-1, -1, -1],
 [0, 0, 0]
 [1, 1, 1]]</code></pre>
</div>
<p>This kernel will give a high value to a pixel if it is on a
horizontal border between dark and light areas. Note that for RGB
images, the kernel should also have a depth of 3.</p>
<p>In the following image, we see the effect of such a kernel on the
values of a single-channel image. The red cell in the output matrix is
the result of multiplying and summing the values of the red square in
the input, and the kernel. Applying this kernel to a real image shows
that it indeed detects horizontal edges.</p>
<figure><img src="fig/04_conv_matrix.png" style="width:90%" alt="Example of a convolution matrix calculation" class="figure mx-auto d-block"></figure><figure><img src="fig/04_conv_image.png" style="width:100%" alt="Convolution example on an image of a cat to extract features" class="figure mx-auto d-block"></figure><p>In our <strong>convolutional layer</strong> our hidden units are a
number of convolutional matrices (or kernels), where the values of the
matrices are the weights that we learn in the training process. The
output of a convolutional layer is an ‘image’ for each of the kernels,
that gives the output of the kernel applied to each pixel.</p>
<div id="playing-with-convolutions" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="playing-with-convolutions" class="callout-inner">
<h3 class="callout-title">Playing with convolutions</h3>
<div class="callout-content">
<p>Convolutions applied to images can be hard to grasp at first.
Fortunately there are resources out there that enable users to
interactively play around with images and convolutions:</p>
<ul>
<li>
<a href="https://setosa.io/ev/image-kernels/" class="external-link">Image kernels
explained</a> shows how different convolutions can achieve certain
effects on an image, like sharpening and blurring.</li>
<li>
<a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#" class="external-link">The
convolutional neural network cheat sheet</a> shows animated examples of
the different components of convolutional neural nets</li>
</ul>
</div>
</div>
</div>
<div id="border-pixels" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="border-pixels" class="callout-inner">
<h3 class="callout-title">Border pixels</h3>
<div class="callout-content">
<p>What, do you think, happens to the border pixels when applying a
convolution?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>There are different ways of dealing with border pixels. You can
ignore them, which means that your output image is slightly smaller then
your input. It is also possible to ‘pad’ the borders, e.g. with the same
value or with zeros, so that the convolution can also be applied to the
border pixels. In that case, the output image will have the same size as
the input image.</p>
<p><a href="https://datacarpentry.org/image-processing/06-blurring.html#callout4" class="external-link">This
callout in the Data Carpentry: Image Processing with Python
curriculum</a> provides more detail about convolution at the boundaries
of an image, in the context of applying a <em>Gaussian blur</em>.</p>
</div>
</div>
</div>
</div>
<div id="parameters-exercise-3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="parameters-exercise-3" class="callout-inner">
<h3 class="callout-title">Number of model parameters</h3>
<div class="callout-content">
<p>Suppose we apply a convolutional layer with 100 kernels of size 3 * 3
* 3 (the last dimension applies to the rgb channels) to our images of 64
* 64 * 3 pixels. How many parameters do we have? Assume, for simplicity,
that the kernels do not use bias terms. Compare this to the answer of
the earlier exercise, <a href="#parameters-exercise-1">“Number of
Parameters”</a>.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p>We have 100 matrices with 3 * 3 * 3 = 27 values each so that gives 27
* 100 = 2700 weights. This is a magnitude of 2000 less than the fully
connected layer with 100 units! Nevertheless, as we will see,
convolutional networks work very well for image data. This illustrates
the expressiveness of convolutional layers.</p>
</div>
</div>
</div>
</div>
<p>So let us look at a network with a few convolutional layers. We need
to finish with a Dense layer to connect the output cells of the
convolutional layer to the outputs for our classes.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>keras.utils.set_random_seed(<span class="dv">2</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"dollar_street_model_small"</span>)</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "dollar_street_model_small"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)   │ (None, 64, 64, 3)    │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d (Conv2D)              │ (None, 62, 62, 50)   │       1,400 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_1 (Conv2D)            │ (None, 60, 60, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ flatten (Flatten)            │ (None, 180000)       │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_1 (Dense)              │ (None, 10)           │   1,800,010 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 1,823,960 (6.96 MB)

 Trainable params: 1,823,960 (6.96 MB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
<div id="convolutional-neural-network" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="convolutional-neural-network" class="callout-inner">
<h3 class="callout-title">Convolutional Neural Network</h3>
<div class="callout-content">
<p>Inspect the network above:</p>
<ul>
<li>What do you think is the function of the <code>Flatten</code>
layer?</li>
<li>Which layer has the most parameters? Do you find this
intuitive?</li>
<li>(optional) This dataset is similar to the often used CIFAR-10
dataset. We can get inspiration for neural network architectures that
could work on our dataset here: <a href="https://paperswithcode.com/sota/image-classification-on-cifar-10" class="external-link uri">https://paperswithcode.com/sota/image-classification-on-cifar-10</a>
. Pick a model and try to understand how it works.</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" data-bs-parent="#accordionSolution5" aria-labelledby="headingSolution5">
<div class="accordion-body">
<ul>
<li>The Flatten layer converts the 60x60x50 output of the convolutional
layer into a single one-dimensional vector, that can be used as input
for a dense layer.</li>
<li>The last dense layer has the most parameters. This layer connects
every single output ‘pixel’ from the convolutional layer to the 10
output classes. That results in a large number of connections, so a
large number of parameters. This undermines a bit the expressiveness of
the convolutional layers, that have much fewer parameters.</li>
</ul>
</div>
</div>
</div>
</div>

<div id="search-for-existing-architectures-or-pretrained-models" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="search-for-existing-architectures-or-pretrained-models" class="callout-inner">
<h3 class="callout-title">Search for existing architectures or
pretrained models</h3>
<div class="callout-content">
<p>So far in this course we have built neural networks from scratch,
because we want you to fully understand the basics of Keras. In the real
world however, you would first search for existing solutions to your
problem.</p>
<p>You could for example search for ‘large CNN image classification
Keras implementation’, and see if you can find any Keras implementations
of more advanced architectures that you could reuse. A lot of the
best-performing architectures for image classification are convolutional
neural networks or at least have some elements in common. Therefore, we
will introduce convolutional neural networks here, and the best way to
teach you is by developing a neural network from scratch!</p>
</div>
</div>
</div>

</div>
<div class="section level3">
<h3 id="pooling-layers">Pooling layers<a class="anchor" aria-label="anchor" href="#pooling-layers"></a>
</h3>
<p>Often in convolutional neural networks, the convolutional layers are
intertwined with <strong>Pooling layers</strong>. As opposed to the
convolutional layer, the pooling layer actually alters the dimensions of
the image and reduces it by a scaling factor. It is basically decreasing
the resolution of your picture. The rationale behind this is that higher
layers of the network should focus on higher-level features of the
image. By introducing a pooling layer, the subsequent convolutional
layer has a broader ‘view’ on the original image.</p>
<p>Let’s put it into practice. We compose a Convolutional network with
two convolutional layers and two pooling layers.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="kw">def</span> create_nn(input_shape):</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x) <span class="co"># a new maxpooling layer</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x) <span class="co"># a new maxpooling layer (same as maxpool)</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x) <span class="co"># a new Dense layer</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"dollar_street_model"</span>)</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>model <span class="op">=</span> create_nn(input_shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "dollar_street_model"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)   │ (None, 64, 64, 3)    │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_2 (Conv2D)            │ (None, 62, 62, 50)   │       1,400 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d (MaxPooling2D) │ (None, 31, 31, 50)   │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_3 (Conv2D)            │ (None, 29, 29, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_1              │ (None, 14, 14, 50)   │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ flatten_1 (Flatten)          │ (None, 9800)         │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_2 (Dense)              │ (None, 50)           │     490,050 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_3 (Dense)              │ (None, 10)           │         510 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 514,510 (1.96 MB)

 Trainable params: 514,510 (1.96 MB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="choose-a-loss-function-and-optimizer">5. Choose a loss function and optimizer<a class="anchor" aria-label="anchor" href="#choose-a-loss-function-and-optimizer"></a>
</h2>
<hr class="half-width">
<p>We compile the model using the adam optimizer (other optimizers could
also be used here!). Similar to the penguin classification task, we will
use the crossentropy function to calculate the model’s loss. This loss
function is appropriate to use when the data has two or more label
classes.</p>
<p>Remember that our target class is represented by a single integer,
whereas the output of our network has 10 nodes, one for each class. So,
we should have actually one-hot encoded the targets and used a softmax
activation for the neurons in our output layer! Luckily, there is a
quick fix to calculate crossentropy loss for data that has its classes
represented by integers, the
<code>SparseCategoricalCrossentropy()</code> function. Adding the
argument <code>from_logits=True</code> accounts for the fact that the
output has a linear activation instead of softmax. This is what is often
done in practice, because it spares you from having to worry about
one-hot encoding.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="kw">def</span> compile_model(model):</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>                  loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>                  metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>compile_model(model)</span></code></pre>
</div>
<div id="choosing-a-metric" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="choosing-a-metric" class="callout-inner">
<h3 class="callout-title">Choosing a Metric</h3>
<div class="callout-content">
<p>The purpose of an evaluation metric is to reflect how well a model
performs on “real” data, hence on new samples it has never encountered
before. Achieving a suspiciously high score can indicate that the model
has learned to “cheat” the chosen metric instead of solving the actual
task. When that is the case, it means that the chosen metric is not
suitable to measure the model performance.</p>
<p>For instance, you could use a dataset of 100 cat images and dog
images to evaluate a model. If the data is highly imbalanced and 90 of
these images are dogs, the model will achieve 90% accuracy by
classifying each image as a dog. This high number looks like the model
performs great, but it is misleading; the model might not have learned
to identify a cat image at all. In such an imbalanced dataset, other
metrics such as <a href="https://keras.io/api/metrics/classification_metrics/#precision-class" class="external-link">precision</a>
and <a href="https://keras.io/api/metrics/classification_metrics/#recall-class" class="external-link">recall</a>
are more suitable.</p>
<p>The documentation provides a comprehensive list of <a href="https://keras.io/api/metrics/" class="external-link">metrics available in Keras</a>,
suitable for different tasks and datasets.</p>
</div>
</div>
</div>

</section><section><h2 class="section-heading" id="train-the-model">6. Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<hr class="half-width">
<p>We then train the model for 10 epochs:</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(train_images, train_labels, epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>                    validation_data<span class="op">=</span>(val_images, val_labels))</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="perform-a-predictionclassification">7. Perform a Prediction/Classification<a class="anchor" aria-label="anchor" href="#perform-a-predictionclassification"></a>
</h2>
<hr class="half-width">
<p>Here we skip performing a prediction, and continue to measuring the
performance. In practice, you will only do this step once in a while
when you actually need to have the individual predictions, often you
know enough based on the evaluation metric scores. Of course, behind the
scenes whenever you measure performance you have to make predictions and
compare them to the ground truth.</p>
</section><section><h2 class="section-heading" id="measure-performance">8. Measure performance<a class="anchor" aria-label="anchor" href="#measure-performance"></a>
</h2>
<hr class="half-width">
<p>We can plot the training process using the history:</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="kw">def</span> plot_history(history, metrics):</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co">    Plot the training history</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a><span class="co">        history (keras History object that is returned by model.fit())</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a><span class="co">        metrics(str, list): Metric or a list of metrics to plot</span></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>    history_df <span class="op">=</span> pd.DataFrame.from_dict(history.history)</span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>    sns.lineplot(data<span class="op">=</span>history_df[metrics])</span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>    plt.xlabel(<span class="st">"epochs"</span>)</span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>    plt.ylabel(<span class="st">"metric"</span>)</span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>plot_history(history, [<span class="st">'accuracy'</span>, <span class="st">'val_accuracy'</span>])</span></code></pre>
</div>
<figure><img src="fig/04_training_history_1.png" alt="Plot of training accuracy and validation accuracy vs epochs for the trained model, showing training accuracy incrasing consistently by approximately 0.1 for each epoch while validation accuracy remains steady, with only slight fluctuations around 0.25." class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>plot_history(history, [<span class="st">'loss'</span>, <span class="st">'val_loss'</span>])</span></code></pre>
</div>
<figure><img src="fig/04_training_history_loss_1.png" alt="Plot of training loss and validation loss vs epochs for the trained model, showing training loss steadily decreasing while validation loss remains steady before increasing after the sixth epoch." class="figure mx-auto d-block"></figure><p>It seems that the model is overfitting a lot, because the training
accuracy increases, while the validation accuracy stagnates. Meanwhile,
the training loss keeps decreasing while the validation loss actually
starts increasing after a few epochs.</p>

<div id="comparison-with-a-network-with-only-dense-layers-1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="comparison-with-a-network-with-only-dense-layers-1" class="callout-inner">
<h3 class="callout-title">Comparison with a network with only dense
layers</h3>
<div class="callout-content">
<p>How does this simple CNN compare to a neural network with only dense
layers?</p>
<p>We can define a neural network with only dense layers:</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="kw">def</span> create_dense_model():</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(inputs)</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>    <span class="cf">return</span> keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs,</span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>                              name<span class="op">=</span><span class="st">'dense_model'</span>)</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>dense_model <span class="op">=</span> create_dense_model()</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>dense_model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "dense_model"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)   │ (None, 64, 64, 3)    │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ flatten_2 (Flatten)          │ (None, 12288)        │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_4 (Dense)              │ (None, 50)           │     614,450 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_5 (Dense)              │ (None, 50)           │       2,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_6 (Dense)              │ (None, 10)           │         510 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 617,510 (2.36 MB)

 Trainable params: 617,510 (2.36 MB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
<p>As you can see this model has more parameters than our simple CNN,
let’s train and evaluate it!</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>compile_model(dense_model)</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>history <span class="op">=</span> dense_model.fit(train_images, train_labels, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>                    validation_data<span class="op">=</span>(val_images, val_labels))</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>plot_history(history, [<span class="st">'accuracy'</span>, <span class="st">'val_accuracy'</span>])</span></code></pre>
</div>
<figure><img src="fig/04_dense_model_training_history.png" alt="Plot of training accuracy and validation accuracy vs epochs for a model with only dense layers, showing training accuracy increasing to approximately 0.22 and validation accuracy plateauing around 0.18. Both values show relatively large fluctations as training progresses." class="figure mx-auto d-block"></figure><p>As you can see the validation accuracy only reaches about 18%,
whereas the CNN reached about 28% accuracy.</p>
<p>This demonstrates that convolutional layers are a big improvement
over dense layers for these kind of datasets.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="refine-the-model">9. Refine the model<a class="anchor" aria-label="anchor" href="#refine-the-model"></a>
</h2>
<hr class="half-width">
<div id="network-depth" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="network-depth" class="callout-inner">
<h3 class="callout-title">Network depth</h3>
<div class="callout-content">
<p>What, do you think, will be the effect of adding a convolutional
layer to your model? Will this model have more or fewer parameters? Try
it out. Create a <code>model</code> that has an additional
<code>Conv2d</code> layer with 50 filters and another MaxPooling2D layer
after the last MaxPooling2D layer. Train it for 10 epochs and plot the
results.</p>
<p><strong>HINT</strong>: The model definition that we used previously
needs to be adjusted as follows:</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a><span class="co"># Add your extra layers here</span></span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a>outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Show me the solution </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" data-bs-parent="#accordionSolution6" aria-labelledby="headingSolution6">
<div class="accordion-body">
<p>We add an extra Conv2D layer after the second pooling layer:</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="kw">def</span> create_nn_extra_layer():</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x) <span class="co">#</span></span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x) <span class="co"># extra layer</span></span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x) <span class="co"># extra layer</span></span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"dollar_street_model"</span>)</span>
<span id="cb28-14"><a href="#cb28-14" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb28-15"><a href="#cb28-15" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" tabindex="-1"></a>model <span class="op">=</span> create_nn_extra_layer()</span></code></pre>
</div>
<p>With the model defined above, we can inspect the number of
parameters:</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>model.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "dollar_street_model"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)   │ (None, 64, 64, 3)    │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_4 (Conv2D)            │ (None, 62, 62, 50)   │       1,400 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_2              │ (None, 31, 31, 50)   │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_5 (Conv2D)            │ (None, 29, 29, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_3              │ (None, 14, 14, 50)   │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_6 (Conv2D)            │ (None, 12, 12, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_4              │ (None, 6, 6, 50)     │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ flatten_3 (Flatten)          │ (None, 1800)         │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_7 (Dense)              │ (None, 50)           │      90,050 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_8 (Dense)              │ (None, 10)           │         510 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 137,060 (535.39 KB)

 Trainable params: 137,060 (535.39 KB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
<p>The number of parameters has decreased by adding this layer. We can
see that the extra layers decrease the resolution from 14x14 to 6x6, as
a result, the input of the Dense layer is smaller than in the previous
network. To train the network and plot the results:</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>compile_model(model)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>history <span class="op">=</span> model.fit(train_images, train_labels, epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>                   validation_data<span class="op">=</span>(val_images, val_labels))</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a>plot_history(history, [<span class="st">'accuracy'</span>, <span class="st">'val_accuracy'</span>])</span></code></pre>
</div>
<figure><img src="fig/04_training_history_2.png" alt="Plot of training accuracy and validation accuracy vs epochs for the trained model, showing training accuracy increasing steadily by approximately 0.04 per epoch up to around 0.55 while validation accuracy increases before plateauing around 0.25." class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="other-types-of-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="other-types-of-data" class="callout-inner">
<h3 class="callout-title">Other types of data</h3>
<div class="callout-content">
<p>Convolutional and Pooling layers are also applicable to different
types of data than image data. Whenever the data is ordered in a
(spatial) dimension, and <em>translation invariant</em> features are
expected to be useful, convolutions can be used. Think for example of
time series data from an accelerometer, audio data for speech
recognition, or 3d structures of chemical compounds.</p>
</div>
</div>
</div>
<div id="why-and-when-to-use-convolutional-neural-networks" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="why-and-when-to-use-convolutional-neural-networks" class="callout-inner">
<h3 class="callout-title">Why and when to use convolutional neural
networks</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>Would it make sense to train a convolutional neural network (CNN) on
the penguins dataset and why?</li>
<li>Would it make sense to train a CNN on the weather dataset and
why?</li>
<li>(Optional) Can you think of a different machine learning task that
would benefit from a CNN architecture?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution7" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution7" aria-expanded="false" aria-controls="collapseSolution7">
  <h4 class="accordion-header" id="headingSolution7"> Show me the solution </h4>
</button>
<div id="collapseSolution7" class="accordion-collapse collapse" data-bs-parent="#accordionSolution7" aria-labelledby="headingSolution7">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>No that would not make sense. Convolutions only work when the
features of the data can be ordered in a meaningful way. Pixels for
example are ordered in a spatial dimension. This kind of order cannot be
applied to the features of the penguin dataset. If we would have
pictures or audio recordings of the penguins as input data it would make
sense to use a CNN architecture.</li>
<li>It would make sense, but only if we approach the problem from a
different angle then we did before. Namely, 1D convolutions work quite
well on sequential data such as timeseries. If we have as our input a
matrix of the different weather conditions over time in the past x days,
a CNN would be suited to quickly grasp the temporal relationship over
days.</li>
<li>Some example domains in which CNNs are applied:</li>
</ol>
<ul>
<li>Text data</li>
<li>Timeseries, specifically audio</li>
<li>Molecular structures</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="dropout">Dropout<a class="anchor" aria-label="anchor" href="#dropout"></a>
</h3>
<p>Note that the training loss continues to decrease, while the
validation loss stagnates, and even starts to increase over the course
of the epochs. Similarly, the accuracy for the validation set does not
improve anymore after some epochs. This means we are overfitting on our
training data set.</p>
<p>Techniques to avoid overfitting, or to improve model generalization,
are termed <strong>regularization techniques</strong>. One of the most
versatile regularization technique is <strong>dropout</strong> (<a href="https://jmlr.org/papers/v15/srivastava14a.html" class="external-link">Srivastava et al.,
2014</a>). Dropout means that during each training cycle (one forward
pass of the data through the model) a random fraction of neurons in a
dense layer are turned off. This is described with the dropout rate
between 0 and 1 which determines the fraction of nodes to silence at a
time.</p>
<figure><img src="fig/neural_network_sketch_dropout.png" alt="A sketch of a neural network with and without dropout" class="figure mx-auto d-block"></figure><p>The intuition behind dropout is that it enforces redundancies in the
network by constantly removing different elements of a network. The
model can no longer rely on individual nodes and instead must create
multiple “paths”. In addition, the model has to make predictions with
much fewer nodes and weights (connections between the nodes). As a
result, it becomes much harder for a network to memorize particular
features. At first this might appear a quite drastic approach which
affects the network architecture strongly. In practice, however, dropout
is computationally a very elegant solution which does not affect
training speed. And it frequently works very well.</p>
<p><strong>Important to note:</strong> Dropout layers will only randomly
silence nodes during training! During a prediction step, all nodes
remain active (dropout is off). During training, the sample of nodes
that are silenced are different for each training instance, to give all
nodes a chance to observe enough training data to learn its weights.</p>
<p>Let us add a dropout layer after each pooling layer towards the end
of the network that randomly drops 80% of the nodes.</p>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="kw">def</span> create_nn_with_dropout():</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb32-4"><a href="#cb32-4" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb32-5"><a href="#cb32-5" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.8</span>)(x) <span class="co"># This is new!</span></span>
<span id="cb32-6"><a href="#cb32-6" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb32-8"><a href="#cb32-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb32-9"><a href="#cb32-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.8</span>)(x) <span class="co"># This is new!</span></span>
<span id="cb32-10"><a href="#cb32-10" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb32-12"><a href="#cb32-12" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb32-13"><a href="#cb32-13" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.8</span>)(x) <span class="co"># This is new!</span></span>
<span id="cb32-14"><a href="#cb32-14" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb32-16"><a href="#cb32-16" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb32-17"><a href="#cb32-17" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb32-18"><a href="#cb32-18" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"dropout_model"</span>)</span>
<span id="cb32-19"><a href="#cb32-19" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb32-20"><a href="#cb32-20" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" tabindex="-1"></a>model_dropout <span class="op">=</span> create_nn_with_dropout()</span>
<span id="cb32-22"><a href="#cb32-22" tabindex="-1"></a>model_dropout.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "dropout_model"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Layer (type)                 ┃ Output Shape         ┃     Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)   │ (None, 64, 64, 3)    │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_7 (Conv2D)            │ (None, 62, 62, 50)   │       1,400 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_5              │ (None, 31, 31, 50)   │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dropout (Dropout)            │ (None, 31, 31, 50)   │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_8 (Conv2D)            │ (None, 29, 29, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_6              │ (None, 14, 14, 50)   │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dropout_1 (Dropout)          │ (None, 14, 14, 50)   │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ conv2d_9 (Conv2D)            │ (None, 12, 12, 50)   │      22,550 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ max_pooling2d_7              │ (None, 6, 6, 50)     │           0 │
│ (MaxPooling2D)               │                      │             │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dropout_2 (Dropout)          │ (None, 6, 6, 50)     │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ flatten_4 (Flatten)          │ (None, 1800)         │           0 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_9 (Dense)              │ (None, 50)           │      90,050 │
├──────────────────────────────┼──────────────────────┼─────────────┤
│ dense_10 (Dense)             │ (None, 10)           │         510 │
└──────────────────────────────┴──────────────────────┴─────────────┘

 Total params: 137,060 (535.39 KB)

 Trainable params: 137,060 (535.39 KB)

 Non-trainable params: 0 (0.00 B)</code></pre>
</div>
<p>We can see that the dropout does not alter the dimensions of the
image, and has zero parameters.</p>
<p>We again compile and train the model.</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>compile_model(model_dropout)</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>history <span class="op">=</span> model_dropout.fit(train_images, train_labels, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>                    validation_data<span class="op">=</span>(val_images, val_labels))</span></code></pre>
</div>
<p>And inspect the training results:</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>plot_history(history, [<span class="st">'accuracy'</span>, <span class="st">'val_accuracy'</span>])</span></code></pre>
</div>
<figure><img src="fig/04_training_history_3.png" alt="Plot of training accuracy and validation accuracy vs epochs for the trained model, showing both values increasing before they diverge after around 10 epochs, with training accuracy reaching approximately 0.4 while validation accuracy plateaus around 0.3" class="figure mx-auto d-block"></figure><p>Now we see that the gap between the training accuracy and validation
accuracy is much smaller, and that the final accuracy on the validation
set is higher than without dropout.</p>
<div id="vary-dropout-rate" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="vary-dropout-rate" class="callout-inner">
<h3 class="callout-title">Vary dropout rate</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>What do you think would happen if you lower the dropout rate? Try it
out, and see how it affects the model training.</li>
<li>You are varying the dropout rate and checking its effect on the
model performance, what is the term associated to this procedure?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution8" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution8" aria-expanded="false" aria-controls="collapseSolution8">
  <h4 class="accordion-header" id="headingSolution8"> Show me the solution </h4>
</button>
<div id="collapseSolution8" class="accordion-collapse collapse" data-bs-parent="#accordionSolution8" aria-labelledby="headingSolution8">
<div class="accordion-body">
<div class="section level3">
<h3 id="varying-the-dropout-rate">1. Varying the dropout rate<a class="anchor" aria-label="anchor" href="#varying-the-dropout-rate"></a>
</h3>
<p>The code below instantiates and trains a model with varying dropout
rates. You can see from the resulting plot that the ideal dropout rate
in this case is around 0.9. This is where the val loss is lowest.</p>
<p>Note that it can take a while to train these 6 networks.</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="kw">def</span> create_nn_with_dropout(dropout_rate):</span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb36-5"><a href="#cb36-5" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(dropout_rate)(x)</span>
<span id="cb36-6"><a href="#cb36-6" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb36-8"><a href="#cb36-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb36-9"><a href="#cb36-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(dropout_rate)(x)</span>
<span id="cb36-10"><a href="#cb36-10" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb36-12"><a href="#cb36-12" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(dropout_rate)(x)</span>
<span id="cb36-13"><a href="#cb36-13" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb36-14"><a href="#cb36-14" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb36-15"><a href="#cb36-15" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb36-16"><a href="#cb36-16" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"dropout_model"</span>)</span>
<span id="cb36-17"><a href="#cb36-17" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb36-18"><a href="#cb36-18" tabindex="-1"></a></span>
<span id="cb36-19"><a href="#cb36-19" tabindex="-1"></a>early_stopper <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb36-20"><a href="#cb36-20" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" tabindex="-1"></a>dropout_rates <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>]</span>
<span id="cb36-22"><a href="#cb36-22" tabindex="-1"></a>val_losses <span class="op">=</span> []</span>
<span id="cb36-23"><a href="#cb36-23" tabindex="-1"></a><span class="cf">for</span> dropout_rate <span class="kw">in</span> dropout_rates:</span>
<span id="cb36-24"><a href="#cb36-24" tabindex="-1"></a>    model_dropout <span class="op">=</span> create_nn_with_dropout(dropout_rate)</span>
<span id="cb36-25"><a href="#cb36-25" tabindex="-1"></a>    compile_model(model_dropout)</span>
<span id="cb36-26"><a href="#cb36-26" tabindex="-1"></a>    model_dropout.fit(train_images, train_labels, epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb36-27"><a href="#cb36-27" tabindex="-1"></a>                      validation_data<span class="op">=</span>(val_images, val_labels),</span>
<span id="cb36-28"><a href="#cb36-28" tabindex="-1"></a>                      callbacks<span class="op">=</span>[early_stopper]</span>
<span id="cb36-29"><a href="#cb36-29" tabindex="-1"></a>                      )</span>
<span id="cb36-30"><a href="#cb36-30" tabindex="-1"></a></span>
<span id="cb36-31"><a href="#cb36-31" tabindex="-1"></a>    val_loss, val_acc <span class="op">=</span> model_dropout.evaluate(val_images,  val_labels)</span>
<span id="cb36-32"><a href="#cb36-32" tabindex="-1"></a>    val_losses.append(val_loss)</span>
<span id="cb36-33"><a href="#cb36-33" tabindex="-1"></a></span>
<span id="cb36-34"><a href="#cb36-34" tabindex="-1"></a>loss_df <span class="op">=</span> pd.DataFrame({<span class="st">'dropout_rate'</span>: dropout_rates, <span class="st">'val_loss'</span>: val_losses})</span>
<span id="cb36-35"><a href="#cb36-35" tabindex="-1"></a></span>
<span id="cb36-36"><a href="#cb36-36" tabindex="-1"></a></span>
<span id="cb36-37"><a href="#cb36-37" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>loss_df, x<span class="op">=</span><span class="st">'dropout_rate'</span>, y<span class="op">=</span><span class="st">'val_loss'</span>)</span></code></pre>
</div>
<figure><img src="fig/04_vary_dropout_rate.png" alt="Plot of vall loss vs dropout rate used in the model. The val loss varies between 2.3 and 2.0 and is lowest with a dropout_rate of 0.9" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="term-associated-to-this-procedure">2. Term associated to this procedure<a class="anchor" aria-label="anchor" href="#term-associated-to-this-procedure"></a>
</h3>
<p>This is called hyperparameter tuning.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="hyperparameter-tuning">Hyperparameter tuning<a class="anchor" aria-label="anchor" href="#hyperparameter-tuning"></a>
</h3>

<p>Recall that hyperparameters are model configuration settings that are
chosen before the training process and affect the model’s learning
behavior and performance, for example the dropout rate. In general, if
you are varying hyperparameters to find the combination of
hyperparameters with the best model performance this is called
hyperparameter tuning. A naive way to do this is to write a for-loop and
train a slightly different model in every cycle. However, it is better
to use the <code>keras_tuner</code> package for this.</p>
<p>Let’s first define a function that creates a neuronal network given 2
hyperparameters, namely the dropout rate and the number of layers:</p>
<div class="codewrapper sourceCode" id="cb37">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="kw">def</span> create_nn_with_hp(dropout_rate, n_layers):</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>    x <span class="op">=</span> inputs</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(n_layers):</span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb37-6"><a href="#cb37-6" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb37-7"><a href="#cb37-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(dropout_rate)(x)</span>
<span id="cb37-8"><a href="#cb37-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb37-9"><a href="#cb37-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb37-10"><a href="#cb37-10" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb37-11"><a href="#cb37-11" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"cifar_model"</span>)</span>
<span id="cb37-12"><a href="#cb37-12" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre>
</div>
<p>Now, let’s find the best combination of hyperparameters using grid
search. Grid search is the simplest hyperparameter tuning strategy, you
test all the combinations of predefined values for the hyperparameters
that you want to vary.</p>
<p>For this we will make use of the package <code>keras_tuner</code>, we
can install it by typing in the command line:</p>
<div class="codewrapper sourceCode" id="cb38">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a><span class="ex">pip</span> install keras_tuner</span></code></pre>
</div>
<p>Note that this can take some time to train (around 5 minutes or
longer).</p>
<div class="codewrapper sourceCode" id="cb39">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="im">import</span> keras_tuner</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>hp <span class="op">=</span> keras_tuner.HyperParameters()</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb39-6"><a href="#cb39-6" tabindex="-1"></a>    <span class="co"># Define values for hyperparameters to try out:</span></span>
<span id="cb39-7"><a href="#cb39-7" tabindex="-1"></a>    n_layers <span class="op">=</span> hp.Int(<span class="st">"n_layers"</span>, min_value<span class="op">=</span><span class="dv">1</span>, max_value<span class="op">=</span><span class="dv">2</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-8"><a href="#cb39-8" tabindex="-1"></a>    dropout_rate <span class="op">=</span> hp.Float(<span class="st">"dropout_rate"</span>, min_value<span class="op">=</span><span class="fl">0.2</span>, max_value<span class="op">=</span><span class="fl">0.8</span>, step<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb39-9"><a href="#cb39-9" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" tabindex="-1"></a>    model <span class="op">=</span> create_nn_with_hp(dropout_rate, n_layers)</span>
<span id="cb39-11"><a href="#cb39-11" tabindex="-1"></a>    compile_model(model)</span>
<span id="cb39-12"><a href="#cb39-12" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb39-13"><a href="#cb39-13" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" tabindex="-1"></a>tuner <span class="op">=</span> keras_tuner.GridSearch(build_model, objective<span class="op">=</span><span class="st">'val_loss'</span>)</span>
<span id="cb39-15"><a href="#cb39-15" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" tabindex="-1"></a>tuner.search(train_images, train_labels, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb39-17"><a href="#cb39-17" tabindex="-1"></a>             validation_data<span class="op">=</span>(val_images, val_labels))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Trial 6 Complete [00h 00m 19s]
val_loss: 2.086069345474243

Best val_loss So Far: 2.086069345474243
Total elapsed time: 00h 01m 28s</code></pre>
</div>
<p>Let’s have a look at the results:</p>
<div class="codewrapper sourceCode" id="cb41">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>tuner.results_summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Results summary
Results in ./untitled_project
Showing 10 best trials
Objective(name="val_loss", direction="min")

Trial 0005 summary
Hyperparameters:
n_layers: 2
dropout_rate: 0.8
Score: 2.086069345474243

Trial 0000 summary
Hyperparameters:
n_layers: 1
dropout_rate: 0.2
Score: 2.101102352142334

Trial 0001 summary
Hyperparameters:
n_layers: 1
dropout_rate: 0.5
Score: 2.1184325218200684

Trial 0003 summary
Hyperparameters:
n_layers: 2
dropout_rate: 0.2
Score: 2.1233835220336914

Trial 0002 summary
Hyperparameters:
n_layers: 1
dropout_rate: 0.8
Score: 2.1370232105255127

Trial 0004 summary
Hyperparameters:
n_layers: 2
dropout_rate: 0.5
Score: 2.143627882003784</code></pre>
</div>
<div id="hyperparameter-tuning-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="hyperparameter-tuning-1" class="callout-inner">
<h3 class="callout-title">Hyperparameter tuning</h3>
<div class="callout-content">
<p>1: Looking at the grid search results, select all correct
statements:</p>
<ul>
<li>A. 6 different models were trained in this grid search run, because
there are 6 possible combinations for the defined hyperparameter
values</li>
<li>B. 2 different models were trained, 1 for each hyperparameter that
we want to change</li>
<li>C. 1 model is trained with 6 different hyperparameter
combinations</li>
<li>D. The model with 2 layer and a dropout rate of 0.5 is the best
model with a validation loss of 2.144</li>
<li>E. The model with 2 layers and a dropout rate of 0.8 is the best
model with a validation loss of 2.086</li>
<li>F. We found the model with the best possible combination of dropout
rate and number of layers</li>
</ul>
<p>2 (Optional): Perform a grid search finding the best combination of
the following hyperparameters: 2 different activation functions: ‘relu’,
and ‘tanh’, and 2 different values for the kernel size: 3 and 4. Which
combination works best?</p>
<p><strong>Hint</strong>: Instead of <code>hp.Int</code> you should now
use <code>hp.Choice("name", ["value1", "value2"])</code> to use
hyperparameters from a predefined set of possible values.</p>
</div>
</div>
</div>
<div id="accordionSolution9" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution9" aria-expanded="false" aria-controls="collapseSolution9">
  <h4 class="accordion-header" id="headingSolution9"> Show me the solution </h4>
</button>
<div id="collapseSolution9" class="accordion-collapse collapse" data-bs-parent="#accordionSolution9" aria-labelledby="headingSolution9">
<div class="accordion-body">
<p>1:</p>
<ul>
<li>A: Correct, 2 values for number of layers (1 and 2) are combined
with 3 values for the dropout rate (0.2, 0.5, 0.8). 2 * 3 = 6
combinations</li>
<li>B: Incorrect, a model is trained for each combination of defined
hyperparameter values</li>
<li>C: Incorrect, it is important to note that you actually train and
test different models for each run of the grid search</li>
<li>D: Incorrect, this is the worst model since the validation loss is
highest</li>
<li>E: Correct, this is the best model with the lowest loss</li>
<li>F: Incorrect, it could be that a different number of layers in
combination with a dropout rate that we did not test (for example 3
layers and a dropout rate of 0.6) could be the best model.</li>
</ul>
<p>2 (Optional):</p>
<p>You need to adapt the code as follows:</p>
<div class="codewrapper sourceCode" id="cb43">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="kw">def</span> create_nn_with_hp(activation_function, kernel_size):</span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>    x <span class="op">=</span> inputs</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.Conv2D(<span class="dv">50</span>, (kernel_size, kernel_size), activation<span class="op">=</span>activation_function)(x)</span>
<span id="cb43-6"><a href="#cb43-6" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb43-7"><a href="#cb43-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb43-8"><a href="#cb43-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb43-9"><a href="#cb43-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span>activation_function)(x)</span>
<span id="cb43-10"><a href="#cb43-10" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb43-11"><a href="#cb43-11" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"cifar_model"</span>)</span>
<span id="cb43-12"><a href="#cb43-12" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb43-13"><a href="#cb43-13" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" tabindex="-1"></a>hp <span class="op">=</span> keras_tuner.HyperParameters()</span>
<span id="cb43-15"><a href="#cb43-15" tabindex="-1"></a></span>
<span id="cb43-16"><a href="#cb43-16" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb43-17"><a href="#cb43-17" tabindex="-1"></a>    kernel_size <span class="op">=</span> hp.Int(<span class="st">"kernel_size"</span>, min_value<span class="op">=</span><span class="dv">3</span>, max_value<span class="op">=</span><span class="dv">4</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-18"><a href="#cb43-18" tabindex="-1"></a>    activation <span class="op">=</span> hp.Choice(<span class="st">"activation"</span>, [<span class="st">"relu"</span>, <span class="st">"tanh"</span>])</span>
<span id="cb43-19"><a href="#cb43-19" tabindex="-1"></a>    model <span class="op">=</span> create_nn_with_hp(activation, kernel_size)</span>
<span id="cb43-20"><a href="#cb43-20" tabindex="-1"></a>    compile_model(model)</span>
<span id="cb43-21"><a href="#cb43-21" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb43-22"><a href="#cb43-22" tabindex="-1"></a></span>
<span id="cb43-23"><a href="#cb43-23" tabindex="-1"></a>tuner <span class="op">=</span> keras_tuner.GridSearch(build_model, objective<span class="op">=</span><span class="st">'val_loss'</span>, project_name<span class="op">=</span><span class="st">'new_project'</span>)</span>
<span id="cb43-24"><a href="#cb43-24" tabindex="-1"></a>tuner.search(train_images, train_labels, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb43-25"><a href="#cb43-25" tabindex="-1"></a>             validation_data<span class="op">=</span>(val_images, val_labels))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Trial 4 Complete [00h 00m 25s]
val_loss: 2.0591845512390137

Best val_loss So Far: 2.0277602672576904
Total elapsed time: 00h 01m 30s</code></pre>
</div>
<p>Let’s look at the results:</p>
<div class="codewrapper sourceCode" id="cb45">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a>tuner.results_summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Results summary
Results in ./new_project
Showing 10 best trials
Objective(name="val_loss", direction="min")

Trial 0001 summary
Hyperparameters:
kernel_size: 3
activation: tanh
Score: 2.0277602672576904

Trial 0003 summary
Hyperparameters:
kernel_size: 4
activation: tanh
Score: 2.0591845512390137

Trial 0000 summary
Hyperparameters:
kernel_size: 3
activation: relu
Score: 2.123767614364624

Trial 0002 summary
Hyperparameters:
kernel_size: 4
activation: relu
Score: 2.150160551071167</code></pre>
</div>
<p>A kernel size of 3 and <code>tanh</code> as activation function is
the best tested combination.</p>
</div>
</div>
</div>
</div>
<p>Grid search can quickly result in a combinatorial explosion because
all combinations of hyperparameters are trained and tested. Instead,
<code>random search</code> randomly samples combinations of
hyperparemeters, allowing for a much larger look through a large number
of possible hyperparameter combinations.</p>
<p>Next to grid search and random search there are many different
hyperparameter tuning strategies, including <a href="https://en.wikipedia.org/wiki/Neural_architecture_search" class="external-link">neural
architecture search</a> where a separate neural network is trained to
find the best architecture for a model!</p>
</div>
</section><section><h2 class="section-heading" id="share-model">10. Share model<a class="anchor" aria-label="anchor" href="#share-model"></a>
</h2>
<hr class="half-width">
<p>Let’s save our model</p>
<div class="codewrapper sourceCode" id="cb47">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a>model.save(<span class="st">'cnn_model.keras'</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="conclusion-and-next-steps">Conclusion and next steps<a class="anchor" aria-label="anchor" href="#conclusion-and-next-steps"></a>
</h2>
<hr class="half-width">
<p>How successful were we with creating a model here? With ten image
classes, and assuming that we would not ask the model to classify an
image that contains none of the given classes of object, a model working
on complete guesswork would be correct 10% of the time. Against this
baseline accuracy of 10%, and considering the diversity and relatively
low resolution of the example images, perhaps our last model’s
validation accuracy of ~30% is not too bad. What could be done to
improve on this performance? We might try adjusting the number of layers
and their parameters, such as the number of units in a layer, or
providing more training data (we were using only a subset of the
original Dollar Street dataset here). Or we could explore some other
deep learning techniques, such as transfer learning, to create more
sophisticated models.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Convolutional layers make efficient reuse of model parameters.</li>
<li>Pooling layers decrease the resolution of your input</li>
<li>Dropout is a way to prevent overfitting</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-5-transfer-learning"><p>Content from <a href="5-transfer-learning.html">Transfer learning</a></p>
<hr>
<p>Last updated on 2025-09-02 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/5-transfer-learning.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I apply a pre-trained model to my data?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Adapt a state-of-the-art pre-trained network to your own
dataset</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="what-is-transfer-learning">What is transfer learning?<a class="anchor" aria-label="anchor" href="#what-is-transfer-learning"></a>
</h2>
<hr class="half-width">
<p>Instead of training a model from scratch, with transfer learning you
make use of models that are trained on another machine learning task.
The pre-trained network captures generic knowledge during pre-training
and will only be ‘fine-tuned’ to the specifics of your dataset.</p>
<p>An example: Let’s say that you want to train a model to classify
images of different dog breeds. You could make use of a pre-trained
network that learned how to classify images of dogs and cats. The
pre-trained network will not know anything about different dog breeds,
but it will have captured some general knowledge of, on a high-level,
what dogs look like, and on a low-level all the different features
(eyes, ears, paws, fur) that make up an image of a dog. Further training
this model on your dog breed dataset is a much easier task than training
from scratch, because the model can use the general knowledge captured
in the pre-trained network.</p>
<figure><img src="fig/05-transfer_learning.png" class="figure mx-auto d-block"><!--
Edit this plot using the Mermaid live editor:
1. Open this link that includes the source code of the chart to open the live editor web interface:
https://mermaid.live/edit#pako:eNpVkE1vgzAMhv9K5MPUSrQKAWUlh0kr9NZetp02drAgUCRIqhC0dZT_vizso_PJb_zYr-MRCl1KEFC1-q04orFk_5Ar4uL-ZZHpuic3JEXbkwwtLl_JanVHLk8GG0UOrrO9kO3CJ-QKXs4T0tGBqq-kIXuJRjWqnubK1s9JZ5F5I7I1Upb_fL7rqRe7a8g7LiGATpoOm9J9YPyCc7BH2ckchEtLWeHQ2hxyNTkUB6sfz6oAYc0gAzB6qI8gKmx7p4ZTiVZmDdYGu9_XE6pnrf-0LBurzWE-mb-cZ0CM8A5iRdfUBeObmEZJzKOEJRHnUQBnECwK15zRMGJxzNkmoXwK4MMPD30bpSHjt5SHSfyzzs7bzQtPn9Xpf_E
2. Make changes to the chart as desired in the live editor
3. Download the newly created diagram from the live editor (Actions / PNG) and replace the existing image in the episode folder (episodes/fig/05-transfer_learning.png)
4. (optional) crop the image to remove the white space around the plot in a separate image editor
5. Update the URL in step 1 of this comment to the new URL of the live editor
--></figure><p>In this episode we will learn how use Keras to adapt a
state-of-the-art pre-trained model to the <a href="https://zenodo.org/records/10970014" class="external-link">Dollar Street
Dataset</a>.</p>
</section><section><h2 class="section-heading" id="formulate-outline-the-problem">1. Formulate / Outline the problem<a class="anchor" aria-label="anchor" href="#formulate-outline-the-problem"></a>
</h2>
<hr class="half-width">
<p>Just like in the previous episode, we use the Dollar Street 10
dataset.</p>
<p>We load the data in the same way as the previous episode:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> pathlib</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>DATA_FOLDER <span class="op">=</span> pathlib.Path(<span class="st">'data/dataset_dollarstreet/'</span>) <span class="co"># change to location where you stored the data</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>train_images <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'train_images.npy'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>val_images <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'test_images.npy'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>train_labels <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'train_labels.npy'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>val_labels <span class="op">=</span> np.load(DATA_FOLDER <span class="op">/</span> <span class="st">'test_labels.npy'</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="identify-inputs-and-outputs">2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#identify-inputs-and-outputs"></a>
</h2>
<hr class="half-width">
<p>As discussed in the previous episode, the input are images of
dimension 64 x 64 pixels with 3 colour channels each. The goal is to
predict one out of 10 classes to which the image belongs.</p>
</section><section><h2 class="section-heading" id="prepare-the-data">3. Prepare the data<a class="anchor" aria-label="anchor" href="#prepare-the-data"></a>
</h2>
<hr class="half-width">
<p>We prepare the data as before, scaling the values between 0 and
1.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>train_images <span class="op">=</span> train_images <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>val_images <span class="op">=</span> val_images <span class="op">/</span> <span class="fl">255.0</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="choose-a-pre-trained-model-or-start-building-architecture-from-scratch">4. Choose a pre-trained model or start building architecture from
scratch<a class="anchor" aria-label="anchor" href="#choose-a-pre-trained-model-or-start-building-architecture-from-scratch"></a>
</h2>
<hr class="half-width">
<p>Let’s define our model input layer using the shape of our training
images:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># input tensor</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>keras.utils.set_random_seed(<span class="dv">2</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(train_images.shape[<span class="dv">1</span>:])</span></code></pre>
</div>
<p>Our images are 64 x 64 pixels, whereas the pre-trained model that we
will use was trained on images of 160 x 160 pixels. To adapt our data
accordingly, we add an upscale layer that resizes the images to 160 x
160 pixels during training and prediction.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># upscale layer</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>method <span class="op">=</span> tf.image.ResizeMethod.BILINEAR</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>upscale <span class="op">=</span> keras.layers.Lambda(</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>  <span class="kw">lambda</span> x: tf.image.resize_with_pad(x, <span class="dv">160</span>, <span class="dv">160</span>, method<span class="op">=</span>method))(inputs)</span></code></pre>
</div>
<p>From the <code>keras.applications</code> module we use the
<code>DenseNet121</code> architecture. This architecture was proposed by
the paper: <a href="https://arxiv.org/abs/1608.06993" class="external-link">Densely Connected
Convolutional Networks (CVPR 2017)</a>. It is trained on the <a href="https://www.image-net.org/" class="external-link">Imagenet</a> dataset, which contains
14,197,122 annotated images according to the WordNet hierarchy with over
20,000 classes.</p>
<p>We will have a look at the architecture later, for now it is enough
to know that it is a convolutional neural network with 121 layers that
was designed to work well on image classification tasks.</p>
<p>Let’s configure the DenseNet121:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>base_model <span class="op">=</span> keras.applications.DenseNet121(include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>                                            pooling<span class="op">=</span><span class="st">'max'</span>,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>                                            weights<span class="op">=</span><span class="st">'imagenet'</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>                                            input_tensor<span class="op">=</span>upscale,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>                                            input_shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>),</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>                                            )</span></code></pre>
</div>
<div id="ssl-certificate-verify-failed-error" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="ssl-certificate-verify-failed-error" class="callout-inner">
<h3 class="callout-title">SSL: certificate verify failed error</h3>
<div class="callout-content">
<p>If you get the following error message:
<code>certificate verify failed: unable to get local issuer certificate</code>,
you can download <a href="https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5" class="external-link">the
weights of the model manually</a> and then load in the weights from the
downloaded file:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>base_model <span class="op">=</span> keras.applications.DenseNet121(</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    pooling<span class="op">=</span><span class="st">'max'</span>,</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'</span>, <span class="co"># this should refer to the weights file you downloaded</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    input_tensor<span class="op">=</span>upscale,</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    input_shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>),</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
</div>
</div>
<p>By setting <code>include_top</code> to <code>False</code> we exclude
the fully connected layer at the top of the network, hence the final
output layer. This layer was used to predict the Imagenet classes, but
will be of no use for our Dollar Street dataset. Note that the ‘top
layer’ appears at the bottom in the output of
<code>model.summary()</code>.</p>
<p>We add <code>pooling='max'</code> so that max pooling is applied to
the output of the DenseNet121 network.</p>
<p>By setting <code>weights='imagenet'</code> we use the weights that
resulted from training this network on the Imagenet data.</p>
<p>We connect the network to the <code>upscale</code> layer that we
defined before.</p>
<div class="section level3">
<h3 id="only-train-a-head-network">Only train a ‘head’ network<a class="anchor" aria-label="anchor" href="#only-train-a-head-network"></a>
</h3>
<p>Instead of fine-tuning all the weights of the DenseNet121 network
using our dataset, we choose to freeze all these weights and only train
a so-called ‘head network’ that sits on top of the pre-trained network.
You can see the DenseNet121 network as extracting a meaningful feature
representation from our image. The head network will then be trained to
decide on which of the 10 Dollar Street dataset classes the image
belongs.</p>
<p>We will turn of the <code>trainable</code> property of the base
model:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span></code></pre>
</div>
<p>Let’s define our ‘head’ network:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>out <span class="op">=</span> base_model.output</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>out <span class="op">=</span> keras.layers.Flatten()(out)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>out <span class="op">=</span> keras.layers.BatchNormalization()(out)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>out <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(out)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>out <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.5</span>)(out)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>out <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(out)</span></code></pre>
</div>
<p>Finally we define our model:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>model <span class="op">=</span> keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>out)</span></code></pre>
</div>
<div id="inspect-the-densenet121-network" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="inspect-the-densenet121-network" class="callout-inner">
<h3 class="callout-title">Inspect the DenseNet121 network</h3>
<div class="callout-content">
<p>Have a look at the network architecture with
<code>model.summary()</code>. It is indeed a deep network, so expect a
long summary!</p>
<div class="section level3">
<h3 id="trainable-parameters">1.Trainable parameters<a class="anchor" aria-label="anchor" href="#trainable-parameters"></a>
</h3>
<p>How many parameters are there? How many of them are trainable?</p>
<p>Why is this and how does it effect the time it takes to train the
model?</p>
</div>
<div class="section level3">
<h3 id="head-and-base">2. Head and base<a class="anchor" aria-label="anchor" href="#head-and-base"></a>
</h3>
<p>Can you see in the model summary which part is the base network and
which part is the head network?</p>
</div>
<div class="section level3">
<h3 id="max-pooling">3. Max pooling<a class="anchor" aria-label="anchor" href="#max-pooling"></a>
</h3>
<p>Which layer is added because we provided <code>pooling='max'</code>
as argument for <code>DenseNet121()</code>?</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Solutions </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="trainable-parameters-1">1. Trainable parameters<a class="anchor" aria-label="anchor" href="#trainable-parameters-1"></a>
</h3>
<p>Total number of parameters: 7093360, out of which only 53808 are
trainable.</p>
<p>The 53808 trainable parameters are the weights of the head network.
All other parameters are ‘frozen’ because we set
<code>base_model.trainable=False</code>. Because only a small proportion
of the parameters have to be updated at each training step, this will
greatly speed up training time.</p>
</div>
<div class="section level3">
<h3 id="head-and-base-1">2. Head and base<a class="anchor" aria-label="anchor" href="#head-and-base-1"></a>
</h3>
<p>The head network starts at the <code>flatten</code> layer, 5 layers
before the final layer.</p>
</div>
<div class="section level3">
<h3 id="max-pooling-1">3. Max pooling<a class="anchor" aria-label="anchor" href="#max-pooling-1"></a>
</h3>
<p>The <code>max_pool</code> layer right before the <code>flatten</code>
layer is added because we provided <code>pooling='max'</code>.</p>
</div>
</div>
</div>
</div>
</div>
<div id="compile-the-model" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="compile-the-model" class="callout-inner">
<h3 class="callout-title">1. Compile the model</h3>
<div class="callout-content">
<p>Compile the model:</p>
<ul>
<li>Use the <code>adam</code> optimizer</li>
<li>Use the <code>SparseCategoricalCrossentropy</code> loss with
<code>from_logits=True</code>.</li>
<li>Use ‘accuracy’ as a metric.</li>
</ul>
<div class="section level3">
<h3 id="train-the-model">2. Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h3>
<p>Train the model on the training dataset:</p>
<ul>
<li>Use a batch size of 32</li>
<li>Train for 30 epochs, but use an earlystopper with a patience of
5</li>
<li>Pass the validation dataset as validation data so we can monitor
performance on the validation data during training</li>
<li>Store the result of training in a variable called
<code>history</code>
</li>
<li>Training can take a while, it is a much larger model than what we
have seen so far.</li>
</ul>
</div>
<div class="section level3">
<h3 id="inspect-the-results">3. Inspect the results<a class="anchor" aria-label="anchor" href="#inspect-the-results"></a>
</h3>
<p>Plot the training history and evaluate the trained model. What do you
think of the results?</p>
</div>
<div class="section level3">
<h3 id="optional-try-out-other-pre-trained-neural-networks">4. (Optional) Try out other pre-trained neural networks<a class="anchor" aria-label="anchor" href="#optional-try-out-other-pre-trained-neural-networks"></a>
</h3>
<p>Train and evaluate another pre-trained model from <a href="https://keras.io/api/applications/" class="external-link uri">https://keras.io/api/applications/</a>. How does it compare
to DenseNet121?</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="section level3">
<h3 id="compile-the-model-1">1. Compile the model<a class="anchor" aria-label="anchor" href="#compile-the-model-1"></a>
</h3>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>              loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="train-the-model-1">2. Train the model<a class="anchor" aria-label="anchor" href="#train-the-model-1"></a>
</h3>
<p>Define the early stopper:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>early_stopper <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>                              patience<span class="op">=</span><span class="dv">5</span>)</span></code></pre>
</div>
<p>Train the model:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(x<span class="op">=</span>train_images,</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>                    y<span class="op">=</span>train_labels,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>                    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>                    epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>                    callbacks<span class="op">=</span>[early_stopper],</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>                    validation_data<span class="op">=</span>(val_images, val_labels))</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="inspect-the-results-1">3. Inspect the results<a class="anchor" aria-label="anchor" href="#inspect-the-results-1"></a>
</h3>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="kw">def</span> plot_history(history, metrics):</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">    Plot the training history</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">        history (keras History object that is returned by model.fit())</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">        metrics(str, list): Metric or a list of metrics to plot</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    history_df <span class="op">=</span> pd.DataFrame.from_dict(history.history)</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>    sns.lineplot(data<span class="op">=</span>history_df[metrics])</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>    plt.xlabel(<span class="st">"epochs"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>    plt.ylabel(<span class="st">"metric"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>plot_history(history, [<span class="st">'accuracy'</span>, <span class="st">'val_accuracy'</span>])</span></code></pre>
</div>
<p><img src="fig/05_training_history_transfer_learning.png" alt="Training history for training the pre-trained-model. The training accuracy slowly raises from 0.2 to 0.9 in 20 epochs. The validation accuracy starts higher at 0.25, but reaches a plateau around 0.64" class="figure">
The final validation accuracy reaches 64%, this is a huge improvement
over 30% accuracy we reached with the simple convolutional neural
network that we build from scratch in the previous episode.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="concluding-the-power-of-transfer-learning">Concluding: The power of transfer learning<a class="anchor" aria-label="anchor" href="#concluding-the-power-of-transfer-learning"></a>
</h2>
<hr class="half-width">
<p>In many domains, large networks are available that have been trained
on vast amounts of data, such as in computer vision and natural language
processing. Using transfer learning, you can benefit from the knowledge
that was captured from another machine learning task. In many fields,
transfer learning will outperform models trained from scratch,
especially if your dataset is small or of poor quality.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Large pre-trained models capture generic knowledge about a
domain</li>
<li>Use the <code>keras.applications</code> module to easily use
pre-trained models for your own datasets</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-6-outlook"><p>Content from <a href="6-outlook.html">Outlook</a></p>
<hr>
<p>Last updated on 2025-09-01 |

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/episodes/6-outlook.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does what I learned in this course translate to real-world
problems?</li>
<li>How do I organise a deep learning project?</li>
<li>What are next steps to take after this course?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand that what we learned in this course can be applied to
real-world problems</li>
<li>Use best practices for organising a deep learning project</li>
<li>Identify next steps to take after this course</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>You have come to the end of this course. In this episode we will look
back at what we have learned so far, how to apply that to real-world
problems, and identify next steps to take to start applying deep
learning in your own projects.</p>
<section><h2 class="section-heading" id="real-world-application">Real-world application<a class="anchor" aria-label="anchor" href="#real-world-application"></a>
</h2>
<hr class="half-width">
<p>To introduce the core concepts of deep learning we have used quite
simple machine learning problems. But how does what we learned so far
apply to real-world applications?</p>
<p>To illustrate that what we learned is actually the basis of
successful applications in research, we will have a look at an example
from the field of <a href="https://en.wikipedia.org/wiki/Cheminformatics" class="external-link">cheminformatics</a>.</p>

<p>We will have a look at <a href="https://github.com/matchms/ms2deepscore/blob/0.4.0/notebooks/MS2DeepScore_tutorial.ipynb" class="external-link">this
notebook</a>. It is part of the codebase for <a href="https://doi.org/10.1186/s13321-021-00558-4" class="external-link">this paper</a>.</p>
<p>In short, the deep learning problem is that of finding out how
similar two molecules are in terms of their molecular properties, based
on their mass spectrum. You can compare this to comparing two pictures
of animals, and predicting how similar they are.</p>
<p>A Siamese neural network is used to solve the problem. In a Siamese
neural network you have two input vectors, let’s say two images of
animals or two mass spectra. They pass through a base network. Instead
of outputting a class or number with one or a few output neurons, the
output layer of the base network is a whole vector of for example 100
neurons. After passing through the base network, you end up with two of
these vectors representing the two inputs. The goal of the base network
is to output a meaningful representation of the input (this is called an
embedding). The next step is to compute the cosine similarity between
these two output vectors, cosine similarity is a measure for how similar
two vectors are to each other, ranging from 0 (completely different) to
1 (identical). This cosine similarity is compared to the actual
similarity between the two inputs and this error is used to update the
weights in the network.</p>
<p>Don’t worry if you do not fully understand the deep learning problem
and the approach that is taken here. We just want you to appreciate that
you already learned enough to be able to do this yourself in your own
domain.</p>
<div id="exercise-a-real-world-deep-learning-application" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="exercise-a-real-world-deep-learning-application" class="callout-inner">
<h3 class="callout-title">Exercise: A real-world deep learning
application</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>Looking at the ‘Model training’ section of the notebook, what do you
recognize from what you learned in this course?</li>
<li>Can you identify the different steps of the deep learning workflow
in this notebook?</li>
<li>(Optional): Try to understand the neural network architecture from
the first figure of <a href="https://doi.org/10.1186/s13321-021-00558-4" class="external-link">the paper</a>.
<ol style="list-style-type: lower-alpha">
<li>Why are there 10.000 neurons in the input layer?</li>
<li>What do you think would happen if you would decrease the size of
spectral embedding layer drastically, to for example 5 neurons?</li>
</ol>
</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>The model summary for the Siamese model is more complex than what we
have seen so far, but it is basically a repetition of Dense, BatchNorm,
and Dropout layers. The syntax for training and evaluating the model is
the same as what we learned in this course. EarlyStopping as well as the
Adam optimizer is used.</li>
<li>The different steps are not as clearly defined as in this course,
but you should be able to identify ‘3: Data preparation’, ‘4: Choose a
pretrained model or start building architecture from scratch’, ‘5:
Choose a loss function and optimizer’, ‘6: Train the model’, ‘7: Make
predictions’ (which is called ‘Model inference’ in this notebook), and
‘10: Save model’.</li>
<li>(optional)
<ol style="list-style-type: lower-alpha">
<li>Because the shape of the input is 10.000. More specifically, the
spectrum is binned into a size 10.000 vector, apparently this is a good
size to represent the mass spectrum.</li>
<li>This would force the neural network to have a representation of the
mass spectrum in only 5 numbers. This representation would probably be
more generic, but might fail to capture all the characteristics found in
the spectrum. This would likely result in underfitting.</li>
</ol>
</li>
</ol>
</div>
</div>
</div>
</div>
<p>Hopefully you can appreciate that what you learned in this course,
can be applied to real-world problems as well.</p>
<div id="extensive-data-preparation" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="extensive-data-preparation" class="callout-inner">
<h3 class="callout-title">Extensive data preparation</h3>
<div class="callout-content">
<p>You might have noticed that the data preparation for this example is
much more extensive than what we have done so far in this course. This
is quite common for applied deep learning projects. It is said that 90%
of the time in a deep learning problem is spent on data preparation, and
only 10% on modeling!</p>
</div>
</div>
</div>
<div id="bias-and-evaluation" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="bias-and-evaluation" class="callout-inner">
<h3 class="callout-title">Bias and Evaluation</h3>
<div class="callout-content">
<p>Bias has been discussed in the context of machine learning, deep
learning and artificial intelligence frequently and on various levels.
That is because there are many aspects to bias. One the one hand, bias
is very technical: a model can be biased towards certain classes or
certain features. On the other hand, this can have very practical and
severe impact on the users of a such a model; for instance when it comes
to misclassification in relation to color of the skin or geographical
location.</p>
<p>If such biases are reflected in a dataset that is used for model
validation and testing, you might not be able to see them. In order to
get an evaluation that is representative for the diversity found in the
real world, it is therefore important to use a test set that reflects
this diversity as much as possible.</p>
<p>The need for such a dataset as opposed to existing datasets that
mostly presumed Western standards has been one of the motivations for
creating the Dollar Street Dataset – and why we have used it in this
lesson. The creators <a href="https://papers.nips.cc/paper_files/paper/2022/hash/5474d9d43c0519aa176276ff2c1ca528-Abstract-Datasets_and_Benchmarks.html" class="external-link">have
shown</a> that more diversity in a training dataset can contribute to
significant model improvements. A model trained on a more diverse
dataset is more robust against unexpected occurrences.</p>
<p>Therefore, it is important to fully understand the quantitative
evaluation of a new model: it reflects the model’s performance on the
test set, but it does not say anything about how well that dataset
represents the real world. Also be aware that such matters can be
related to racism and other forms of discrimination. Depending on the
use case, diversity can also refer to imbalance on other, more subtle
and less sensitive dimensions.</p>
<p><strong>Discuss the following statement with your
neighbors:</strong></p>
<ul>
<li>What forms of bias and data imbalance can you think of?</li>
<li>How would they affect the performance of a deep learning model?</li>
</ul>
</div>
</div>
</div>
<div id="discussion-large-language-models-and-prompt-engineering" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="discussion-large-language-models-and-prompt-engineering" class="callout-inner">
<h3 class="callout-title">Discussion: Large Language Models and prompt
engineering</h3>
<div class="callout-content">
<p>Large Language Models (LLMs) are deep learning models that are able
to perform general-purpose language generation. They are trained on
large amounts of texts, such all pages of Wikipedia. In recent years the
quality of LLMs language understanding and generation has increased
tremendously, and since the launch of generative chatbot ChatGPT in 2022
the power of LLMs is now appreciated by the general public.</p>
<p>It is becoming more and more feasible to unleash this power in
scientific research. For example, the authors of <a href="https://doi.org/10.1021/acscentsci.3c01087" class="external-link">Zheng et
al. (2023)</a> guided ChatGPT in the automation of extracting chemical
information from a large amount of research articles. The authors did
not implement a deep learning model themselves, but instead they
designed the right input for ChatGPT (called a ‘prompt’) that would
produce optimal outputs. This is called prompt engineering. A highly
simplified example of such a prompt would be: “Given compounds X and Y
and context Z, what are the chemical details of the reaction?”</p>
<p>Developments in LLM research are moving fast, at the end of 2023 the
newest ChatGPT version <a href="https://openai.com/blog/chatgpt-can-now-see-hear-and-speak" class="external-link">could
take images and sound as input</a>. In theory, this means that you can
solve the Dollar Street image classification problem from the previous
episode by prompt engineering, with prompts similar to “Which out of
these categories: [LIST OF CATEGORIES] is depicted in the image”.</p>
<p><strong>Discuss the following statement with your
neighbors:</strong></p>
<p><em>In a few years most machine learning problems in scientific
research can be solved with prompt engineering.</em></p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="organising-deep-learning-projects">Organising deep learning projects<a class="anchor" aria-label="anchor" href="#organising-deep-learning-projects"></a>
</h2>
<hr class="half-width">
<p>As you might have noticed already in this course, deep learning
projects can quickly become messy. Here follow some best practices for
keeping your projects organized:</p>
<div class="section level3">
<h3 id="organise-experiments-in-notebooks">1. Organise experiments in notebooks<a class="anchor" aria-label="anchor" href="#organise-experiments-in-notebooks"></a>
</h3>
<p>Jupyter notebooks are a useful tool for doing deep learning
experiments. You can very easily modify your code bit by bit, and
interactively look at the results. In addition you can explain why you
are doing things in markdown cells. - As a rule of thumb do one approach
or experiment in one notebook. - Give consistent and meaningful names to
notebooks, such as: <code>01-all-cities-simple-cnn.ipynb</code> - Add a
rationale on top and a conclusion on the bottom of each notebook</p>
<p><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007007" class="external-link"><em>Ten
simple rules for writing and sharing computational analyses in Jupyter
Notebooks</em></a> provides further advice on how to maximise the
usefulness and reproducibility of experiments captured in a
notebook.</p>
</div>
<div class="section level3">
<h3 id="use-python-modules">2. Use Python modules<a class="anchor" aria-label="anchor" href="#use-python-modules"></a>
</h3>
<p>Code that is repeatedly used should live in a Python module and not
be copied to multiple notebooks. You can import functions and classes
from the module(s) in the notebooks. This way you can remove a lot of
code definition from your notebooks and have a focus on the actual
experiment.</p>
</div>
<div class="section level3">
<h3 id="keep-track-of-your-results-in-a-central-place">3. Keep track of your results in a central place<a class="anchor" aria-label="anchor" href="#keep-track-of-your-results-in-a-central-place"></a>
</h3>
<p>Always evaluate your experiments in the same way, on the exact same
test set. Document the results of your experiments in a consistent and
meaningful way. You can use a simple spreadsheet such as this:</p>
<table class="table">
<colgroup>
<col width="21%">
<col width="38%">
<col width="5%">
<col width="13%">
<col width="13%">
<col width="8%">
</colgroup>
<thead><tr class="header">
<th>MODEL NAME</th>
<th>MODEL DESCRIPTION</th>
<th>RMSE</th>
<th>TESTSET NAME</th>
<th>GITHUB COMMIT</th>
<th>COMMENTS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>weather_prediction_v1.0</td>
<td>Basel features only, 10 years. nn: 100-50</td>
<td>3.21</td>
<td>10_years_v1.0</td>
<td>ed28d85</td>
<td></td>
</tr>
<tr class="even">
<td>weather_prediction_v1.1</td>
<td>all features, 10 years. nn: 100-50</td>
<td>3.35</td>
<td>10_years_v1.0</td>
<td>4427b78</td>
<td></td>
</tr>
</tbody>
</table>
<p>You could also use a tool such as <a href="https://wandb.ai/site" class="external-link">Weights and Biases</a> for this.</p>
<div id="cookiecutter-data-science" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="cookiecutter-data-science" class="callout-inner">
<h3 class="callout-title">Cookiecutter data science</h3>
<div class="callout-content">
<p>If you want to get more pointers for organising deep learning, or
data science projects in general, we recommend <a href="https://drivendata.github.io/cookiecutter-data-science/" class="external-link">Cookiecutter
data science</a>. It is a template for initiating an organized data
science project folder structure that you can adapt to your own
needs.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="next-steps">Next steps<a class="anchor" aria-label="anchor" href="#next-steps"></a>
</h2>
<hr class="half-width">
<p>You now understand the basic principles of deep learning and are able
to implement your own deep learning pipelines in Python. But there is
still so much to learn and do!</p>
<p>Here are some suggestions for next steps you can take in your
endeavor to become a deep learning expert:</p>
<ul>
<li>Learn more by going through a few of <a href="reference.html#external-references">the learning resources we have
compiled for you</a>
</li>
<li>Apply what you have learned to your own projects. Use the deep
learning workflow to structure your work. Start as simple as possible,
and incrementally increase the complexity of your approach.</li>
<li>Compete in a <a href="https://www.kaggle.com/competitions" class="external-link">Kaggle
competition</a> to practice what you have learned.</li>
<li>Get access to a GPU. Your deep learning experiments will progress
much quicker if you have to wait for your network to train in a few
seconds instead of hours (which is the order of magnitude of speedup you
can expect from training on a GPU instead of CPU). Tensorflow/Keras will
automatically detect and use a GPU if it is available on your system
without any code changes. A simple and quick way to get access to a GPU
is to use <a href="https://colab.google/" class="external-link">Google Colab</a>
</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Although the data preparation and model architectures are somewhat
more complex, what we have learned in this course can directly be
applied to real-world problems</li>
<li>Use what you have learned in this course as a basis for your own
learning trajectory in the world of deep learning</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-lab/deep-learning-intro/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-lab/deep-learning-intro/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-lab/deep-learning-intro/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-lab/deep-learning-intro/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:deep-learning-lesson-dev@esciencecenter.nl">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries-lab.github.io/deep-learning-intro/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "deep learning, keras, lesson, The Carpentries, neural networks",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-lab.github.io/deep-learning-intro/aio.html",
  "identifier": "https://carpentries-lab.github.io/deep-learning-intro/aio.html",
  "dateCreated": "2020-10-17",
  "dateModified": "2025-10-23",
  "datePublished": "2025-10-23"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

